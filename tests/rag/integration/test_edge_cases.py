"""
Integration tests for Edge Cases and Error Scenarios.

Tests challenging edge cases that may occur in real-world usage:
- Typos and spelling errors
- Incomplete sentences
- Mixed language queries
- Special characters and formatting
- Empty or malformed queries
- Very long queries
"""

import pytest

from src.rag.automation.domain.context_tracker import ContextTracker
from src.rag.automation.domain.entities import ContextHistory, Turn
from src.rag.domain.entities import Chunk, ChunkLevel
from src.rag.infrastructure.query_analyzer import QueryAnalyzer, QueryType
from src.rag.infrastructure.query_expander import DynamicQueryExpander


def make_chunk(
    id: str,
    text: str,
    title: str = "",
    rule_code: str = "",
) -> Chunk:
    """Helper to create test chunks."""
    return Chunk(
        id=id,
        text=text,
        title=title,
        rule_code=rule_code,
        level=ChunkLevel.ARTICLE,
        embedding_text=text,
        full_text=text,
        parent_path=[title] if title else [],
        token_count=len(text.split()),
        keywords=[],
        is_searchable=True,
    )


class TestTypoHandling:
    """Test handling of typos and spelling errors."""

    @pytest.fixture
    def query_analyzer(self):
        """Create QueryAnalyzer instance."""
        return QueryAnalyzer()

    def test_common_korean_typo_correction(self, query_analyzer):
        """
        SPEC: System should handle common Korean typos.

        Given: Query with common typos (e.g., "íœ´í•™" -> "íœ´í•™", "ì¥í•™ê¸ˆ" -> "ì¥í•™ê¸ˆ")
        When: Query is analyzed
        Then: Should detect intent despite typos
        """
        # Common typo: ã…—/ã…“ confusion, consonant omission
        query = "íœµí•™ ì‹ ì²­ ë°©ë²• ì•Œë ¤ì£¼ì„¸ìš”"  # "íœ´í•™" typo

        query_type = query_analyzer.analyze(query)

        # Should still detect as natural question
        assert query_type in (
            QueryType.NATURAL_QUESTION,
            QueryType.NATURAL_QUESTION,
            QueryType.INTENT,
            QueryType.GENERAL,
        )

    def test_english_korean_mix_typo(self, query_analyzer):
        """
        SPEC: System should handle English-Korean mixed typos.

        Given: Query "GPA ì •ì • í•˜ëŠ” ë²•"
        When: Query is analyzed
        Then: Should recognize GPA as ì„±ì  context
        """
        query = "GPA ì •ì • í•˜ëŠ” ë²•"

        query_type = query_analyzer.analyze(query)

        # Should detect as procedural question
        assert query_type in (
            QueryType.NATURAL_QUESTION,
            QueryType.NATURAL_QUESTION,
            QueryType.GENERAL,
        )

    def test_consonant_vowel_omission(self, query_analyzer):
        """
        SPEC: System should handle Korean consonant/vowel omissions.

        Given: Query "ì¥í•™ê¸ˆ ë°›ã„¹ ìˆ˜ ìˆë‚˜ìš”?" (consonant omitted)
        When: Query is analyzed
        Then: Should still detect correct intent
        """
        query = "ì¥í•™ê¸ˆ ë°›ã„¹ ìˆ˜ ìˆë‚˜ìš”?"

        query_type = query_analyzer.analyze(query)

        # Should detect as eligibility question
        assert query_type in (
            QueryType.NATURAL_QUESTION,
            QueryType.INTENT,
            QueryType.INTENT,
            QueryType.GENERAL,
        )

    def test_spacing_errors(self, query_analyzer):
        """
        SPEC: System should handle spacing errors.

        Given: Query "íœ´í•™ì‹ ì²­í•˜ëŠ”ë²•" (no spaces)
        When: Query is analyzed
        Then: Should segment correctly
        """
        query = "íœ´í•™ì‹ ì²­í•˜ëŠ”ë²•"

        query_type = query_analyzer.analyze(query)

        # Should detect as procedural question
        assert query_type in (
            QueryType.NATURAL_QUESTION,
            QueryType.NATURAL_QUESTION,
            QueryType.GENERAL,
        )


class TestIncompleteSentences:
    """Test handling of incomplete sentence fragments."""

    @pytest.fixture
    def query_analyzer(self):
        """Create QueryAnalyzer instance."""
        return QueryAnalyzer()

    def test_sentence_fragment_with_context(self, query_analyzer):
        """
        SPEC: System should complete fragments using conversation context.

        Given: Previous turn about "íœ´í•™ ì‹ ì²­"
        When: Follow-up is "ì„œë¥˜ëŠ”?" (incomplete)
        Then: Should complete to "íœ´í•™ ì‹ ì²­ ì„œë¥˜ëŠ”?"
        """
        ContextHistory(
            scenario_id="fragment_test",
            conversation_history=[
                Turn(
                    turn_number=1,
                    query="íœ´í•™ ì‹ ì²­ì€ ì–´ë–»ê²Œ í•˜ë‚˜ìš”?",
                    answer="íœ´í•™ ì‹ ì²­ì€...",
                    sources=["ê·œì •"],
                    confidence=0.9,
                )
            ],
            implicit_entities={"íœ´í•™": "leave"},
            topic_transitions=[],
            intent_history=["íœ´í•™ ì‹ ì²­"],
        )

        fragment_query = "ì„œë¥˜ëŠ”?"

        # Should detect context from history
        query_type = query_analyzer.analyze(fragment_query)

        assert query_type in (
            QueryType.NATURAL_QUESTION,
            QueryType.INTENT,
            QueryType.GENERAL,
        )

    def test_single_word_query(self, query_analyzer):
        """
        SPEC: System should handle single-word queries.

        Given: Query "íœ´í•™?" (just topic name)
        When: Query is analyzed
        Then: Should infer general information request
        """
        query = "íœ´í•™?"

        query_type = query_analyzer.analyze(query)

        # Should detect as general question
        assert query_type in (
            QueryType.NATURAL_QUESTION,
            QueryType.INTENT,
            QueryType.GENERAL,
        )

    def test_elliptical_expression(self, query_analyzer):
        """
        SPEC: System should handle elliptical expressions.

        Given: Query "ì–¸ì œê¹Œì§€ì•¼?" (missing subject)
        When: Query is analyzed
        Then: Should recognize as deadline question
        """
        query = "ì–¸ì œê¹Œì§€ì•¼?"

        query_type = query_analyzer.analyze(query)

        # Should detect as general question (context-dependent)
        assert query_type in (
            QueryType.NATURAL_QUESTION,
            QueryType.GENERAL,
        )


class TestMixedLanguageQueries:
    """Test handling of mixed Korean-English queries."""

    @pytest.fixture
    def query_analyzer(self):
        """Create QueryAnalyzer instance."""
        return QueryAnalyzer()

    def test_korean_english_code_switching(self, query_analyzer):
        """
        SPEC: System should handle Korean-English code switching.

        Given: Query "GPA 3.5 ì´ìƒì´ë©´ ì¥í•™ê¸ˆ ë°›ì•„ìš”?"
        When: Query is analyzed
        Then: Should handle mixed script correctly
        """
        query = "GPA 3.5 ì´ìƒì´ë©´ ì¥í•™ê¸ˆ ë°›ì•„ìš”?"

        query_type = query_analyzer.analyze(query)

        # Should detect as eligibility question
        assert query_type in (
            QueryType.NATURAL_QUESTION,
            QueryType.INTENT,
            QueryType.INTENT,
            QueryType.GENERAL,
        )

    def test_english_acronyms(self, query_analyzer):
        """
        SPEC: System should handle English acronyms in Korean text.

        Given: Query "TOEIC ì„±ì ìœ¼ë¡œ ì¥í•™ê¸ˆ ê°€ëŠ¥?"
        When: Query is analyzed
        Then: Should recognize TOEIC as English test score
        """
        query = "TOEIC ì„±ì ìœ¼ë¡œ ì¥í•™ê¸ˆ ê°€ëŠ¥?"

        query_type = query_analyzer.analyze(query)

        # Should detect as eligibility question
        assert query_type in (
            QueryType.NATURAL_QUESTION,
            QueryType.INTENT,
            QueryType.INTENT,
            QueryType.GENERAL,
        )

    def test_mixed_script_loanwords(self, query_analyzer):
        """
        SPEC: System should handle loanwords in original script.

        Given: Query "Campus job ì•Œë°” í•´ë„ ë˜ë‚˜ìš”?"
        When: Query is analyzed
        Then: Should map loanwords to Korean equivalents
        """
        query = "Campus job ì•Œë°” í•´ë„ ë˜ë‚˜ìš”?"

        query_type = query_analyzer.analyze(query)

        # Should detect as eligibility question
        assert query_type in (
            QueryType.NATURAL_QUESTION,
            QueryType.INTENT,
            QueryType.INTENT,
            QueryType.GENERAL,
        )


class TestSpecialCharacters:
    """Test handling of special characters and formatting."""

    @pytest.fixture
    def query_analyzer(self):
        """Create QueryAnalyzer instance."""
        return QueryAnalyzer()

    def test_emoji_in_query(self, query_analyzer):
        """
        SPEC: System should handle emojis in queries.

        Given: Query "íœ´í•™ ì‹ ì²­ ë°©ë²• ì•Œë ¤ì£¼ì„¸ìš” ğŸ™"
        When: Query is analyzed
        Then: Should ignore or handle emojis appropriately
        """
        query = "íœ´í•™ ì‹ ì²­ ë°©ë²• ì•Œë ¤ì£¼ì„¸ìš” ğŸ™"

        query_type = query_analyzer.analyze(query)

        # Should still detect as procedural question
        assert query_type in (
            QueryType.NATURAL_QUESTION,
            QueryType.NATURAL_QUESTION,
            QueryType.GENERAL,
        )

    def test_excessive_punctuation(self, query_analyzer):
        """
        SPEC: System should handle excessive punctuation.

        Given: Query "ì§„ì§œ ê¶ê¸ˆí•´ìš”!!!! ì¥í•™ê¸ˆ ì–´ë–»ê²Œ ë°›ì•„ìš”???"
        When: Query is analyzed
        Then: Should normalize punctuation
        """
        query = "ì§„ì§œ ê¶ê¸ˆí•´ìš”!!!! ì¥í•™ê¸ˆ ì–´ë–»ê²Œ ë°›ì•„ìš”???"

        query_type = query_analyzer.analyze(query)

        # Should detect as natural question
        assert query_type in (
            QueryType.NATURAL_QUESTION,
            QueryType.NATURAL_QUESTION,
            QueryType.INTENT,
            QueryType.GENERAL,
        )

    def test_legal_article_reference_format(self, query_analyzer):
        """
        SPEC: System should handle legal article references.

        Given: Query "í•™ì¹™ Â§15ì¡°ì— ë”°ë¥´ë©´ ë­ê°€ ë˜ë‚˜ìš”?"
        When: Query is analyzed
        Then: Should recognize article reference format
        """
        query = "í•™ì¹™ Â§15ì¡°ì— ë”°ë¥´ë©´ ë­ê°€ ë˜ë‚˜ìš”?"

        query_type = query_analyzer.analyze(query)

        # Should detect as article reference or natural question
        assert query_type in (
            QueryType.ARTICLE_REFERENCE,
            QueryType.NATURAL_QUESTION,
            QueryType.GENERAL,
        )

    def test_parentheses_content(self, query_analyzer):
        """
        SPEC: System should handle parenthetical content.

        Given: Query "ë³µí•™ (íœ´í•™ í›„ ì¬ì…í•™) ì ˆì°¨ê°€ ì–´ë–»ê²Œ ë¼ìš”?"
        When: Query is analyzed
        Then: Should handle parenthetical explanation
        """
        query = "ë³µí•™ (íœ´í•™ í›„ ì¬ì…í•™) ì ˆì°¨ê°€ ì–´ë–»ê²Œ ë¼ìš”?"

        query_type = query_analyzer.analyze(query)

        # Should detect as procedural question
        assert query_type in (
            QueryType.NATURAL_QUESTION,
            QueryType.NATURAL_QUESTION,
            QueryType.GENERAL,
        )


class TestEdgeCaseQueries:
    """Test various edge case query scenarios."""

    @pytest.fixture
    def query_analyzer(self):
        """Create QueryAnalyzer instance."""
        return QueryAnalyzer()

    def test_empty_query(self, query_analyzer):
        """
        SPEC: System should handle empty queries gracefully.

        Given: Query "" or "   "
        When: Query is analyzed
        Then: Should return appropriate response or error
        """
        query = ""

        # Should handle without crashing
        query_type = query_analyzer.analyze(query)

        # Should default to general or handle gracefully
        assert query_type is not None

    def test_very_long_query(self, query_analyzer):
        """
        SPEC: System should handle very long queries.

        Given: Query with 500+ characters
        When: Query is analyzed
        Then: Should process without errors
        """
        query = " ".join(["ì¥í•™ê¸ˆ"] * 100) + " ì‹ ì²­ ë°©ë²• ì•Œë ¤ì£¼ì„¸ìš”"

        # Should handle without crashing
        query_type = query_analyzer.analyze(query)

        assert query_type is not None

    def test_repeated_words(self, query_analyzer):
        """
        SPEC: System should handle repeated words (stuttering/emphasis).

        Given: Query "ì§„ì§œ ì§„ì§œ ê¼­ ì•Œê³  ì‹¶ì€ë° íœ´í•™ ë°©ë²• ì•Œë ¤ì¤˜"
        When: Query is analyzed
        Then: Should normalize repetitions
        """
        query = "ì§„ì§œ ì§„ì§œ ê¼­ ì•Œê³  ì‹¶ì€ë° íœ´í•™ ë°©ë²• ì•Œë ¤ì¤˜"

        query_type = query_analyzer.analyze(query)

        # Should detect as procedural question
        assert query_type in (
            QueryType.NATURAL_QUESTION,
            QueryType.NATURAL_QUESTION,
            QueryType.INTENT,
            QueryType.GENERAL,
        )

    def test_negation_query(self, query_analyzer):
        """
        SPEC: System should handle negation queries correctly.

        Given: Query "íœ´í•™ ì•ˆ í•˜ë©´ ì•ˆ ë˜ë‚˜ìš”?"
        When: Query is analyzed
        Then: Should detect negation properly
        """
        query = "íœ´í•™ ì•ˆ í•˜ë©´ ì•ˆ ë˜ë‚˜ìš”?"

        query_type = query_analyzer.analyze(query)

        # Should detect as eligibility/natural question
        assert query_type in (
            QueryType.NATURAL_QUESTION,
            QueryType.INTENT,
            QueryType.INTENT,
            QueryType.GENERAL,
        )

    def test_double_negative_query(self, query_analyzer):
        """
        SPEC: System should handle double negatives.

        Given: Query "ì¥í•™ê¸ˆ ì•ˆ ëª» ë°›ëŠ” ê²½ìš° ì—†ë‚˜ ì—†ì–´?"
        When: Query is analyzed
        Then: Should resolve double negative correctly
        """
        query = "ì¥í•™ê¸ˆ ì•ˆ ëª» ë°›ëŠ” ê²½ìš° ì—†ë‚˜ ì—†ì–´?"

        query_type = query_analyzer.analyze(query)

        # Should handle despite double negative
        assert query_type in (
            QueryType.NATURAL_QUESTION,
            QueryType.INTENT,
            QueryType.GENERAL,
        )


class TestContextEdgeCases:
    """Test edge cases in context management."""

    @pytest.fixture
    def context_tracker(self):
        """Create ContextTracker instance."""
        return ContextTracker(context_window_size=3)

    def test_context_with_no_history(self, context_tracker):
        """
        SPEC: System should handle context with no previous history.

        Given: Empty conversation history
        When: Context preservation is checked
        Then: Should return True (nothing to preserve)
        """
        empty_context = ContextHistory(
            scenario_id="empty_test",
            conversation_history=[],
            implicit_entities={},
            topic_transitions=[],
            intent_history=[],
        )

        current_turn = Turn(
            turn_number=1,
            query="íœ´í•™ ë°©ë²•",
            answer="ë‹µë³€",
            sources=["ê·œì •"],
            confidence=0.9,
        )

        preserved = context_tracker.detect_context_preservation(
            empty_context, current_turn
        )

        assert preserved is True, "Empty context should preserve by default"

    def test_context_exceeding_window(self, context_tracker):
        """
        SPEC: System should handle context exceeding window size.

        Given: Conversation history with 10 turns
        When: Context window is 3
        Then: Should only consider last 3 turns
        """
        # Create 10 turns
        turns = [
            Turn(
                turn_number=i,
                query=f"Question {i}",
                answer=f"Answer {i}",
                sources=[f"Source {i}"],
                confidence=0.8,
            )
            for i in range(1, 11)
        ]

        context = ContextHistory(
            scenario_id="window_test",
            conversation_history=turns,
            implicit_entities={},
            topic_transitions=[],
            intent_history=[f"Intent {i}" for i in range(1, 11)],
        )

        recent = context.get_recent_context(window_size=3)

        # Should only return last 3 turns
        assert len(recent) == 3
        assert recent[0].turn_number == 8
        assert recent[1].turn_number == 9
        assert recent[2].turn_number == 10

    def test_rapid_topic_switching(self, context_tracker):
        """
        SPEC: System should handle rapid topic switching.

        Given: Conversation rapidly switching between unrelated topics
        When: Topic transitions are tracked
        Then: Should detect multiple transitions
        """
        turns = [
            Turn(
                turn_number=1,
                query="íœ´í•™ ë°©ë²•",  # Topic A
                answer="A1",
                sources=["ê·œì • A"],
                confidence=0.9,
            ),
            Turn(
                turn_number=2,
                query="ì¡¸ì—… ìš”ê±´",  # Topic B
                answer="B1",
                sources=["ê·œì • B"],
                confidence=0.8,
            ),
            Turn(
                turn_number=3,
                query="ì¥í•™ê¸ˆ",  # Topic C
                answer="C1",
                sources=["ê·œì • C"],
                confidence=0.85,
            ),
        ]

        context = ContextHistory(
            scenario_id="switch_test",
            conversation_history=[],
            implicit_entities={},
            topic_transitions=[],
            intent_history=[],
        )

        # Add turns and track transitions
        transitions = []
        for i, turn in enumerate(turns):
            if i == 0:
                context = context_tracker.create_initial_context("switch_test", turn)
            else:
                old_context = context
                context = context_tracker.update_context(context, turn)
                transition = context_tracker._detect_topic_transition(old_context, turn)
                if transition:
                    transitions.append(transition)

        # Should detect topic transitions
        assert len(transitions) >= 1, "Should detect at least one topic transition"


class TestQueryExpansionEdgeCases:
    """Test edge cases in query expansion."""

    def test_expand_stopwords_only(self):
        """
        SPEC: System should handle queries with only stopwords.

        Given: Query "ê·¸ê²Œ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?" (mostly stopwords)
        When: Query is expanded
        Then: Should handle gracefully without excessive expansion
        """
        expander = DynamicQueryExpander()
        query = "ê·¸ê²Œ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?"

        result = expander.expand(query)

        # Should return some expansion
        assert result is not None
        assert len(result.expanded_query) > 0

    def test_expand_with_numerical_values(self):
        """
        SPEC: System should handle numerical values in queries.

        Given: Query "3.5 ì´ìƒ GPAë©´ ì¥í•™ê¸ˆ ë°›ì•„?"
        When: Query is expanded
        Then: Should preserve numerical information
        """
        expander = DynamicQueryExpander()
        query = "3.5 ì´ìƒ GPAë©´ ì¥í•™ê¸ˆ ë°›ì•„?"

        result = expander.expand(query)

        # Should contain key terms
        assert (
            "3.5" in result.expanded_query
            or "GPA" in result.expanded_query
            or "ì¥í•™" in result.expanded_query
        )

    def test_expand_with_date_references(self):
        """
        SPEC: System should handle date/time references.

        Given: Query "2024ë…„ 2í•™ê¸° ì¥í•™ê¸ˆ ì‹ ì²­ ê¸°ê°„"
        When: Query is expanded
        Then: Should preserve temporal information
        """
        expander = DynamicQueryExpander()
        query = "2024ë…„ 2í•™ê¸° ì¥í•™ê¸ˆ ì‹ ì²­ ê¸°ê°„"

        result = expander.expand(query)

        # Should contain temporal terms
        has_temporal = any(
            term in result.expanded_query
            for term in ["2024", "2í•™ê¸°", "í•™ê¸°", "ì‹ ì²­", "ê¸°ê°„", "ì¥í•™"]
        )
        assert has_temporal
