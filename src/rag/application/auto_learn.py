"""
Auto Learning for RAG System Improvement.

Analyzes feedback data and suggests improvements
for intents, synonyms, and query understanding.
"""

import json
from collections import Counter
from dataclasses import dataclass, field
from pathlib import Path
from typing import TYPE_CHECKING, Any, Dict, List, Optional

if TYPE_CHECKING:
    from ..domain.repositories import ILLMClient
    from ..infrastructure.feedback import FeedbackCollector, FeedbackEntry


@dataclass
class ImprovementSuggestion:
    """
    A suggested improvement based on feedback analysis.
    
    Types:
        - intent: intents.jsonì— íŠ¸ë¦¬ê±° ì¶”ê°€
        - synonym: synonyms.jsonì— ë™ì˜ì–´ ì¶”ê°€
        - rerank: Reranker ê²€í†  í•„ìš”
        - llm_expert: LLM ê¸°ë°˜ ì œì•ˆ
        - code_pattern: QueryAnalyzer íŒ¨í„´ ë¡œì§ ê°œì„  í•„ìš”
        - code_weight: ê°€ì¤‘ì¹˜ í”„ë¦¬ì…‹ ì¡°ì • í•„ìš”
        - code_audience: ëŒ€ìƒ ê°ì§€ ë¡œì§ ê°œì„  í•„ìš”
        - architecture: ì‹œìŠ¤í…œ êµ¬ì¡°ì  ê°œì„  í•„ìš”
    """

    type: str
    priority: str  # "high", "medium", "low"
    description: str
    suggested_value: Dict[str, Any] = field(default_factory=dict)
    affected_queries: List[str] = field(default_factory=list)


@dataclass
class AnalysisResult:
    """Result of feedback analysis."""

    total_negative_feedback: int
    unique_problematic_queries: int
    suggestions: List[ImprovementSuggestion] = field(default_factory=list)


class AutoLearnUseCase:
    """
    Use case for automated learning from feedback.

    Analyzes negative feedback patterns and suggests
    improvements to intents, synonyms, and prompts.
    """

    def __init__(
        self,
        feedback_collector: Optional["FeedbackCollector"] = None,
        llm_client: Optional["ILLMClient"] = None,
        intents_path: Optional[str] = None,
        synonyms_path: Optional[str] = None,
    ):
        """
        Initialize auto learning use case.

        Args:
            feedback_collector: FeedbackCollector instance.
            llm_client: Optional LLM client for generating suggestions.
            intents_path: Path to intents.json.
            synonyms_path: Path to synonyms.json.
        """
        self._feedback = feedback_collector
        self._llm_client = llm_client
        self._intents_path = intents_path or self._default_intents_path()
        self._synonyms_path = synonyms_path or self._default_synonyms_path()

    def _default_intents_path(self) -> str:
        from ..config import get_config
        return str(get_config().intents_path_resolved or "data/config/intents.json")

    def _default_synonyms_path(self) -> str:
        from ..config import get_config
        return str(get_config().synonyms_path_resolved or "data/config/synonyms.json")

    def analyze_feedback(self) -> AnalysisResult:
        """
        Analyze negative feedback and generate improvement suggestions.

        Returns:
            AnalysisResult with suggestions.
        """
        if self._feedback is None:
            return AnalysisResult(
                total_negative_feedback=0,
                unique_problematic_queries=0,
            )

        negative = self._feedback.get_negative_feedback()
        if not negative:
            return AnalysisResult(
                total_negative_feedback=0,
                unique_problematic_queries=0,
            )

        # Group by query
        query_groups: Dict[str, List["FeedbackEntry"]] = {}
        for entry in negative:
            if entry.query not in query_groups:
                query_groups[entry.query] = []
            query_groups[entry.query].append(entry)

        suggestions: List[ImprovementSuggestion] = []

        # Analyze patterns
        for query, entries in query_groups.items():
            if len(entries) >= 2:  # Multiple negative feedback
                suggestion = self._analyze_query_pattern(query, entries)
                if suggestion:
                    suggestions.append(suggestion)

        # Check for missing intents
        intent_suggestions = self._check_missing_intents(query_groups)
        suggestions.extend(intent_suggestions)

        # Check for missing synonyms
        synonym_suggestions = self._check_missing_synonyms(query_groups)
        suggestions.extend(synonym_suggestions)

        # Check for code-level improvements (patterns in failures)
        code_suggestions = self._check_code_improvements(query_groups)
        suggestions.extend(code_suggestions)

        # LLM-based suggestions (if available)
        if self._llm_client and query_groups:
            # Sort queries by negative count
            top_problematic = sorted(
                query_groups.items(), key=lambda x: len(x[1]), reverse=True
            )[:5]

            for query, _ in top_problematic:
                llm_sug = self.suggest_with_llm(query)
                if llm_sug:
                    suggestions.append(llm_sug)

        return AnalysisResult(
            total_negative_feedback=len(negative),
            unique_problematic_queries=len(query_groups),
            suggestions=suggestions,
        )

    def _analyze_query_pattern(
        self,
        query: str,
        entries: List["FeedbackEntry"],
    ) -> Optional[ImprovementSuggestion]:
        """Analyze a specific query with multiple negative feedback."""
        # Check if intents were matched
        all_intents = set()
        for e in entries:
            all_intents.update(e.matched_intents or [])

        if not all_intents:
            return ImprovementSuggestion(
                type="intent",
                priority="high",
                description=f"ì¿¼ë¦¬ '{query}'ì— ë§¤ì¹­ë˜ëŠ” ì˜ë„ê°€ ì—†ìŒ",
                suggested_value={
                    "action": "add_intent",
                    "query": query,
                },
                affected_queries=[query],
            )

        # Check if wrong results were returned
        wrong_codes = [e.rule_code for e in entries]
        return ImprovementSuggestion(
            type="rerank",
            priority="medium",
            description=f"ì¿¼ë¦¬ '{query}'ì— ì˜ëª»ëœ ê·œì •({wrong_codes[:3]})ì´ ë°˜í™˜ë¨",
            suggested_value={
                "action": "review_search",
                "query": query,
                "wrong_rule_codes": wrong_codes,
            },
            affected_queries=[query],
        )

    def _check_missing_intents(
        self,
        query_groups: Dict[str, List["FeedbackEntry"]],
    ) -> List[ImprovementSuggestion]:
        """Check for queries that might need new intents."""
        suggestions = []

        # Load existing intents
        intents_path = Path(self._intents_path)
        if not intents_path.exists():
            return suggestions

        try:
            data = json.loads(intents_path.read_text(encoding="utf-8"))
            existing_triggers = set()
            for intent in data.get("intents", []):
                existing_triggers.update(intent.get("triggers", []))
        except Exception:
            return suggestions

        # Find queries not covered by existing triggers
        for query in query_groups.keys():
            query_lower = query.lower()
            covered = any(
                trigger.lower() in query_lower for trigger in existing_triggers
            )
            if not covered:
                suggestions.append(
                    ImprovementSuggestion(
                        type="intent",
                        priority="high",
                        description=f"ìƒˆ ì¸í…íŠ¸ íŠ¸ë¦¬ê±° ì¶”ê°€ ê¶Œì¥: '{query}'",
                        suggested_value={
                            "action": "add_trigger",
                            "query": query,
                        },
                        affected_queries=[query],
                    )
                )

        return suggestions[:5]  # Limit suggestions

    def _check_missing_synonyms(
        self,
        query_groups: Dict[str, List["FeedbackEntry"]],
    ) -> List[ImprovementSuggestion]:
        """Check for terms that might need synonyms."""
        suggestions = []

        # Load existing synonyms
        synonyms_path = Path(self._synonyms_path)
        if not synonyms_path.exists():
            return suggestions

        try:
            data = json.loads(synonyms_path.read_text(encoding="utf-8"))
            terms = data.get("terms", data) if isinstance(data, dict) else {}
            existing_terms = set(terms.keys())
        except Exception:
            return suggestions

        # Extract common words from queries
        word_counts: Counter = Counter()
        for query in query_groups.keys():
            words = query.split()
            for word in words:
                if len(word) >= 2:
                    word_counts[word] += 1

        # Find frequent words not in synonyms
        for word, count in word_counts.most_common(10):
            if word not in existing_terms and count >= 2:
                suggestions.append(
                    ImprovementSuggestion(
                        type="synonym",
                        priority="medium",
                        description=f"ë™ì˜ì–´ ì¶”ê°€ ê¶Œì¥: '{word}'",
                        suggested_value={
                            "action": "add_synonym",
                            "term": word,
                            "count": count,
                        },
                        affected_queries=[q for q in query_groups.keys() if word in q],
                    )
                )

        return suggestions[:5]

    def _check_code_improvements(
        self,
        query_groups: Dict[str, List["FeedbackEntry"]],
    ) -> List[ImprovementSuggestion]:
        """
        Analyze failure patterns to suggest code-level improvements.
        
        Detects patterns that indicate need for:
        - QueryAnalyzer pattern logic changes
        - Weight preset adjustments
        - Audience detection improvements
        - Architectural changes
        """
        suggestions = []
        
        # Pattern 1: Intent triggers match but wrong results
        # â†’ Indicates weight preset or reranker issues
        intent_matched_failures = [
            (q, entries) for q, entries in query_groups.items()
            if any(e.matched_intents for e in entries)
        ]
        if len(intent_matched_failures) >= 3:
            suggestions.append(
                ImprovementSuggestion(
                    type="code_weight",
                    priority="high",
                    description=(
                        f"ì¸í…íŠ¸ ë§¤ì¹­ë¨ì—ë„ {len(intent_matched_failures)}ê°œ ì¿¼ë¦¬ì—ì„œ "
                        "ì˜ëª»ëœ ê²°ê³¼ ë°˜í™˜ â†’ WEIGHT_PRESETS ë˜ëŠ” Reranker ê°€ì¤‘ì¹˜ ì¡°ì • í•„ìš”"
                    ),
                    suggested_value={
                        "action": "adjust_weight_presets",
                        "file": "src/rag/infrastructure/query_analyzer.py",
                        "target": "WEIGHT_PRESETS",
                        "note": "Intent ì¿¼ë¦¬ì˜ BM25/Dense ë¹„ìœ¨ ê²€í† ",
                    },
                    affected_queries=[q for q, _ in intent_matched_failures[:5]],
                )
            )
        
        # Pattern 2: Similar query patterns failing repeatedly
        # â†’ Indicates missing pattern in QueryAnalyzer
        pattern_keywords = ["ì‹¶ì–´", "í•˜ê³ ", "ì–´ë–»ê²Œ", "ë­ì•¼", "ì•Œë ¤ì¤˜"]
        keyword_failures: Dict[str, List[str]] = {}
        for query in query_groups.keys():
            for kw in pattern_keywords:
                if kw in query:
                    keyword_failures.setdefault(kw, []).append(query)
        
        for kw, queries in keyword_failures.items():
            if len(queries) >= 3:
                suggestions.append(
                    ImprovementSuggestion(
                        type="code_pattern",
                        priority="high",
                        description=(
                            f"'{kw}' íŒ¨í„´ í¬í•¨ ì¿¼ë¦¬ {len(queries)}ê°œ ë°˜ë³µ ì‹¤íŒ¨ â†’ "
                            "QueryAnalyzer.INTENT_PATTERNSì— ìƒˆ íŒ¨í„´ ì¶”ê°€ í•„ìš”"
                        ),
                        suggested_value={
                            "action": "add_intent_pattern",
                            "file": "src/rag/infrastructure/query_analyzer.py",
                            "pattern_keyword": kw,
                            "sample_queries": queries[:3],
                        },
                        affected_queries=queries[:5],
                    )
                )
        
        # Pattern 3: Audience-related failures
        # â†’ Indicates audience detection logic issues
        audience_keywords = ["í•™ìƒ", "êµìˆ˜", "êµì›", "ì§ì›", "êµì§ì›"]
        audience_failures = []
        for query in query_groups.keys():
            for kw in audience_keywords:
                if kw in query:
                    audience_failures.append(query)
                    break
        
        if len(audience_failures) >= 2:
            suggestions.append(
                ImprovementSuggestion(
                    type="code_audience",
                    priority="medium",
                    description=(
                        f"ëŒ€ìƒ í‚¤ì›Œë“œ í¬í•¨ ì¿¼ë¦¬ {len(audience_failures)}ê°œ ì‹¤íŒ¨ â†’ "
                        "detect_audience() ë˜ëŠ” AUDIENCE_KEYWORDS í™•ì¥ í•„ìš”"
                    ),
                    suggested_value={
                        "action": "extend_audience_detection",
                        "file": "src/rag/infrastructure/query_analyzer.py",
                        "target": "FACULTY_KEYWORDS, STUDENT_KEYWORDS, STAFF_KEYWORDS",
                    },
                    affected_queries=audience_failures[:5],
                )
            )
        
        # Pattern 4: High failure rate overall
        # â†’ Indicates potential architectural issues
        if len(query_groups) >= 10:
            suggestions.append(
                ImprovementSuggestion(
                    type="architecture",
                    priority="medium",
                    description=(
                        f"ì „ì²´ {len(query_groups)}ê°œ ë¬¸ì œ ì¿¼ë¦¬ ë°œìƒ â†’ "
                        "ê²€ìƒ‰ íŒŒì´í”„ë¼ì¸ ì „ë°˜ ê²€í†  í•„ìš” (HybridSearcher, Reranker)"
                    ),
                    suggested_value={
                        "action": "review_pipeline",
                        "components": [
                            "HybridSearcher (BM25 + Dense ìœµí•©)",
                            "BGEReranker (Cross-Encoder ì¬ì •ë ¬)",
                            "QueryAnalyzer (ì¿¼ë¦¬ ë¶„ì„/í™•ì¥)",
                        ],
                    },
                    affected_queries=list(query_groups.keys())[:10],
                )
            )
        
        return suggestions[:5]

    def suggest_with_llm(self, query: str) -> Optional[ImprovementSuggestion]:
        """
        Use LLM to suggest improvements for a specific query.

        Args:
            query: The problematic query.

        Returns:
            ImprovementSuggestion or None.
        """
        if not self._llm_client:
            return None

        prompt = f"""ë‹¤ìŒ ê²€ìƒ‰ ì¿¼ë¦¬ì— ëŒ€í•´ ì‚¬ìš©ìê°€ ë¶€ì •ì ì¸ í”¼ë“œë°±ì„ ë‚¨ê²¼ìŠµë‹ˆë‹¤.
ê²€ìƒ‰ í’ˆì§ˆì„ ë†’ì´ê¸° ìœ„í•´ ì–´ë–¤ ì¸í…íŠ¸(Intent), ë™ì˜ì–´(Synonym), ë˜ëŠ” ë¦¬ë¼ì´íŒ… ê·œì¹™ì´ í•„ìš”í• ê¹Œìš”?

ì¿¼ë¦¬: "{query}"

## ì œì•ˆ í˜•ì‹ (JSON)
{{
  "intent_trigger": "ì¶”ê°€í•  íŠ¸ë¦¬ê±° ë‹¨ì–´ (ì—†ìœ¼ë©´ null)",
  "synonyms": ["ë‹¨ì–´1", "ë‹¨ì–´2"],
  "reason": "ì œì•ˆ ì´ìœ "
}}"""

        try:
            response = self._llm_client.generate(
                system_prompt="ë‹¹ì‹ ì€ ëŒ€í•™ ê·œì • ê²€ìƒ‰ ì‹œìŠ¤í…œ ê°œì„  ì „ë¬¸ê°€ì…ë‹ˆë‹¤.",
                user_message=prompt,
                temperature=0.3,
            )

            # Parse JSON from response
            import re

            json_match = re.search(r"\{.*\}", response, re.DOTALL)
            if not json_match:
                return ImprovementSuggestion(
                    type="llm_raw",
                    priority="high",
                    description=f"LLM ë¶„ì„: {query}",
                    suggested_value={"llm_response": response},
                    affected_queries=[query],
                )

            data = json.loads(json_match.group())
            desc = f"LLM ì œì•ˆ - {data.get('reason', 'ê²€ìƒ‰ í’ˆì§ˆ ê°œì„ ')}"

            return ImprovementSuggestion(
                type="llm_expert",
                priority="high",
                description=desc,
                suggested_value=data,
                affected_queries=[query],
            )
        except Exception:
            return None

    def format_suggestions(self, result: AnalysisResult) -> str:
        """Format analysis result as readable string."""
        lines = [
            "=" * 60,
            "ìë™ í•™ìŠµ ë¶„ì„ ê²°ê³¼",
            "=" * 60,
            f"ë¶€ì • í”¼ë“œë°± ìˆ˜: {result.total_negative_feedback}",
            f"ë¬¸ì œ ì¿¼ë¦¬ ìˆ˜: {result.unique_problematic_queries}",
            f"ê°œì„  ì œì•ˆ ìˆ˜: {len(result.suggestions)}",
            "-" * 60,
        ]

        if not result.suggestions:
            lines.append("\nâœ… í˜„ì¬ ë¶„ì„ëœ ê°œì„  ì‚¬í•­ì´ ì—†ìŠµë‹ˆë‹¤.")
        else:
            for i, s in enumerate(result.suggestions, 1):
                priority_icon = {
                    "high": "ğŸ”´",
                    "medium": "ğŸŸ¡",
                    "low": "ğŸŸ¢",
                }.get(s.priority, "âšª")
                lines.append(f"\n{priority_icon} [{i}] {s.type.upper()}")
                lines.append(f"   {s.description}")
                if s.affected_queries:
                    lines.append(f"   ì˜í–¥ ì¿¼ë¦¬: {s.affected_queries[:3]}")

        lines.append("\n" + "=" * 60)
        return "\n".join(lines)
