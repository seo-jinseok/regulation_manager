"""
CLI Interface for Regulation RAG System.

Provides command-line tools for:
- Syncing regulations
- Searching regulations
- Asking questions

Usage:
    uv run python -m src.rag.interface.cli sync data/output/ê·œì •ì§‘.json
    uv run python -m src.rag.interface.cli search "êµì› ì—°êµ¬ë…„"
    uv run python -m src.rag.interface.cli ask "êµì› ì—°êµ¬ë…„ ì‹ ì²­ ìê²©ì€?"
"""

import argparse
import os
import sys
from pathlib import Path
from typing import Optional

# Enable readline for better interactive input handling (backspace, arrow keys, etc.)
try:
    import readline  # noqa: F401 - imported for side effects
except ImportError:
    pass  # readline not available on some platforms

# Load .env file
try:
    from dotenv import load_dotenv

    load_dotenv()
except ImportError:
    pass

# Formatters for output formatting
from .chat_logic import (
    attachment_label_variants,
    build_history_context,
    expand_followup_query,
    extract_regulation_title,
    has_explicit_target,
    parse_attachment_request,
)
from .formatters import (
    build_display_path,
    clean_path_segments,
    extract_display_text,
    filter_by_relevance,
    get_confidence_info,
    get_relevance_label_combined,
    infer_attachment_label,
    infer_regulation_title_from_tables,
    normalize_markdown_emphasis,
    normalize_markdown_table,
    normalize_relevance_scores,
    render_full_view_nodes,
    strip_path_prefix,
)
from .query_handler import QueryContext, QueryHandler, QueryOptions, QueryResult, QueryType

# Rich for pretty output (optional)
try:
    from rich.console import Console
    from rich.markdown import Markdown
    from rich.panel import Panel
    from rich.table import Table

    RICH_AVAILABLE = True
    console = Console()
except ImportError:
    RICH_AVAILABLE = False
    console = None


def print_info(msg: str) -> None:
    """Print info message."""
    if RICH_AVAILABLE:
        console.print(f"[blue]â„¹[/blue] {msg}")
    else:
        print(f"[INFO] {msg}")


def print_success(msg: str) -> None:
    """Print success message."""
    if RICH_AVAILABLE:
        console.print(f"[green]âœ“[/green] {msg}")
    else:
        print(f"[OK] {msg}")


def print_error(msg: str) -> None:
    """Print error message."""
    if RICH_AVAILABLE:
        console.print(f"[red]âœ—[/red] {msg}")
    else:
        print(f"[ERROR] {msg}")


def print_query_rewrite(search, original_query: str) -> None:
    """Print query rewrite info when available."""
    info = search.get_last_query_rewrite()
    if not info:
        return

    if RICH_AVAILABLE:
        console.print()
        console.print("[bold cyan]ğŸ”„ ì¿¼ë¦¬ ë¶„ì„ ê²°ê³¼[/bold cyan]")
    else:
        print("\n=== ì¿¼ë¦¬ ë¶„ì„ ê²°ê³¼ ===")

    if not info.used:
        print_info(f"ì¿¼ë¦¬ ë¦¬ë¼ì´íŒ…: (ì ìš© ì•ˆë¨) '{original_query}'")
        return

    # ë°©ë²• í‘œì‹œ
    if info.method == "llm":
        method_label = "LLM ê¸°ë°˜ ë¦¬ë¼ì´íŒ…"
        method_icon = "ğŸ¤–"
    elif info.method == "rules":
        method_label = "ê·œì¹™ ê¸°ë°˜ í™•ì¥"
        method_icon = "ğŸ“‹"
    else:
        method_label = "ì•Œìˆ˜ì—†ìŒ"
        method_icon = "â“"

    # ì¶”ê°€ ìƒíƒœ
    extras = []
    if info.from_cache:
        extras.append("ìºì‹œ íˆíŠ¸")
    if info.fallback:
        extras.append("LLM ì‹¤íŒ¨â†’í´ë°±")
    extra_text = f" ({', '.join(extras)})" if extras else ""

    # ì›ë³¸ â†’ ë³€í™˜ ì¿¼ë¦¬
    if info.original == info.rewritten:
        print_info(f"{method_icon} {method_label}{extra_text}: ë³€ê²½ ì—†ìŒ")
        print_info(f"   ì›ë³¸: '{info.original}'")
    else:
        print_info(f"{method_icon} {method_label}{extra_text}")
        print_info(f"   ì›ë³¸: '{info.original}'")
        print_info(f"   ë³€í™˜: '{info.rewritten}'")

    # ë™ì˜ì–´ ì‚¬ìš© ì—¬ë¶€
    if info.used_synonyms is not None:
        if info.used_synonyms:
            print_info("ğŸ“š ë™ì˜ì–´ ì‚¬ì „: âœ… ì ìš©ë¨ (ìœ ì‚¬ì–´ë¡œ í™•ì¥)")
        else:
            print_info("ğŸ“š ë™ì˜ì–´ ì‚¬ì „: â– ë¯¸ì ìš©")

    # ì¸í…íŠ¸ ì‚¬ìš© ì—¬ë¶€
    if info.used_intent is not None:
        if info.used_intent:
            print_info("ğŸ¯ ì˜ë„ ì¸ì‹: âœ… ë§¤ì¹­ë¨")
            if info.matched_intents:
                intents_str = ", ".join(info.matched_intents)
                print_info(f"   ë§¤ì¹­ëœ ì˜ë„: [{intents_str}]")
        else:
            print_info("ğŸ¯ ì˜ë„ ì¸ì‹: â– ë¯¸ë§¤ì¹­")

    if RICH_AVAILABLE:
        console.print()


def create_parser() -> argparse.ArgumentParser:
    """Create argument parser."""
    providers = ["ollama", "lmstudio", "mlx", "local", "openai", "gemini", "openrouter"]
    default_provider = os.getenv("LLM_PROVIDER") or "ollama"
    if default_provider not in providers:
        default_provider = "ollama"
    default_model = os.getenv("LLM_MODEL") or None
    default_base_url = os.getenv("LLM_BASE_URL") or None
    parser = argparse.ArgumentParser(
        prog="rag",
        description="ê·œì •ì§‘ RAG ì‹œìŠ¤í…œ CLI",
    )
    subparsers = parser.add_subparsers(dest="command", required=True)

    # sync command
    sync_parser = subparsers.add_parser(
        "sync",
        help="ê·œì • ë°ì´í„°ë² ì´ìŠ¤ ë™ê¸°í™”",
    )
    sync_parser.add_argument(
        "json_path",
        type=str,
        help="ê·œì •ì§‘ JSON íŒŒì¼ ê²½ë¡œ",
    )
    sync_parser.add_argument(
        "--full",
        action="store_true",
        help="ì „ì²´ ì¬ë™ê¸°í™” (ê¸°ë³¸: ì¦ë¶„ ë™ê¸°í™”)",
    )
    sync_parser.add_argument(
        "--db-path",
        type=str,
        default="data/chroma_db",
        help="ChromaDB ì €ì¥ ê²½ë¡œ",
    )

    # search command
    search_parser = subparsers.add_parser(
        "search",
        help="ê·œì • ê²€ìƒ‰ (ìë™ìœ¼ë¡œ ë‹µë³€ ìƒì„± ë˜ëŠ” ë¬¸ì„œ ê²€ìƒ‰)",
        description="ì§ˆë¬¸ì´ë©´ AI ë‹µë³€ì„, í‚¤ì›Œë“œë©´ ë¬¸ì„œ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ìë™ìœ¼ë¡œ ë³´ì—¬ì¤ë‹ˆë‹¤. (í˜¹ì€ -a/-q ì˜µì…˜ìœ¼ë¡œ ê°•ì œ)",
    )
    search_parser.add_argument(
        "query",
        type=str,
        nargs="?",
        help="ê²€ìƒ‰ ì¿¼ë¦¬ ë˜ëŠ” ì§ˆë¬¸",
    )
    search_parser.add_argument(
        "-n",
        "--top-k",
        type=int,
        default=5,
        help="ê²°ê³¼ ê°œìˆ˜ (ê¸°ë³¸: 5)",
    )
    search_parser.add_argument(
        "--include-abolished",
        action="store_true",
        help="íì§€ ê·œì • í¬í•¨ (ê²€ìƒ‰ ëª¨ë“œì¼ ë•Œë§Œ ìœ íš¨)",
    )
    search_parser.add_argument(
        "--db-path",
        type=str,
        default="data/chroma_db",
        help="ChromaDB ì €ì¥ ê²½ë¡œ",
    )
    search_parser.add_argument(
        "--no-rerank",
        action="store_true",
        help="BGE Reranker ë¹„í™œì„±í™”",
    )
    search_parser.add_argument(
        "-v",
        "--verbose",
        action="store_true",
        help="ìƒì„¸ ì •ë³´ ì¶œë ¥",
    )
    search_parser.add_argument(
        "--debug",
        action="store_true",
        help="ë””ë²„ê·¸ ì •ë³´ ì¶œë ¥",
    )
    search_parser.add_argument(
        "--feedback",
        action="store_true",
        help="ê²°ê³¼ì— ëŒ€í•œ í”¼ë“œë°± ë‚¨ê¸°ê¸°",
    )
    search_parser.add_argument(
        "--interactive",
        action="store_true",
        help="ëŒ€í™”í˜• ëª¨ë“œë¡œ ì—°ì† ì§ˆì˜",
    )
    # Unified specific arguments
    mode_group = search_parser.add_mutually_exclusive_group()
    mode_group.add_argument(
        "-a",
        "--answer",
        action="store_true",
        help="AI ë‹µë³€ ìƒì„± ê°•ì œ (Ask ëª¨ë“œ)",
    )
    mode_group.add_argument(
        "-q",
        "--quick",
        action="store_true",
        help="ë¬¸ì„œ ê²€ìƒ‰ë§Œ ìˆ˜í–‰ (Search ëª¨ë“œ)",
    )
    # LLM options for when answer is triggered
    search_parser.add_argument(
        "--provider",
        type=str,
        default=default_provider,
        choices=providers,
        help="LLM í”„ë¡œë°”ì´ë” (ë‹µë³€ ìƒì„± ì‹œ)",
    )
    search_parser.add_argument(
        "--model",
        type=str,
        default=default_model,
        help="ëª¨ë¸ ì´ë¦„",
    )
    search_parser.add_argument(
        "--base-url",
        type=str,
        default=default_base_url,
        help="ë¡œì»¬ ì„œë²„ URL",
    )
    search_parser.add_argument(
        "--show-sources",
        action="store_true",
        help="ê´€ë ¨ ê·œì • ì „ë¬¸ ì¶œë ¥ (ë‹µë³€ ìƒì„± ì‹œ)",
    )

    # ask command (Legacy Wrapper)
    ask_parser = subparsers.add_parser(
        "ask",
        help="ê·œì • ì§ˆë¬¸ (search -aì™€ ë™ì¼)",
    )
    ask_parser.add_argument(
        "query",
        type=str,
        help="ì§ˆë¬¸",
    )
    ask_parser.add_argument(
        "-n",
        "--top-k",
        type=int,
        default=5,
        help="ì°¸ê³  ê·œì • ìˆ˜",
    )
    ask_parser.add_argument(
        "--db-path",
        type=str,
        default="data/chroma_db",
        help="ChromaDB ì €ì¥ ê²½ë¡œ",
    )
    ask_parser.add_argument(
        "--provider",
        type=str,
        default=default_provider,
        choices=providers,
        help="LLM í”„ë¡œë°”ì´ë” (ollama, lmstudio, mlx, local, openai, gemini, openrouter)",
    )
    ask_parser.add_argument(
        "--model",
        type=str,
        default=default_model,
        help="ëª¨ë¸ ì´ë¦„ (ê¸°ë³¸: í”„ë¡œë°”ì´ë”ë³„ ê¸°ë³¸ê°’)",
    )
    ask_parser.add_argument(
        "--base-url",
        type=str,
        default=default_base_url,
        help="ë¡œì»¬ ì„œë²„ URL (ollama, lmstudio, mlx, localìš©)",
    )
    ask_parser.add_argument(
        "--show-sources",
        action="store_true",
        help="ê´€ë ¨ ê·œì • ì „ë¬¸ ì¶œë ¥",
    )
    ask_parser.add_argument(
        "--no-rerank",
        action="store_true",
        help="BGE Reranker ë¹„í™œì„±í™” (ê¸°ë³¸: reranking ì‚¬ìš©)",
    )
    ask_parser.add_argument(
        "-v",
        "--verbose",
        action="store_true",
        help="ìƒì„¸ ì •ë³´ ì¶œë ¥ (LLM ì„¤ì •, ì¸ë±ìŠ¤ êµ¬ì¶• í˜„í™© ë“±)",
    )
    ask_parser.add_argument(
        "--debug",
        action="store_true",
        help="ë””ë²„ê·¸ ì •ë³´ ì¶œë ¥ (ì¿¼ë¦¬ ë¦¬ë¼ì´íŒ… ë“±)",
    )
    ask_parser.add_argument(
        "--feedback",
        action="store_true",
        help="ê²°ê³¼ì— ëŒ€í•œ í”¼ë“œë°± ë‚¨ê¸°ê¸° (ì¸í„°ë™í‹°ë¸Œ)",
    )

    # status command
    status_parser = subparsers.add_parser(
        "status",
        help="ë™ê¸°í™” ìƒíƒœ í™•ì¸",
    )
    status_parser.add_argument(
        "--db-path",
        type=str,
        default="data/chroma_db",
        help="ChromaDB ì €ì¥ ê²½ë¡œ",
    )

    # reset command
    reset_parser = subparsers.add_parser(
        "reset",
        help="ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” (ëª¨ë“  ë°ì´í„° ì‚­ì œ)",
    )
    reset_parser.add_argument(
        "--confirm",
        action="store_true",
        required=True,
        help="ì´ˆê¸°í™” í™•ì¸ (í•„ìˆ˜)",
    )
    reset_parser.add_argument(
        "--db-path",
        type=str,
        default="data/chroma_db",
        help="ChromaDB ì €ì¥ ê²½ë¡œ",
    )

    # synonym command group
    synonym_parser = subparsers.add_parser(
        "synonym",
        help="ë™ì˜ì–´ ê´€ë¦¬ (LLM ê¸°ë°˜ ìë™ ìƒì„± ë° ìˆ˜ë™ ê´€ë¦¬)",
    )
    synonym_subparsers = synonym_parser.add_subparsers(dest="synonym_cmd")

    # synonym suggest <term>
    suggest_parser = synonym_subparsers.add_parser(
        "suggest",
        help="LLMìœ¼ë¡œ ë™ì˜ì–´ í›„ë³´ ìƒì„±",
    )
    suggest_parser.add_argument("term", help="ë™ì˜ì–´ë¥¼ ìƒì„±í•  ìš©ì–´")
    suggest_parser.add_argument(
        "--context",
        default="ëŒ€í•™ ê·œì •",
        help="ìš©ì–´ ë§¥ë½ (ê¸°ë³¸: ëŒ€í•™ ê·œì •)",
    )
    suggest_parser.add_argument(
        "--auto-add",
        action="store_true",
        help="ê²€í†  ì—†ì´ ë°”ë¡œ ì¶”ê°€",
    )
    suggest_parser.add_argument(
        "--provider",
        type=str,
        default=default_provider,
        choices=providers,
        help="LLM í”„ë¡œë°”ì´ë”",
    )
    suggest_parser.add_argument("--model", type=str, default=default_model, help="ëª¨ë¸ëª…")
    suggest_parser.add_argument("--base-url", type=str, default=default_base_url, help="ë¡œì»¬ ì„œë²„ URL")

    # synonym add <term> <synonym>
    add_syn_parser = synonym_subparsers.add_parser("add", help="ë™ì˜ì–´ ìˆ˜ë™ ì¶”ê°€")
    add_syn_parser.add_argument("term", help="ê¸°ì¤€ ìš©ì–´")
    add_syn_parser.add_argument("synonym", help="ì¶”ê°€í•  ë™ì˜ì–´")

    # synonym remove <term> <synonym>
    remove_syn_parser = synonym_subparsers.add_parser("remove", help="ë™ì˜ì–´ ì œê±°")
    remove_syn_parser.add_argument("term", help="ê¸°ì¤€ ìš©ì–´")
    remove_syn_parser.add_argument("synonym", help="ì œê±°í•  ë™ì˜ì–´")

    # synonym list [term]
    list_syn_parser = synonym_subparsers.add_parser("list", help="ë™ì˜ì–´ ëª©ë¡ ì¡°íšŒ")
    list_syn_parser.add_argument("term", nargs="?", help="íŠ¹ì • ìš©ì–´ë§Œ ì¡°íšŒ (ìƒëµ ì‹œ ì „ì²´)")

    return parser


def cmd_sync(args) -> int:
    """Execute sync command."""
    from ..application.sync_usecase import SyncUseCase
    from ..infrastructure.chroma_store import ChromaVectorStore
    from ..infrastructure.json_loader import JSONDocumentLoader

    json_path = Path(args.json_path)
    if not json_path.exists():
        print_error(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {json_path}")
        return 1

    print_info(f"ë°ì´í„°ë² ì´ìŠ¤: {args.db_path}")
    print_info(f"JSON íŒŒì¼: {json_path.name}")

    # Initialize components
    loader = JSONDocumentLoader()
    store = ChromaVectorStore(persist_directory=args.db_path)
    sync = SyncUseCase(loader, store)

    # Execute sync
    if args.full:
        print_info("ì „ì²´ ë™ê¸°í™” ì‹¤í–‰ ì¤‘...")
        result = sync.full_sync(str(json_path))
    else:
        print_info("ì¦ë¶„ ë™ê¸°í™” ì‹¤í–‰ ì¤‘...")
        result = sync.incremental_sync(str(json_path))

    # Print results
    if result.has_errors:
        for error in result.errors:
            print_error(error)
        return 1

    print_success(str(result))
    print_info(f"ì´ ì²­í¬ ìˆ˜: {store.count()}")
    return 0


def _decide_search_mode(args) -> str:
    """Wrapper for shared decide_search_mode."""
    from .common import decide_search_mode

    # Check flags first
    force_mode = None
    if hasattr(args, "answer") and args.answer:
        force_mode = "ask"
    elif hasattr(args, "quick") and args.quick:
        force_mode = "search"

    return decide_search_mode(args.query, force_mode)


def _format_toc(toc: list[str]) -> str:
    if not toc:
        return "ëª©ì°¨ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤."
    return "### ëª©ì°¨\n" + "\n".join([f"- {t}" for t in toc])


def _print_markdown(title: str, text: str) -> None:
    if RICH_AVAILABLE:
        console.print()
        console.print(Panel(Markdown(text), title=title, border_style="green"))
    else:
        print(f"\n=== {title} ===")
        print(text)


def _print_query_result(result: QueryResult, verbose: bool = False) -> None:
    """Print QueryHandler result to CLI."""
    if not result.success:
        print_error(result.content)
        return
    
    if result.type == QueryType.ERROR:
        print_error(result.content)
        return
    
    if result.type == QueryType.CLARIFICATION:
        # Handle clarification requests
        if result.clarification_type == "audience":
            print("ëŒ€ìƒì„ ì„ íƒí•´ì£¼ì„¸ìš”:")
            for opt in result.clarification_options:
                print(f"  - {opt}")
        elif result.clarification_type == "regulation":
            print("ì—¬ëŸ¬ ê·œì •ì´ ë§¤ì¹­ë©ë‹ˆë‹¤. ì„ íƒí•´ì£¼ì„¸ìš”:")
            for i, opt in enumerate(result.clarification_options, 1):
                print(f"  {i}. {opt}")
        return
    
    # Map result types to titles
    title_map = {
        QueryType.OVERVIEW: "ğŸ“‹ ê·œì • ê°œìš”",
        QueryType.ARTICLE: "ğŸ“Œ ì¡°í•­ ì „ë¬¸",
        QueryType.CHAPTER: "ğŸ“‘ ì¥ ì „ë¬¸",
        QueryType.ATTACHMENT: "ğŸ“‹ ë³„í‘œ/ì„œì‹",
        QueryType.FULL_VIEW: "ğŸ“– ê·œì • ì „ë¬¸",
        QueryType.SEARCH: "ğŸ” ê²€ìƒ‰ ê²°ê³¼",
        QueryType.ASK: "ğŸ’¬ AI ë‹µë³€",
    }
    
    title = title_map.get(result.type, "ê²°ê³¼")
    
    # Add regulation info to title if available
    if result.data.get("regulation_title") or result.data.get("title"):
        reg_title = result.data.get("regulation_title") or result.data.get("title")
        title = f"{title} - {reg_title}"
    
    _print_markdown(title, result.content)

def _print_regulation_overview(overview, other_matches: Optional[list] = None) -> None:
    """Print regulation overview in a nice format."""
    from ..domain.entities import RegulationStatus

    if RICH_AVAILABLE:
        # Build content lines
        lines = []

        # Status info
        status_label = "âœ… ì‹œí–‰ì¤‘" if overview.status == RegulationStatus.ACTIVE else "âŒ íì§€"
        lines.append(f"**ìƒíƒœ**: {status_label} | **ì´ ì¡°í•­ ìˆ˜**: {overview.article_count}ê°œ")
        lines.append("")

        # Table of contents
        if overview.chapters:
            lines.append("## ğŸ“– ëª©ì°¨")
            for ch in overview.chapters:
                article_info = f" ({ch.article_range})" if ch.article_range else ""
                lines.append(f"- **{ch.display_no}** {ch.title}{article_info}")
        else:
            lines.append("*(ì¥ êµ¬ì¡° ì—†ì´ ì¡°í•­ìœ¼ë¡œë§Œ êµ¬ì„±ëœ ê·œì •)*")

        # Addenda info
        if overview.has_addenda:
            lines.append("")
            lines.append("ğŸ“ **ë¶€ì¹™** ìˆìŒ")

        # Next action hint
        lines.append("")
        lines.append("---")
        lines.append(f"ğŸ’¡ íŠ¹ì • ì¡°í•­ ê²€ìƒ‰: `{overview.title} ì œNì¡°` ë˜ëŠ” `{overview.rule_code} ì œNì¡°`")

        if other_matches:
            lines.append("")
            lines.append("â“ **í˜¹ì‹œ ë‹¤ìŒ ê·œì •ì„ ì°¾ìœ¼ì…¨ë‚˜ìš”?**")
            for m in other_matches:
                lines.append(f"- {m}")

        content = "\n".join(lines)
        console.print()
        console.print(
            Panel(
                Markdown(content),
                title=f"ğŸ“‹ {overview.title} ({overview.rule_code})",
                border_style="cyan",
            )
        )
    else:
        print(f"\n=== {overview.title} ({overview.rule_code}) ===")
        status_label = "ì‹œí–‰ì¤‘" if overview.status == RegulationStatus.ACTIVE else "íì§€"
        print(f"ìƒíƒœ: {status_label} | ì´ ì¡°í•­ ìˆ˜: {overview.article_count}ê°œ")
        print("\nëª©ì°¨:")
        for ch in overview.chapters:
            article_info = f" ({ch.article_range})" if ch.article_range else ""
            print(f"  - {ch.display_no} {ch.title}{article_info}")
        if overview.has_addenda:
            print("\në¶€ì¹™ ìˆìŒ")
        
        if other_matches:
            print("\nâ“ í˜¹ì‹œ ë‹¤ìŒ ê·œì •ì„ ì°¾ìœ¼ì…¨ë‚˜ìš”?")
            for m in other_matches:
                print(f"  - {m}")


def _find_json_path() -> Optional[str]:
    """Find the regulation JSON file in data/output directory."""
    output_dir = Path("data/output")
    if not output_dir.exists():
        return None
    # Find the first JSON file that looks like a regulation file
    for f in output_dir.iterdir():
        if f.suffix == ".json" and not f.name.endswith("_metadata.json"):
            if f.name != "dummy.json":
                return str(f)
    return None


_BACKSPACE_CHARS = {"\b", "\x7f"}


def _sanitize_query_input(text: Optional[str]) -> str:
    """Normalize user input by applying backspaces and trimming."""
    if text is None:
        return ""
    buffer = []
    for char in str(text):
        if char in _BACKSPACE_CHARS:
            if buffer:
                buffer.pop()
            continue
        if ord(char) < 32 or ord(char) == 127:
            continue
        buffer.append(char)
    return "".join(buffer).strip()


def _append_history(
    state: Optional[dict],
    role: str,
    content: str,
    max_messages: int = 20,
) -> None:
    if not state or not content:
        return
    history = state.setdefault("history", [])
    history.append({"role": role, "content": content})
    if len(history) > max_messages:
        del history[:-max_messages]


def _select_regulation(matches, interactive: bool):
    if not matches:
        return None
    if len(matches) == 1:
        return matches[0]

    print_info("ì—¬ëŸ¬ ê·œì •ì´ ë§¤ì¹­ë©ë‹ˆë‹¤. ë²ˆí˜¸ ë˜ëŠ” ì œëª©ìœ¼ë¡œ ì„ íƒí•´ì£¼ì„¸ìš”.")
    for i, match in enumerate(matches, 1):
        print(f"{i}. {match.title}")

    if not interactive:
        return None

    while True:
        try:
            choice = input("\nì„ íƒ (Enterë¡œ ì·¨ì†Œ): ").strip()
        except (KeyboardInterrupt, EOFError):
            print("\nì·¨ì†Œí•©ë‹ˆë‹¤.")
            return None

        if not choice:
            return None
        if choice.isdigit():
            idx = int(choice)
            if 1 <= idx <= len(matches):
                return matches[idx - 1]
        for match in matches:
            if match.title == choice:
                return match
        print("ì˜¬ë°”ë¥¸ ì„ íƒì´ ì•„ë‹™ë‹ˆë‹¤.")


def _perform_unified_search(
    args,
    force_mode: Optional[str] = None,
    state: Optional[dict] = None,
    interactive: bool = False,
) -> int:
    """Core logic for unified search/ask."""
    from rich.panel import Panel

    from ..application.full_view_usecase import FullViewUseCase
    from ..application.search_usecase import SearchUseCase
    from ..infrastructure.chroma_store import ChromaVectorStore
    from ..infrastructure.json_loader import JSONDocumentLoader
    from ..infrastructure.llm_adapter import LLMClientAdapter

    state = state or {}
    raw_query = _sanitize_query_input(args.query)
    query = raw_query
    context_hint = None
    if interactive and query:
        context_hint = state.get("last_regulation") or state.get("last_query")
        query = expand_followup_query(query, context_hint)
    query = _sanitize_query_input(query)
    if not query:
        if interactive:
            return 0
        print_error("ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        print_info("ğŸ’¡ ì˜ˆì‹œ: uv run regulation search 'íœ´í•™ ì‹ ì²­ ì ˆì°¨'")
        print_info("ğŸ’¡ ì˜ˆì‹œ: uv run regulation search 'êµì› ì—°êµ¬ë…„ ìê²©ì€?' -a")
        return 1
    args.query = query
    history_text = (
        build_history_context(state.get("history", [])) if interactive else ""
    )
    if interactive:
        _append_history(state, "user", raw_query)
    explicit_target = has_explicit_target(raw_query)
    explicit_regulation = extract_regulation_title(raw_query)

    mode = force_mode or _decide_search_mode(args)
    if args.verbose:
        print_info(f"ì‹¤í–‰ ëª¨ë“œ: {mode.upper()} (ì¿¼ë¦¬: '{args.query}')")

    # Check if query is regulation name or code only -> show overview
    import re
    from ..application.search_usecase import REGULATION_ONLY_PATTERN, RULE_CODE_PATTERN

    is_regulation_only = REGULATION_ONLY_PATTERN.match(query) is not None
    is_rule_code_only = RULE_CODE_PATTERN.match(query) is not None

    if is_regulation_only or is_rule_code_only:
        # Use QueryHandler for overview
        handler = QueryHandler()
        result = handler.get_regulation_overview(query)
        
        if result.success:
            _print_query_result(result, args.verbose)
            state["last_regulation"] = result.state_update.get("last_regulation")
            state["last_rule_code"] = result.state_update.get("last_rule_code")
            state["last_query"] = raw_query
            if interactive:
                reg_title = result.data.get("title", query)
                _append_history(
                    state,
                    "assistant",
                    f"{reg_title} ê°œìš”ë¥¼ í‘œì‹œí–ˆìŠµë‹ˆë‹¤.",
                )
            return 0
        # If overview not found, fall through to normal search

    # Check if query targets a specific article (e.g. "Regulation Article 7")
    # This allows showing the full text of the article instead of just a search snippet
    article_match = re.search(r"(?:ì œ)?\s*(\d+)\s*ì¡°", query)
    # Use 'query' here which may have been expanded with context (e.g. "êµì›ì¸ì‚¬ê·œì • 5ì¥")
    target_regulation = explicit_regulation or extract_regulation_title(query)

    if target_regulation and article_match:
        article_no = int(article_match.group(1))
        handler = QueryHandler()
        result = handler.get_article_view(target_regulation, article_no)
        
        if result.type == QueryType.CLARIFICATION:
            # Need user to select regulation
            print("ì—¬ëŸ¬ ê·œì •ì´ ë§¤ì¹­ë©ë‹ˆë‹¤. ì„ íƒí•´ì£¼ì„¸ìš”:")
            for i, opt in enumerate(result.clarification_options, 1):
                print(f"  {i}. {opt}")
            return 0
        
        if result.success:
            _print_query_result(result, args.verbose)
            state["last_regulation"] = result.state_update.get("last_regulation")
            state["last_rule_code"] = result.state_update.get("last_rule_code")
            state["last_query"] = raw_query
            if interactive:
                reg_title = result.data.get("regulation_title", target_regulation)
                _append_history(
                    state,
                    "assistant",
                    f"{reg_title} ì œ{article_no}ì¡° ì „ë¬¸ì„ í‘œì‹œí–ˆìŠµë‹ˆë‹¤.",
                )
            return 0

    # Check if query targets a specific chapter (e.g. "Regulation Chapter 5")
    chapter_match = re.search(r"(?:ì œ)?\s*(\d+)\s*ì¥", query)
    if target_regulation and chapter_match:
        chapter_no = int(chapter_match.group(1))
        handler = QueryHandler()
        result = handler.get_chapter_view(target_regulation, chapter_no)
        
        if result.type == QueryType.CLARIFICATION:
            print("ì—¬ëŸ¬ ê·œì •ì´ ë§¤ì¹­ë©ë‹ˆë‹¤. ì„ íƒí•´ì£¼ì„¸ìš”:")
            for i, opt in enumerate(result.clarification_options, 1):
                print(f"  {i}. {opt}")
            return 0
        
        if result.success:
            _print_query_result(result, args.verbose)
            state["last_regulation"] = result.state_update.get("last_regulation")
            state["last_rule_code"] = result.state_update.get("last_rule_code")
            state["last_query"] = raw_query
            if interactive:
                reg_title = result.data.get("regulation_title", target_regulation)
                chapter_title = result.data.get("chapter_title", "")
                full_title = f"{reg_title} ì œ{chapter_no}ì¥ {chapter_title}".strip()
                _append_history(
                    state,
                    "assistant",
                    f"{full_title} ì „ë¬¸ì„ í‘œì‹œí–ˆìŠµë‹ˆë‹¤.",
                )
            return 0

    attachment_request = parse_attachment_request(
        args.query,
        state.get("last_regulation") if interactive else None,
    )
    if attachment_request:
        reg_query, table_no, label = attachment_request
        handler = QueryHandler()
        result = handler.get_attachment_view(reg_query, label, table_no)
        
        if result.type == QueryType.CLARIFICATION:
            print("ì—¬ëŸ¬ ê·œì •ì´ ë§¤ì¹­ë©ë‹ˆë‹¤. ì„ íƒí•´ì£¼ì„¸ìš”:")
            for i, opt in enumerate(result.clarification_options, 1):
                print(f"  {i}. {opt}")
            return 0
        
        if not result.success:
            print_info(result.content)
            return 0
        
        _print_query_result(result, args.verbose)
        state["last_regulation"] = result.state_update.get("last_regulation")
        state["last_rule_code"] = result.state_update.get("last_rule_code")
        state["last_query"] = raw_query
        if interactive:
            label_text = result.data.get("label", "ë³„í‘œ")
            reg_title = result.data.get("regulation_title", reg_query)
            _append_history(
                state,
                "assistant",
                f"{reg_title} {label_text} ë‚´ìš©ì„ í‘œì‹œí–ˆìŠµë‹ˆë‹¤.",
            )
        return 0

    if mode == "full_view":
        full_view = FullViewUseCase(JSONDocumentLoader())
        matches = full_view.find_matches(args.query)
        selected = _select_regulation(matches, interactive)
        if not selected:
            return 0

        view = full_view.get_full_view(selected.rule_code) or full_view.get_full_view(
            selected.title
        )
        if not view:
            print_error("ê·œì • ì „ë¬¸ì„ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            return 1

        toc_text = _format_toc(view.toc)
        content_text = render_full_view_nodes(view.content)
        addenda_text = render_full_view_nodes(view.addenda)
        detail = f"{toc_text}\n\n### ë³¸ë¬¸\n\n{content_text or 'ë³¸ë¬¸ì´ ì—†ìŠµë‹ˆë‹¤.'}"
        if addenda_text:
            detail += f"\n\n### ë¶€ì¹™\n\n{addenda_text}"

        _print_markdown(f"{view.title} ì „ë¬¸", detail)
        state["last_regulation"] = view.title
        state["last_rule_code"] = view.rule_code
        state["last_query"] = raw_query
        if interactive:
            _append_history(state, "assistant", f"{view.title} ì „ë¬¸ì„ í‘œì‹œí–ˆìŠµë‹ˆë‹¤.")
        return 0

    # Step 1: Check database
    store = ChromaVectorStore(persist_directory=args.db_path)
    if store.count() == 0:
        print_error("ë°ì´í„°ë² ì´ìŠ¤ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. ë¨¼ì € syncë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")
        return 1

    use_reranker = not args.no_rerank
    
    # Step 1.5: Tool Calling Mode (FunctionGemma-style)
    if getattr(args, "use_tools", False):
        from ..infrastructure.function_gemma_adapter import FunctionGemmaAdapter
        from ..infrastructure.tool_executor import ToolExecutor
        from ..infrastructure.query_analyzer import QueryAnalyzer
        from ..application.search_usecase import SearchUseCase
        
        if RICH_AVAILABLE:
            console.print("[bold blue]ğŸ”§ Tool Calling ëª¨ë“œ í™œì„±í™”[/bold blue]")
        
        # Initialize components
        search_usecase = SearchUseCase(store, use_reranker=use_reranker)
        query_analyzer = QueryAnalyzer()
        tool_executor = ToolExecutor(
            search_usecase=search_usecase,
            query_analyzer=query_analyzer,
        )
        
        tool_mode = getattr(args, "tool_mode", "auto")
        adapter = FunctionGemmaAdapter(
            tool_executor=tool_executor,
            api_mode=tool_mode,
        )
        
        if RICH_AVAILABLE:
            console.print(f"[dim]API ëª¨ë“œ: {adapter._api_mode}[/dim]")
            console.print()
            
            with console.status("[bold blue]ğŸ¤– Tool Callingìœ¼ë¡œ ì²˜ë¦¬ ì¤‘...[/bold blue]"):
                try:
                    answer_text, tool_results = adapter.process_query(query)
                except Exception as e:
                    print_error(f"Tool Calling ì‹¤íŒ¨: {e}")
                    return 1
            
            # Display results
            console.print("[bold green]ğŸ¤– AI ë‹µë³€:[/bold green]")
            console.print()
            console.print(Markdown(answer_text))
            console.print()
            
            if tool_results:
                console.print("[bold cyan]ğŸ“Š í˜¸ì¶œëœ ë„êµ¬:[/bold cyan]")
                for result in tool_results:
                    status = "âœ…" if result.success else "âŒ"
                    console.print(f"  {status} {result.tool_name}")
        else:
            print("ğŸ¤– Tool Calling ëª¨ë“œë¡œ ì²˜ë¦¬ ì¤‘...")
            try:
                answer_text, tool_results = adapter.process_query(query)
            except Exception as e:
                print_error(f"Tool Calling ì‹¤íŒ¨: {e}")
                return 1
            
            print("\n=== AI ë‹µë³€ ===")
            print(answer_text)
            print("\nğŸ“Š í˜¸ì¶œëœ ë„êµ¬:")
            for result in tool_results:
                status = "âœ…" if result.success else "âŒ"
                print(f"  {status} {result.tool_name}")
        
        return 0

    # Initialize LLM only if needed
    llm = None
    if mode == "ask":
        if RICH_AVAILABLE:
            with console.status(
                "[bold blue]â³ LLM í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì¤‘...[/bold blue]"
            ):
                try:
                    llm = LLMClientAdapter(
                        provider=args.provider,
                        model=args.model,
                        base_url=args.base_url,
                    )
                except Exception as e:
                    print_error(f"LLM ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                    return 1
        else:
            try:
                llm = LLMClientAdapter(
                    provider=args.provider,
                    model=args.model,
                    base_url=args.base_url,
                )
            except Exception as e:
                print_error(f"LLM ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                return 1

    # Step 2: Build Search Interface
    # SearchUseCase initializes HybridSearcher automatically
    if RICH_AVAILABLE:
        status_msg = "[bold blue]ğŸ” ê²€ìƒ‰ ì—”ì§„ ì¤€ë¹„ ì¤‘...[/bold blue]"
        with console.status(status_msg):
            search = SearchUseCase(store, llm_client=llm, use_reranker=use_reranker)
    else:
        search = SearchUseCase(store, llm_client=llm, use_reranker=use_reranker)

    # Step 3: Execute Logic based on Mode
    if mode == "search":
        # Retrieval Only
        results = search.search_unique(
            args.query,
            top_k=args.top_k,
            include_abolished=args.include_abolished
            if hasattr(args, "include_abolished")
            else False,
        )

        if args.verbose or args.debug:
            print_query_rewrite(search, args.query)

        if not results:
            print_info("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return 0

        # Check if all results have very low scores (irrelevant query)
        LOW_RELEVANCE_THRESHOLD = 0.05
        max_score = max(r.score for r in results) if results else 0
        if max_score < LOW_RELEVANCE_THRESHOLD:
            print_info("âš ï¸ ì…ë ¥í•˜ì‹  ê²€ìƒ‰ì–´ì™€ ê´€ë ¨ëœ ê·œì •ì„ ì°¾ê¸° ì–´ë µìŠµë‹ˆë‹¤.")
            print_info("ğŸ’¡ ë‹¤ë¥¸ í‚¤ì›Œë“œë¡œ ê²€ìƒ‰í•´ë³´ì„¸ìš”. ì˜ˆ: 'íœ´í•™', 'ë“±ë¡ê¸ˆ', 'ì—°êµ¬ë…„'")
            return 0

        # Display Results (Search Style)
        if RICH_AVAILABLE:
            table = Table(title=f"ê²€ìƒ‰ ê²°ê³¼: '{args.query}'")
            table.add_column("#", style="dim", width=3)
            table.add_column("ê·œì •ëª…", style="cyan")
            table.add_column("ì½”ë“œ", style="magenta")
            table.add_column("ì¡°í•­", style="green")
            table.add_column("ì ìˆ˜", justify="right", style="magenta")

            for i, r in enumerate(results, 1):
                path_segments = (
                    clean_path_segments(r.chunk.parent_path)
                    if r.chunk.parent_path
                    else []
                )
                path = " > ".join(path_segments[-2:]) if path_segments else ""
                reg_title = (
                    r.chunk.parent_path[0] if r.chunk.parent_path else r.chunk.title
                )
                table.add_row(
                    str(i),
                    str(reg_title or r.chunk.rule_code),
                    str(r.chunk.rule_code),
                    str(path or r.chunk.title),
                    f"{r.score:.2f}",
                )
            console.print(table)

            # Print first result detail
            if results:
                top = results[0]
                display_path = build_display_path(
                    top.chunk.parent_path or [],
                    top.chunk.text,
                    top.chunk.title,
                )
                display_text = strip_path_prefix(
                    top.chunk.text, top.chunk.parent_path or []
                )
                if display_text != top.chunk.text and display_path:
                    detail_text = f"{display_path}\n{display_text}"
                else:
                    detail_text = display_text
                if len(detail_text) > 500:
                    detail_text = detail_text[:500] + "..."
                console.print(
                    Panel(
                        detail_text,
                        title=f"[1ìœ„] {top.chunk.rule_code}",
                        border_style="green",
                    )
                )
        else:
            print(f"\nê²€ìƒ‰ ê²°ê³¼: '{args.query}'")
            print("-" * 60)
            for i, r in enumerate(results, 1):
                reg_title = (
                    r.chunk.parent_path[0] if r.chunk.parent_path else r.chunk.title
                )
                display_text = strip_path_prefix(
                    r.chunk.text, r.chunk.parent_path or []
                )
                print(f"{i}. {reg_title} [{r.chunk.rule_code}] (ì ìˆ˜: {r.score:.2f})")
                print(f"   {display_text[:100]}...")

        if args.feedback and results:
            _collect_cli_feedback(args.query, results[0].chunk.rule_code)
        if results:
            top = results[0]
            top_regulation = (
                top.chunk.parent_path[0] if top.chunk.parent_path else top.chunk.title
            )
            if explicit_regulation:
                state["last_regulation"] = explicit_regulation
            elif explicit_target or not state.get("last_regulation"):
                state["last_regulation"] = top_regulation
            elif state.get("last_regulation") == top_regulation:
                state["last_regulation"] = top_regulation
            state["last_rule_code"] = top.chunk.rule_code
            state["last_query"] = raw_query
            if interactive:
                summary_text = strip_path_prefix(
                    top.chunk.text, top.chunk.parent_path or []
                )
                summary = f"ê²€ìƒ‰ ê²°ê³¼ 1ìœ„: {top.chunk.rule_code} {summary_text}".strip()
                _append_history(state, "assistant", summary)

    else:
        # Ask (LLM Answer) - Streaming by default
        if RICH_AVAILABLE:
            from rich.live import Live
            from rich.text import Text
            
            # Show step-by-step progress
            console.print("[dim]ğŸ” 1/3 ê·œì • ê²€ìƒ‰ ì¤‘...[/dim]")
            console.print("[dim]ğŸ¯ 2/3 ê´€ë ¨ë„ ì¬ì •ë ¬ ì¤‘...[/dim]")
            console.print("[dim]ğŸ¤– 3/3 AI ë‹µë³€ ìƒì„± ì¤‘...[/dim]")
            console.print()
            
            try:
                # Use streaming API
                stream_gen = search.ask_stream(
                    question=raw_query,
                    top_k=args.top_k,
                    history_text=history_text or None,
                    search_query=query,
                )
                
                sources = []
                confidence = 0.0
                answer_text = ""
                
                # First yield is metadata
                first_item = next(stream_gen)
                if first_item.get("type") == "metadata":
                    sources = first_item.get("sources", [])
                    confidence = first_item.get("confidence", 0.0)
                
                # Stream tokens with Live display
                console.print("[bold green]ğŸ¤– AI ë‹µë³€:[/bold green]")
                console.print()
                
                with Live(Text(""), console=console, refresh_per_second=10) as live:
                    for item in stream_gen:
                        if item.get("type") == "token":
                            token = item.get("content", "")
                            answer_text += token
                            # Update live display with accumulated text
                            live.update(Markdown(answer_text))
                
                console.print()
                
            except Exception as e:
                print_error(f"ë‹µë³€ ìƒì„± ì‹¤íŒ¨: {e}")
                return 1
            
            # Create Answer object for consistent handling
            from ..domain.entities import SearchResult
            answer = type('Answer', (), {
                'text': answer_text,
                'sources': sources,
                'confidence': confidence,
            })()
            
        else:
            print("ğŸ” 1/3 ê·œì • ê²€ìƒ‰ ì¤‘...")
            print("ğŸ¯ 2/3 ê´€ë ¨ë„ ì¬ì •ë ¬ ì¤‘...")
            print("ğŸ¤– 3/3 AI ë‹µë³€ ìƒì„± ì¤‘...")
            try:
                # Fallback to non-streaming for non-Rich terminals
                answer = search.ask(
                    question=raw_query,
                    top_k=args.top_k,
                    history_text=history_text or None,
                    search_query=query,
                    debug=args.debug,
                )
            except Exception as e:
                print_error(f"ë‹µë³€ ìƒì„± ì‹¤íŒ¨: {e}")
                return 1

        if args.verbose or args.debug:
            print_query_rewrite(search, args.query)

        answer_text = normalize_markdown_emphasis(answer.text)

        # Display sources with numbered references
        if RICH_AVAILABLE and answer.sources:
            console.print()
            console.print("[bold cyan]ğŸ“š ì°¸ê³  ê·œì •:[/bold cyan]")

            # Shared formatting logic
            norm_scores = normalize_relevance_scores(answer.sources)
            display_sources = filter_by_relevance(answer.sources, norm_scores)

            for i, result in enumerate(display_sources, 1):
                chunk = result.chunk
                reg_name = (
                    chunk.parent_path[0] if chunk.parent_path else chunk.title
                )
                path = build_display_path(
                    chunk.parent_path, chunk.text, chunk.title
                )
                norm_score = norm_scores.get(chunk.id, 0.0)
                rel_score = int(norm_score * 100)
                rel_label = get_relevance_label_combined(rel_score)
                display_text = extract_display_text(chunk.text)

                content_parts = [
                    f"[bold blue]ğŸ“– {reg_name}[/bold blue]",
                    f"[dim]ğŸ“ {path}[/dim]",
                    "",
                    display_text,
                    "",
                    f"[dim]ğŸ“‹ ê·œì •ë²ˆí˜¸: {chunk.rule_code} | ê´€ë ¨ë„: {rel_score}% {rel_label}[/dim]"
                    + (
                        f" [dim]| AI ì‹ ë¢°ë„: {result.score:.3f}[/dim]"
                        if args.verbose
                        else ""
                    ),
                ]

                console.print(
                    Panel(
                        "\n".join(content_parts),
                        title=f"[{i}]",
                        border_style="blue",
                    )
                )

            # Confidence Info
            console.print()
            conf_icon, conf_label, conf_detail = get_confidence_info(answer.confidence)
            console.print(
                Panel(
                    f"[bold]{conf_icon} {conf_label}[/bold] (ì‹ ë¢°ë„ {answer.confidence:.0%})\n\n{conf_detail}",
                    title="ğŸ“Š ë‹µë³€ ì‹ ë¢°ë„",
                    border_style="dim",
                )
            )
            
            # Interactive: Allow user to view full regulation by entering number
            if interactive and display_sources:
                console.print()
                console.print("[dim]ğŸ‘‰ ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ë©´ í•´ë‹¹ ê·œì • ì „ë¬¸ì„ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤ (Enter: ê±´ë„ˆë›°ê¸°)[/dim]")
                try:
                    choice = input().strip()
                    if choice.isdigit():
                        idx = int(choice)
                        if 1 <= idx <= len(display_sources):
                            selected_chunk = display_sources[idx - 1].chunk
                            # Show full regulation
                            from ..application.full_view_usecase import FullViewUseCase
                            from ..infrastructure.json_loader import JSONDocumentLoader
                            full_view_uc = FullViewUseCase(JSONDocumentLoader())
                            view = full_view_uc.get_full_view(selected_chunk.rule_code)
                            if view:
                                toc_text = _format_toc(view.toc)
                                content_text = render_full_view_nodes(view.content)
                                detail = f"{toc_text}\n\n### ë³¸ë¬¸\n\n{content_text or 'ë³¸ë¬¸ì´ ì—†ìŠµë‹ˆë‹¤.'}"
                                _print_markdown(f"{view.title} ì „ë¬¸", detail)
                            else:
                                print_info(f"ê·œì • ì „ë¬¸ì„ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                except (KeyboardInterrupt, EOFError):
                    pass

        elif not RICH_AVAILABLE:
            print("\n=== AI ë‹µë³€ ===")
            print(answer_text)
            print("\n=== ì°¸ê³  ê·œì • ===")
            for i, result in enumerate(answer.sources, 1):
                print(f"[{i}] {result.chunk.rule_code}: {result.chunk.text[:100]}...")

            if getattr(args, "show_sources", False):
                print("\n=== ê·œì • ì „ë¬¸ ===")
                for result in answer.sources:
                    print(f"\n--- {result.chunk.rule_code} ---")
                    print(result.chunk.text)

        if args.feedback and answer.sources:
            _collect_cli_feedback(args.query, answer.sources[0].chunk.rule_code)
        if answer.sources:
            top = answer.sources[0].chunk
            top_regulation = top.parent_path[0] if top.parent_path else top.title
            if explicit_regulation:
                state["last_regulation"] = explicit_regulation
            elif explicit_target or not state.get("last_regulation"):
                state["last_regulation"] = top_regulation
            elif state.get("last_regulation") == top_regulation:
                state["last_regulation"] = top_regulation
            state["last_rule_code"] = top.rule_code
        state["last_query"] = raw_query
        if interactive:
            _append_history(state, "assistant", answer_text)

    return 0


def cmd_search(args) -> int:
    """Execute search command (Unified)."""
    if getattr(args, "interactive", False):
        return _run_interactive_session(args)
    return _perform_unified_search(args)


def cmd_ask(args) -> int:
    """Execute ask command (Legacy Wrapper)."""
    # Map 'question' arg to 'query' expected by unified logic
    if hasattr(args, "question"):
        args.query = args.question
    return _perform_unified_search(args, force_mode="ask")


def _run_interactive_session(args) -> int:
    """Run an interactive CLI session with conversational turns."""
    from .query_suggestions import (
        format_examples_for_cli,
        format_suggestions_for_cli,
        get_followup_suggestions,
        get_initial_examples,
    )

    state = {
        "last_regulation": None,
        "last_rule_code": None,
        "last_query": None,
        "history": [],
    }

    # í˜„ì¬ ì„ íƒ ê°€ëŠ¥í•œ ì˜ˆì‹œ/ì œì•ˆ ëª©ë¡
    current_suggestions = get_initial_examples()

    # ì‹œì‘ ì‹œ ì¿¼ë¦¬ ì˜ˆì‹œ í‘œì‹œ
    print_info("ëŒ€í™”í˜• ëª¨ë“œì…ë‹ˆë‹¤. ì•„ë˜ ì˜ˆì‹œ ì¤‘ ë²ˆí˜¸ë¥¼ ì„ íƒí•˜ê±°ë‚˜ ì§ì ‘ ì§ˆë¬¸í•˜ì„¸ìš”.\n")
    print(format_examples_for_cli(current_suggestions))
    print("\n  '/exit' ì¢…ë£Œ, '/reset' ë¬¸ë§¥ ì´ˆê¸°í™”, '/help' ë„ì›€ë§\n")

    prompt = ">>> "
    query = (args.query or "").strip()

    while True:
        if not query:
            try:
                query = input(prompt).strip()
            except (KeyboardInterrupt, EOFError):
                print("\nì¢…ë£Œí•©ë‹ˆë‹¤.")
                return 0

        # ë²ˆí˜¸ ì…ë ¥ ì²˜ë¦¬
        if query.isdigit():
            idx = int(query) - 1
            if 0 <= idx < len(current_suggestions):
                query = current_suggestions[idx]
                print(f"  â†’ {query}")
            else:
                print_error(f"1~{len(current_suggestions)} ì‚¬ì´ì˜ ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
                query = ""
                continue

        if query.lower() in ("/exit", "exit", "quit", "q"):
            print("ì¢…ë£Œí•©ë‹ˆë‹¤.")
            return 0
        if query.lower() in ("/reset", "reset"):
            state["last_regulation"] = None
            state["last_rule_code"] = None
            state["last_query"] = None
            state["history"] = []
            current_suggestions = get_initial_examples()
            print_info("ë¬¸ë§¥ì„ ì´ˆê¸°í™”í–ˆìŠµë‹ˆë‹¤.\n")
            print(format_examples_for_cli(current_suggestions))
            query = ""
            continue
        if query.lower() in ("/help", "help"):
            print("ëª…ë ¹ì–´: /exit, /reset, /help")
            print("ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ë©´ í•´ë‹¹ ì˜ˆì‹œ/ì œì•ˆì„ ì‹¤í–‰í•©ë‹ˆë‹¤.")
            query = ""
            continue

        # Sanitize and validate query before passing to search
        sanitized = _sanitize_query_input(query)
        if not sanitized:
            query = ""
            continue
        args.query = sanitized
        _perform_unified_search(args, state=state, interactive=True)

        # í›„ì† ì¿¼ë¦¬ ì œì•ˆ
        followups = get_followup_suggestions(
            sanitized,
            regulation_title=state.get("last_regulation"),
        )
        if followups:
            current_suggestions = followups
            print(format_suggestions_for_cli(followups))
        else:
            # ì œì•ˆì´ ì—†ìœ¼ë©´ ê¸°ë³¸ ì˜ˆì‹œë¡œ ë³µê·€
            current_suggestions = get_initial_examples()

        query = ""


def _collect_cli_feedback(query: str, rule_code: str):
    """Interactively collect feedback from CLI."""
    from ..infrastructure.feedback import FeedbackCollector

    print("\n" + "=" * 30)
    print("ğŸ“¢ ì´ ë‹µë³€ì´ ë„ì›€ì´ ë˜ì—ˆë‚˜ìš”?")
    print("1: ğŸ‘ ë„ì›€ì´ ë¨ (Positive)")
    print("2: ğŸ˜ ë³´í†µ (Neutral)")
    print("3: ğŸ‘ ë„ì›€ì´ ì•ˆ ë¨ (Negative)")
    print("0: ê±´ë„ˆë›°ê¸°")

    try:
        choice = input("\nì„ íƒ (0-3): ").strip()
        if choice == "0" or not choice:
            return

        rating_map = {"1": 1, "2": 0, "3": -1}
        if choice not in rating_map:
            print("ì˜¬ë°”ë¥¸ ì„ íƒì´ ì•„ë‹™ë‹ˆë‹¤.")
            return

        rating = rating_map[choice]
        comment = input("ì˜ê²¬ì´ ìˆë‹¤ë©´ ë‚¨ê²¨ì£¼ì„¸ìš” (ì„ íƒì‚¬í•­, Enterë¡œ ìŠ¤í‚µ): ").strip()

        collector = FeedbackCollector()
        collector.record_feedback(
            query=query,
            rule_code=rule_code,
            rating=rating,
            comment=comment or None,
            source="cli",
        )
        print("âœ… ì†Œì¤‘í•œ í”¼ë“œë°± ê°ì‚¬í•©ë‹ˆë‹¤!")
    except (KeyboardInterrupt, EOFError):
        print("\nê±´ë„ˆëœë‹ˆë‹¤.")


def cmd_status(args) -> int:
    """Execute status command."""
    from ..application.sync_usecase import SyncUseCase
    from ..infrastructure.chroma_store import ChromaVectorStore
    from ..infrastructure.json_loader import JSONDocumentLoader

    store = ChromaVectorStore(persist_directory=args.db_path)
    loader = JSONDocumentLoader()
    sync = SyncUseCase(loader, store)

    status = sync.get_sync_status()

    if RICH_AVAILABLE:
        table = Table(title="ë™ê¸°í™” ìƒíƒœ")
        table.add_column("í•­ëª©", style="cyan")
        table.add_column("ê°’", style="green")

        table.add_row("ë§ˆì§€ë§‰ ë™ê¸°í™”", status["last_sync"] or "ì—†ìŒ")
        table.add_row("ğŸ“š ê·œì •ì§‘", status["json_file"] or "ì—†ìŒ")
        table.add_row("ìƒíƒœ íŒŒì¼ ê·œì • ìˆ˜", str(status["state_regulations"]))
        table.add_row("ì €ì¥ëœ ì¡°í•­ ìˆ˜", str(status["store_chunks"]))
        table.add_row("ê·œì • ìˆ˜", str(status["store_regulations"]))

        console.print(table)
    else:
        print("ë™ê¸°í™” ìƒíƒœ")
        print("-" * 40)
        for k, v in status.items():
            print(f"  {k}: {v}")

    return 0


def cmd_reset(args) -> int:
    """Execute reset command - delete all data."""
    from ..application.sync_usecase import SyncUseCase
    from ..infrastructure.chroma_store import ChromaVectorStore
    from ..infrastructure.json_loader import JSONDocumentLoader

    if not args.confirm:
        print_error("ì´ˆê¸°í™”ë¥¼ ìˆ˜í–‰í•˜ë ¤ë©´ --confirm í”Œë˜ê·¸ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.")
        return 1

    store = ChromaVectorStore(persist_directory=args.db_path)
    loader = JSONDocumentLoader()
    sync = SyncUseCase(loader, store)

    # Get current count
    chunk_count = store.count()

    if chunk_count == 0:
        print_info("ë°ì´í„°ë² ì´ìŠ¤ê°€ ì´ë¯¸ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")
        return 0

    print_info(f"ë°ì´í„°ë² ì´ìŠ¤: {args.db_path}")
    print_info(f"ì‚­ì œ ì˜ˆì • ì¡°í•­ ìˆ˜: {chunk_count}")

    # Clear vector store
    deleted = store.clear_all()

    # Clear sync state
    sync.reset_state()

    print_success(f"ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ! {deleted}ê°œ ì¡°í•­ ì‚­ì œë¨")
    return 0


def cmd_synonym(args) -> int:
    """Execute synonym management commands."""
    from ..application.synonym_generator_service import SynonymGeneratorService
    from ..infrastructure.llm_adapter import LLMClientAdapter

    # Handle no subcommand
    if not args.synonym_cmd:
        print_error("synonym ì„œë¸Œì»¤ë§¨ë“œë¥¼ ì§€ì •í•´ì£¼ì„¸ìš”: suggest, add, remove, list")
        print_info("ì˜ˆ: regulation synonym suggest 'ì •ì›'")
        return 1

    # Initialize service (without LLM for non-suggest commands)
    service = SynonymGeneratorService()

    if args.synonym_cmd == "list":
        # List synonyms
        if args.term:
            synonyms = service.get_synonyms(args.term)
            if synonyms:
                print_success(f"'{args.term}'ì˜ ë™ì˜ì–´ ({len(synonyms)}ê°œ):")
                for i, syn in enumerate(synonyms, 1):
                    print(f"  {i}. {syn}")
            else:
                print_info(f"'{args.term}'ì— ëŒ€í•œ ë™ì˜ì–´ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            terms = service.list_terms()
            if terms:
                print_success(f"ë“±ë¡ëœ ìš©ì–´ ({len(terms)}ê°œ):")
                for term in sorted(terms):
                    count = len(service.get_synonyms(term))
                    print(f"  - {term} ({count}ê°œ)")
            else:
                print_info("ë“±ë¡ëœ ë™ì˜ì–´ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return 0

    elif args.synonym_cmd == "add":
        # Add synonym manually
        if service.add_synonym(args.term, args.synonym):
            print_success(f"'{args.synonym}'ì´(ê°€) '{args.term}'ì˜ ë™ì˜ì–´ë¡œ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.")
        else:
            print_info(f"'{args.synonym}'ì€(ëŠ”) ì´ë¯¸ '{args.term}'ì˜ ë™ì˜ì–´ì…ë‹ˆë‹¤.")
        return 0

    elif args.synonym_cmd == "remove":
        # Remove synonym
        if service.remove_synonym(args.term, args.synonym):
            print_success(f"'{args.synonym}'ì´(ê°€) '{args.term}'ì˜ ë™ì˜ì–´ì—ì„œ ì œê±°ë˜ì—ˆìŠµë‹ˆë‹¤.")
        else:
            print_error(f"'{args.synonym}'ì€(ëŠ”) '{args.term}'ì˜ ë™ì˜ì–´ê°€ ì•„ë‹™ë‹ˆë‹¤.")
            return 1
        return 0

    elif args.synonym_cmd == "suggest":
        # Generate synonyms using LLM
        try:
            llm_client = LLMClientAdapter(
                provider=args.provider,
                model=args.model,
                base_url=args.base_url,
            )
            service = SynonymGeneratorService(llm_client=llm_client)
        except Exception as e:
            print_error(f"LLM í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return 1

        # Show existing synonyms if any
        existing = service.get_synonyms(args.term)
        if existing:
            print_info(f"í˜„ì¬ '{args.term}'ì˜ ë™ì˜ì–´ ({len(existing)}ê°œ): {', '.join(existing)}")
            print()

        # Generate candidates
        print_info(f"ğŸ¤– '{args.term}'ì˜ ë™ì˜ì–´ë¥¼ LLMìœ¼ë¡œ ìƒì„± ì¤‘...")
        try:
            candidates = service.generate_synonyms(args.term, context=args.context)
        except Exception as e:
            print_error(f"ë™ì˜ì–´ ìƒì„± ì‹¤íŒ¨: {e}")
            return 1

        if not candidates:
            print_info("ìƒì„±ëœ ë™ì˜ì–´ í›„ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return 0

        print_success(f"ğŸ¤– LLMì´ ì œì•ˆí•˜ëŠ” ë™ì˜ì–´ í›„ë³´ ({len(candidates)}ê°œ):")
        for i, candidate in enumerate(candidates, 1):
            print(f"  {i}. {candidate}")

        # Auto-add mode
        if args.auto_add:
            added = service.add_synonyms(args.term, candidates)
            print_success(f"âœ… {added}ê°œ ë™ì˜ì–´ê°€ ìë™ìœ¼ë¡œ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.")
            return 0

        # Interactive selection
        print()
        print_info("ì¶”ê°€í•  ë™ì˜ì–´ ë²ˆí˜¸ë¥¼ ì„ íƒí•˜ì„¸ìš” (ì‰¼í‘œë¡œ êµ¬ë¶„, ì „ì²´: all, ì·¨ì†Œ: q):")
        try:
            choice = input("> ").strip().lower()
        except (KeyboardInterrupt, EOFError):
            print("\nì·¨ì†Œí•©ë‹ˆë‹¤.")
            return 0

        if choice == "q" or not choice:
            print_info("ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")
            return 0

        if choice == "all":
            selected = candidates
        else:
            selected = []
            for part in choice.split(","):
                part = part.strip()
                if part.isdigit():
                    idx = int(part)
                    if 1 <= idx <= len(candidates):
                        selected.append(candidates[idx - 1])

        if selected:
            added = service.add_synonyms(args.term, selected)
            print_success(f"âœ… {added}ê°œ ë™ì˜ì–´ê°€ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.")
        else:
            print_info("ì¶”ê°€ëœ ë™ì˜ì–´ê°€ ì—†ìŠµë‹ˆë‹¤.")

        return 0

    return 1

def main(argv: Optional[list] = None) -> int:
    """Main entry point."""
    parser = create_parser()
    args = parser.parse_args(argv)

    commands = {
        "sync": cmd_sync,
        "search": cmd_search,
        "ask": cmd_ask,
        "status": cmd_status,
        "reset": cmd_reset,
        "synonym": cmd_synonym,
    }

    if args.command in commands:
        return commands[args.command](args)

    parser.print_help()
    return 1


if __name__ == "__main__":
    sys.exit(main())
