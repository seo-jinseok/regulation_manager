"""
Unified Query Handler for Regulation RAG System.

Provides a single entry point for query processing across all interfaces
(CLI, Web UI, MCP Server) to eliminate code duplication.

Supported query types:
- Overview: Show regulation structure (chapters, article count)
- Article: Show specific article full text
- Chapter: Show specific chapter full text
- Attachment: Show tables (ë³„í‘œ/ë³„ì²¨/ë³„ì§€)
- Full View: Show entire regulation
- Search: Hybrid search with optional reranking
- Ask: LLM-generated answer with sources
"""

import logging
import re
import unicodedata
from dataclasses import dataclass, field
from enum import Enum
from typing import Any, Dict, List, Optional, Tuple

from ..application.full_view_usecase import FullViewUseCase
from ..application.search_usecase import (
    REGULATION_ONLY_PATTERN,
    RULE_CODE_PATTERN,
    SearchUseCase,
)
from ..domain.entities import RegulationStatus
from ..infrastructure.json_loader import JSONDocumentLoader
from ..infrastructure.query_analyzer import Audience, QueryAnalyzer

logger = logging.getLogger(__name__)
from .chat_logic import (
    attachment_label_variants,
    expand_followup_query,
    extract_regulation_title,
    parse_attachment_request,
)
from .common import decide_search_mode
from .formatters import (
    clean_path_segments,
    filter_by_relevance,
    format_regulation_citation,
    format_regulation_content,
    format_search_result_with_explanation,
    infer_attachment_label,
    infer_regulation_title_from_tables,
    normalize_markdown_emphasis,
    normalize_markdown_table,
    normalize_relevance_scores,
    render_full_view_nodes,
    strip_path_prefix,
)
from .query_suggestions import format_suggestions_for_cli, get_followup_suggestions

# Optional FunctionGemma imports
try:
    from ..infrastructure.function_gemma_adapter import FunctionGemmaAdapter
    from ..infrastructure.tool_executor import ToolExecutor

    FUNCTION_GEMMA_AVAILABLE = True
except ImportError:
    FUNCTION_GEMMA_AVAILABLE = False
    FunctionGemmaAdapter = None
    ToolExecutor = None


class QueryType(Enum):
    """Query result types."""

    OVERVIEW = "overview"
    ARTICLE = "article"
    CHAPTER = "chapter"
    ATTACHMENT = "attachment"
    FULL_VIEW = "full_view"
    SEARCH = "search"
    ASK = "ask"
    CLARIFICATION = "clarification"
    ERROR = "error"


@dataclass
class QueryContext:
    """Context for query processing."""

    state: Dict[str, Any] = field(default_factory=dict)
    history: List[Dict[str, str]] = field(default_factory=list)
    interactive: bool = False
    last_regulation: Optional[str] = None
    last_rule_code: Optional[str] = None


@dataclass
class QueryOptions:
    """Options for query processing."""

    top_k: int = 5
    force_mode: Optional[str] = None
    include_abolished: bool = False
    use_rerank: bool = True
    audience_override: Optional[Audience] = None
    show_debug: bool = False
    # LLM options
    llm_provider: Optional[str] = None
    llm_model: Optional[str] = None
    llm_base_url: Optional[str] = None
    # FunctionGemma options
    use_function_gemma: bool = False


@dataclass
class QueryResult:
    """Unified query result."""

    type: QueryType
    success: bool
    # Markdown formatted content for CLI/Web display
    content: str = ""
    # Structured data for MCP/JSON output
    data: Dict[str, Any] = field(default_factory=dict)
    # State updates to apply
    state_update: Dict[str, Any] = field(default_factory=dict)
    # Clarification options (for type=CLARIFICATION)
    clarification_type: Optional[str] = None  # "regulation" | "audience"
    clarification_options: List[str] = field(default_factory=list)
    # Debug info
    debug_info: str = ""
    suggestions: List[str] = field(default_factory=list)


# Deletion warning patterns
DELETION_PATTERNS = [
    (
        re.compile(
            r"ì‚­ì œ\s*[\(\<\[]\s*(\d{4})[.\-/]?\s*(\d{1,2})?[.\-/]?\s*(\d{1,2})?"
        ),
        "ì‚­ì œ",
    ),
    (
        re.compile(
            r"íì§€\s*[\(\<\[]\s*(\d{4})[.\-/]?\s*(\d{1,2})?[.\-/]?\s*(\d{1,2})?"
        ),
        "íì§€",
    ),
    (re.compile(r"\(ì‚­ì œ\)"), "ì‚­ì œ"),
    (re.compile(r"\[ì‚­ì œ\]"), "ì‚­ì œ"),
    (re.compile(r"ë³¸ ì¡°ëŠ”?\s*ì‚­ì œ"), "ì‚­ì œ"),
    (re.compile(r"ë³¸ í•­ì€?\s*ì‚­ì œ"), "ì‚­ì œ"),
]


def detect_deletion_warning(text: str) -> Optional[str]:
    """
    Detect if text contains deletion markers and extract date if available.

    Args:
        text: The chunk text to analyze.

    Returns:
        Warning message if deletion detected, None otherwise.
    """
    for pattern, deletion_type in DELETION_PATTERNS:
        match = pattern.search(text)
        if match:
            groups = match.groups() if match.groups() else ()
            if groups and groups[0]:
                year = groups[0]
                month = groups[1] if len(groups) > 1 and groups[1] else None
                day = groups[2] if len(groups) > 2 and groups[2] else None
                if month and day:
                    return f"âš ï¸ ì´ ì¡°í•­ì€ {year}ë…„ {month}ì›” {day}ì¼ì— {deletion_type}ë˜ì—ˆìŠµë‹ˆë‹¤."
                elif month:
                    return (
                        f"âš ï¸ ì´ ì¡°í•­ì€ {year}ë…„ {month}ì›”ì— {deletion_type}ë˜ì—ˆìŠµë‹ˆë‹¤."
                    )
                else:
                    return f"âš ï¸ ì´ ì¡°í•­ì€ {year}ë…„ì— {deletion_type}ë˜ì—ˆìŠµë‹ˆë‹¤."
            else:
                return f"âš ï¸ ì´ ì¡°í•­ì€ {deletion_type}ë˜ì—ˆìŠµë‹ˆë‹¤. ìµœì‹  ê·œì •ì„ í™•ì¸í•˜ì„¸ìš”."
    return None


class QueryHandler:
    """
    Unified query handler for all interfaces.

    Extracts common logic from CLI's _perform_unified_search and
    Web UI's chat_respond into a single reusable module.
    """

    # Security constants for input validation
    MAX_QUERY_LENGTH = 500
    FORBIDDEN_PATTERNS = [
        r"<script[^>]*>.*?</script>",  # XSS prevention
        r"javascript:",  # JavaScript URL prevention
        r"on\w+\s*=",  # Event handler prevention
        r"DROP\s+TABLE",  # SQL Injection prevention
        r"DELETE\s+FROM",  # SQL Injection prevention
        r"\$\{.*\}",  # Template Injection prevention
        r"<iframe",  # iframe injection prevention
        r"<embed",  # embed tag prevention
    ]

    def __init__(
        self,
        store=None,
        llm_client=None,
        use_reranker: bool = True,
        function_gemma_client=None,
        function_gemma_adapter=None,
        json_path: Optional[str] = None,
    ):
        self.store = store
        self.llm_client = llm_client
        self.use_reranker = use_reranker
        self.loader = JSONDocumentLoader()
        self.full_view_usecase = FullViewUseCase(
            loader=self.loader, json_path=json_path
        )
        self.query_analyzer = QueryAnalyzer()
        self._last_query_rewrite = None

        # FunctionGemma setup
        self._function_gemma_adapter = function_gemma_adapter
        if FUNCTION_GEMMA_AVAILABLE and not self._function_gemma_adapter:
            if function_gemma_client:
                # Check if function_gemma_client is already a FunctionGemmaAdapter
                if hasattr(function_gemma_client, "process_query") and hasattr(
                    function_gemma_client, "_tool_executor"
                ):
                    # It's already an adapter, use it directly
                    self._function_gemma_adapter = function_gemma_client
                else:
                    # It's a raw LLM client, create adapter
                    self._setup_function_gemma(function_gemma_client)

    def _normalize_query(self, query: str) -> str:
        """Normalize input query to NFC for consistent matching."""
        if not query:
            return ""
        return unicodedata.normalize("NFC", query)

    def validate_query(self, query: str) -> Tuple[bool, str]:
        """
        Validate user query for security and format.

        Args:
            query: Query string to validate

        Returns:
            (is_valid, error_message) tuple
            - is_valid: True if validation passed, False otherwise
            - error_message: User-facing error message if validation failed
        """
        # 1. Length validation
        if len(query) > self.MAX_QUERY_LENGTH:
            return False, f"ì¿¼ë¦¬ê°€ ë„ˆë¬´ ê¹ë‹ˆë‹¤ (ìµœëŒ€ {self.MAX_QUERY_LENGTH}ì)"

        # 2. Empty query validation
        if not query or not query.strip():
            return False, "ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”"

        # 3. Security pattern validation
        for pattern in self.FORBIDDEN_PATTERNS:
            if re.search(pattern, query, re.IGNORECASE | re.DOTALL):
                return False, "í—ˆìš©ë˜ì§€ ì•ŠëŠ” ë¬¸ìê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤"

        # 4. Control character validation (except newline, carriage return, tab)
        if any(ord(c) < 32 and c not in "\n\r\t" for c in query):
            return False, "í—ˆìš©ë˜ì§€ ì•ŠëŠ” ì œì–´ ë¬¸ìê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤"

        return True, ""

    def _setup_function_gemma(self, function_gemma_client) -> None:
        """Initialize FunctionGemma adapter with tool executor."""
        from ..application.search_usecase import SearchUseCase
        from ..application.sync_usecase import SyncUseCase
        from ..infrastructure.json_loader import JSONDocumentLoader

        # Create tool executor with use cases
        search_usecase = None
        sync_usecase = None

        if self.store:
            search_usecase = SearchUseCase(
                self.store,
                llm_client=self.llm_client,
                use_reranker=self.use_reranker,
            )
            loader = JSONDocumentLoader()
            sync_usecase = SyncUseCase(loader, self.store)

        tool_executor = ToolExecutor(
            search_usecase=search_usecase,
            sync_usecase=sync_usecase,
            query_analyzer=self.query_analyzer,
            llm_client=self.llm_client,
        )
        logger.debug(f"_setup_function_gemma: Created tool_executor={tool_executor}")

        self._function_gemma_adapter = FunctionGemmaAdapter(
            llm_client=function_gemma_client,
            tool_executor=tool_executor,
        )

    def _process_with_function_gemma(
        self,
        query: str,
        context: QueryContext,
        options: QueryOptions,
    ) -> QueryResult:
        """
        Process query using FunctionGemma tool-based approach.

        FunctionGemma selects and executes tools, then generates
        the final answer using the base LLM.
        """
        try:
            answer, tool_results = self._function_gemma_adapter.process_query(query)

            # Build debug info from tool results
            debug_lines = []
            regulation_title = None

            for result in tool_results:
                status = "âœ…" if result.success else "âŒ"
                debug_msg = f"{status} **{result.tool_name}**"

                if result.arguments:
                    import json

                    try:
                        args_str = json.dumps(result.arguments, ensure_ascii=False)
                        debug_msg += f"\n   ğŸ”¹ Args: `{args_str}`"
                    except Exception:
                        debug_msg += f"\n   ğŸ”¹ Args: {result.arguments}"

                res_str = str(result.result)
                if len(res_str) > 300:
                    res_str = res_str[:300] + "... (truncated)"
                debug_msg += f"\n   ğŸ”¸ Result: {res_str}"

                debug_lines.append(debug_msg)

                # Extract regulation_title from search_regulations results
                if result.tool_name == "search_regulations" and result.success:
                    if isinstance(result.result, dict) and "results" in result.result:
                        for r in result.result["results"]:
                            if r.get("regulation_title"):
                                regulation_title = r["regulation_title"]
                                break

            debug_info = "\n\n".join(debug_lines) if options.show_debug else ""

            return QueryResult(
                type=QueryType.ASK,
                success=True,
                content=answer,
                data={
                    "tool_results": [r.to_dict() for r in tool_results],
                    "used_function_gemma": True,
                    "regulation_title": regulation_title,
                },
                debug_info=debug_info,
            )
        except Exception as e:
            # Fallback to standard processing on error
            return QueryResult(
                type=QueryType.ERROR,
                success=False,
                content=f"FunctionGemma ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}. ê¸°ë³¸ ê²€ìƒ‰ì„ ì‹œë„í•´ì£¼ì„¸ìš”.",
            )

    def process_query(
        self,
        query: str,
        context: Optional[QueryContext] = None,
        options: Optional[QueryOptions] = None,
    ) -> QueryResult:
        """
        Main entry point for query processing.

        Analyzes the query and routes to appropriate handler.
        If use_function_gemma is enabled and adapter is available,
        uses FunctionGemma for tool-based processing.
        """
        context = context or QueryContext()
        options = options or QueryOptions()
        query = self._normalize_query(query)

        # Input validation
        is_valid, error_msg = self.validate_query(query)
        if not is_valid:
            return QueryResult(
                type=QueryType.ERROR,
                success=False,
                content=f"âš ï¸ {error_msg}",
            )

        query = query.strip()

        # 1. Structural Pattern Checks (Prioritize over Tool Calling for consistency)

        # Check for regulation-only or rule-code-only queries first
        if self._is_overview_query(query):
            result = self.get_regulation_overview(query)
            if result.success:
                return self._enrich_with_suggestions(result, query)

        # Check for specific article query (e.g., "êµì›ì¸ì‚¬ê·œì • ì œ8ì¡°")
        article_match = re.search(r"(?:ì œ)?\s*(\d+)\s*ì¡°", query)
        target_regulation = extract_regulation_title(query)

        if target_regulation and article_match:
            article_no = int(article_match.group(1))
            result = self.get_article_view(target_regulation, article_no, context)
            if result.type != QueryType.ERROR:
                return self._enrich_with_suggestions(result, query)

        # Check for chapter query (e.g., "í•™ì¹™ ì œ3ì¥")
        chapter_match = re.search(r"(?:ì œ)?\s*(\d+)\s*ì¥", query)
        if target_regulation and chapter_match:
            chapter_no = int(chapter_match.group(1))
            result = self.get_chapter_view(target_regulation, chapter_no, context)
            if result.type != QueryType.ERROR:
                return self._enrich_with_suggestions(result, query)

        # Check for attachment query (ë³„í‘œ/ë³„ì²¨/ë³„ì§€)
        attachment_request = parse_attachment_request(
            query,
            context.last_regulation if context.interactive else None,
        )
        if attachment_request:
            reg_query, table_no, label = attachment_request
            result = self.get_attachment_view(reg_query, label, table_no, context)
            if result.type != QueryType.ERROR:
                return self._enrich_with_suggestions(result, query)

        # Determine mode using heuristics
        mode = options.force_mode or decide_search_mode(query)

        # Full view mode (e.g., "í•™ì¹™ ì „ë¬¸")
        if mode == "full_view":
            result = self.get_full_view(query, context)
            if result.type != QueryType.ERROR:
                return self._enrich_with_suggestions(result, query)

        # 2. Tool Calling or Traditional Search/Ask

        # FunctionGemma tool-based processing
        if options.use_function_gemma and self._function_gemma_adapter:
            result = self._process_with_function_gemma(query, context, options)
            return self._enrich_with_suggestions(result, query)

        # Check audience ambiguity
        if (
            options.audience_override is None
            and self.query_analyzer.is_audience_ambiguous(query)
        ):
            return QueryResult(
                type=QueryType.CLARIFICATION,
                success=True,
                clarification_type="audience",
                clarification_options=["êµìˆ˜", "í•™ìƒ", "ì§ì›"],
                content="ì§ˆë¬¸ ëŒ€ìƒì„ ì„ íƒí•´ì£¼ì„¸ìš”: êµìˆ˜, í•™ìƒ, ì§ì›",
            )

        # Search or Ask
        if mode == "search":
            result = self.search(query, options)
        else:
            result = self.ask(query, options, context)

        # Enrich with suggestions before returning
        return self._enrich_with_suggestions(result, query)

    def process_query_stream(
        self,
        query: str,
        context: Optional[QueryContext] = None,
        options: Optional[QueryOptions] = None,
    ):
        """
        Streaming version of process_query.
        Yields events: {"type": str, "content": Any, ...}
        """
        context = context or QueryContext()
        options = options or QueryOptions()
        query = self._normalize_query(query)

        # Input validation
        is_valid, error_msg = self.validate_query(query)
        if not is_valid:
            yield {"type": "error", "content": error_msg}
            return

        query = query.strip()

        # 1. Structural Pattern Checks

        # Check for regulation-only or rule-code-only queries first
        if self._is_overview_query(query):
            result = self.get_regulation_overview(query)
            result = self._enrich_with_suggestions(result, query)
            yield from self._yield_result(result)
            return

        # Check for specific article query
        article_match = re.search(r"(?:ì œ)?\s*(\d+)\s*ì¡°", query)
        target_regulation = extract_regulation_title(query)

        if target_regulation and article_match:
            article_no = int(article_match.group(1))
            result = self.get_article_view(target_regulation, article_no, context)
            if result.type != QueryType.ERROR:
                result = self._enrich_with_suggestions(result, query)
                yield from self._yield_result(result)
                return

        # Check for chapter query
        chapter_match = re.search(r"(?:ì œ)?\s*(\d+)\s*ì¥", query)
        if target_regulation and chapter_match:
            chapter_no = int(chapter_match.group(1))
            result = self.get_chapter_view(target_regulation, chapter_no, context)
            if result.type != QueryType.ERROR:
                result = self._enrich_with_suggestions(result, query)
                yield from self._yield_result(result)
                return

        # Check for attachment query
        attachment_request = parse_attachment_request(
            query,
            context.last_regulation if context.interactive else None,
        )
        if attachment_request:
            reg_query, table_no, label = attachment_request
            result = self.get_attachment_view(reg_query, label, table_no, context)
            if result.type != QueryType.ERROR:
                result = self._enrich_with_suggestions(result, query)
                yield from self._yield_result(result)
                return

        # Determine mode
        mode = options.force_mode or decide_search_mode(query)

        # Full view mode
        if mode == "full_view":
            result = self.get_full_view(query, context)
            if result.type != QueryType.ERROR:
                result = self._enrich_with_suggestions(result, query)
                yield from self._yield_result(result)
                return

        # 2. Tool Calling or Traditional Search/Ask

        # FunctionGemma tool-based processing (Sync -> Event Stream)
        if options.use_function_gemma and self._function_gemma_adapter:
            # Yield progress
            yield {"type": "progress", "content": "ğŸ¤– ë„êµ¬ ê¸°ë°˜ ë‹µë³€ ìƒì„± ì¤‘..."}

            # Run synchronously (Tool Calling does not support streaming yet)
            q_result = self._process_with_function_gemma(query, context, options)

            if q_result.success:
                # Enrich with suggestions
                q_result = self._enrich_with_suggestions(q_result, query)

                # Yield usage info
                if q_result.debug_info:
                    yield {
                        "type": "progress",
                        "content": f"ğŸ› ï¸ ì‚¬ìš©ëœ ë„êµ¬:\n{q_result.debug_info}",
                    }

                # Yield final answer
                yield {
                    "type": "complete",
                    "content": q_result.content,
                    "data": q_result.data,
                    "suggestions": q_result.suggestions,
                }
                return
            else:
                yield {"type": "error", "content": q_result.content}
                return

        # Check audience ambiguity
        if (
            options.audience_override is None
            and self.query_analyzer.is_audience_ambiguous(query)
        ):
            yield {
                "type": "clarification",
                "clarification_type": "audience",
                "options": ["êµìˆ˜", "í•™ìƒ", "ì§ì›"],
                "content": "ì§ˆë¬¸ ëŒ€ìƒì„ ì„ íƒí•´ì£¼ì„¸ìš”: êµìˆ˜, í•™ìƒ, ì§ì›",
            }
            return

        # Search or Ask
        if mode == "search":
            # Search is synchronous for now, treat as instant result
            yield {"type": "progress", "content": "ğŸ” ê·œì • ê²€ìƒ‰ ì¤‘..."}
            result = self.search(query, options)
            result = self._enrich_with_suggestions(result, query)
            yield from self._yield_result(result)
        else:
            # Ask - Streaming
            # We can't easily enrich the stream yet without intercepting tokens,
            # but we can yield suggestions at the end.
            for event in self.ask_stream(query, options, context):
                if event.get("type") == "complete":
                    # For completed streaming questions, we can enrich the final content
                    temp_res = QueryResult(
                        type=QueryType.ASK,
                        success=True,
                        content=event["content"],
                        data=event.get("data", {}),
                    )
                    temp_res = self._enrich_with_suggestions(temp_res, query)
                    event["content"] = temp_res.content
                    event["suggestions"] = temp_res.suggestions
                yield event

    def _enrich_with_suggestions(self, result: QueryResult, query: str) -> QueryResult:
        """Calculate and append followup suggestions to result."""
        if result.type in (QueryType.CLARIFICATION, QueryType.ERROR):
            return result

        reg_title = result.data.get("regulation_title") or result.data.get("title")
        suggestions = get_followup_suggestions(
            query=query,
            regulation_title=reg_title,
            answer_text=result.content if result.type == QueryType.ASK else None,
        )

        if suggestions:
            result.suggestions = suggestions
            # Append formatted suggestions to content for standard display
            suggestion_text = format_suggestions_for_cli(suggestions)
            if suggestion_text:
                result.content += "\n\n" + suggestion_text

        return result

    def _yield_result(self, result: QueryResult):
        """Helper to yield a QueryResult as stream events."""
        if result.type == QueryType.CLARIFICATION:
            yield {
                "type": "clarification",
                "clarification_type": result.clarification_type,
                "options": result.clarification_options,
                "content": result.content,
            }
        elif result.type == QueryType.ERROR:
            yield {"type": "error", "content": result.content}
        else:
            # For standard results, we yield metadata then content
            # If state update exists, yield it logic might be handled by caller or here
            # We yield 'answer' or 'complete'
            # Gradio expects 'token' loop or 'complete'
            yield {
                "type": "metadata",
                "rule_code": result.data.get("rule_code"),
                "regulation_title": result.data.get("title")
                or result.data.get("regulation_title"),
            }
            yield {
                "type": "complete",
                "content": result.content,
                "data": result.data,
                "suggestions": result.suggestions,
            }
            if result.state_update:
                yield {"type": "state", "update": result.state_update}

    def ask_stream(
        self,
        question: str,
        options: Optional[QueryOptions] = None,
        context: Optional[QueryContext] = None,
    ):
        """Stream LLM-generated answer."""
        options = options or QueryOptions()
        context = context or QueryContext()

        if self.store is None or self.store.count() == 0 or self.llm_client is None:
            yield {
                "type": "error",
                "content": "ì‹œìŠ¤í…œì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ê±°ë‚˜ DBê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.",
            }
            return

        search_usecase = SearchUseCase(
            self.store,
            llm_client=self.llm_client,
            use_reranker=options.use_rerank,
        )

        # History setup...
        history_text = None
        if context.history:
            history_lines = []
            for msg in context.history[-10:]:
                role = "ì‚¬ìš©ì" if msg.get("role") == "user" else "AI"
                content = msg.get("content", "")
                if content:
                    history_lines.append(f"{role}: {content[:200]}")
            if history_lines:
                history_text = "\n".join(history_lines)

        yield {"type": "progress", "content": "ğŸ” ê·œì • ê²€ìƒ‰ ì¤‘..."}

        # Handle multi-turn context expansion
        search_query = question
        if context.last_regulation:
            expanded = expand_followup_query(question, context.last_regulation)
            if expanded != question:
                search_query = expanded
                if options.show_debug:
                    yield {
                        "type": "progress",
                        "content": f"ğŸ”„ ë¬¸ë§¥ ë°˜ì˜: {search_query}",
                    }

        # Use SearchUseCase.ask_stream
        sources = []
        for event in search_usecase.ask_stream(
            question=question,
            top_k=options.top_k,
            include_abolished=options.include_abolished,
            audience_override=options.audience_override,
            history_text=history_text,
            search_query=search_query,
        ):
            if event.get("type") == "metadata":
                sources = event.get("sources", [])
            yield event

        if sources:
            norm_scores = normalize_relevance_scores(sources)
            display_sources = filter_by_relevance(sources, norm_scores)

            citations_text = ""
            for i, r in enumerate(display_sources, 1):
                citation_block = format_regulation_citation(r.chunk)
                norm_score = norm_scores.get(r.chunk.id, 0.0)
                rel_pct = int(norm_score * 100)

                # Add matching explanation with keywords
                explanation, _ = format_search_result_with_explanation(
                    r, question, show_score=False
                )

                citations_text += (
                    f"\n\n{citation_block}\n*ê´€ë ¨ë„: {rel_pct}%*\n\n"
                    f"**ë§¤ì¹­ ì •ë³´:** {explanation}\n\n---\n"
                )

            if citations_text:
                yield {"type": "token", "content": citations_text}

        self._last_query_rewrite = search_usecase.get_last_query_rewrite()

    def _is_overview_query(self, query: str) -> bool:
        """Check if query is requesting regulation overview."""
        return (
            REGULATION_ONLY_PATTERN.match(query) is not None
            or RULE_CODE_PATTERN.match(query) is not None
        )

    def get_regulation_overview(self, query: str) -> QueryResult:
        """Get regulation overview (structure, chapter count, etc.)."""
        json_path = self.full_view_usecase._resolve_json_path()
        if not json_path:
            return QueryResult(
                type=QueryType.ERROR,
                success=False,
                content="ê·œì • JSON íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
            )

        overview = self.loader.get_regulation_overview(json_path, query)
        if not overview:
            # Try finding candidates
            candidates = self.loader.find_regulation_candidates(json_path, query)
            if len(candidates) == 1:
                # Found exactly one match
                overview = self.loader.get_regulation_overview(
                    json_path, candidates[0][0]
                )
            elif len(candidates) > 1:
                # Multiple matches found
                # Check for exact match (ignoring spaces)
                normalized_query = query.replace(" ", "")
                exact_match = None
                for code, title in candidates:
                    if title.replace(" ", "") == normalized_query:
                        exact_match = (code, title)
                        break

                if exact_match:
                    overview = self.loader.get_regulation_overview(
                        json_path, exact_match[0]
                    )
                else:
                    return QueryResult(
                        type=QueryType.CLARIFICATION,
                        success=True,
                        clarification_type="regulation",
                        clarification_options=[c[1] for c in candidates],
                        content="ì—¬ëŸ¬ ê·œì •ì´ ë§¤ì¹­ë©ë‹ˆë‹¤. ì„ íƒí•´ì£¼ì„¸ìš”.",
                    )
            else:
                return QueryResult(
                    type=QueryType.ERROR,
                    success=False,
                    content="í•´ë‹¹ ê·œì •ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                )

        if not overview:
            return QueryResult(
                type=QueryType.ERROR,
                success=False,
                content="í•´ë‹¹ ê·œì •ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
            )

        # Build markdown content
        status_label = (
            "âœ… ì‹œí–‰ì¤‘" if overview.status == RegulationStatus.ACTIVE else "âŒ íì§€"
        )
        lines = [f"## ğŸ“‹ {overview.title} ({overview.rule_code})"]
        lines.append("")
        lines.append(
            f"**ìƒíƒœ**: {status_label} | **ì´ ì¡°í•­ ìˆ˜**: {overview.article_count}ê°œ"
        )
        lines.append("")

        if overview.chapters:
            lines.append("### ğŸ“– ëª©ì°¨")
            for ch in overview.chapters:
                article_info = f" ({ch.article_range})" if ch.article_range else ""
                lines.append(f"- **{ch.display_no}** {ch.title}{article_info}")
        else:
            lines.append("*(ì¥ êµ¬ì¡° ì—†ì´ ì¡°í•­ìœ¼ë¡œë§Œ êµ¬ì„±ëœ ê·œì •)*")

        if overview.has_addenda:
            lines.append("")
            lines.append("ğŸ“ **ë¶€ì¹™** ìˆìŒ")

        lines.append("")
        lines.append("---")
        lines.append(
            f"ğŸ’¡ íŠ¹ì • ì¡°í•­ ê²€ìƒ‰: `{overview.title} ì œNì¡°` ë˜ëŠ” `{overview.rule_code} ì œNì¡°`"
        )

        # Check for similar regulations
        is_regulation_only = REGULATION_ONLY_PATTERN.match(query) is not None
        other_matches = []
        if is_regulation_only:
            all_titles = self.loader.get_regulation_titles(json_path)
            other_matches = sorted(
                [t for t in all_titles.values() if query in t and t != overview.title]
            )
            if other_matches:
                lines.append("")
                lines.append("â“ **í˜¹ì‹œ ë‹¤ìŒ ê·œì •ì„ ì°¾ìœ¼ì…¨ë‚˜ìš”?**")
                for m in other_matches:
                    lines.append(f"- {m}")

        return QueryResult(
            type=QueryType.OVERVIEW,
            success=True,
            content="\n".join(lines),
            data={
                "title": overview.title,
                "rule_code": overview.rule_code,
                "status": overview.status.value
                if hasattr(overview.status, "value")
                else str(overview.status),
                "article_count": overview.article_count,
                "chapters": [
                    {
                        "display_no": ch.display_no,
                        "title": ch.title,
                        "article_range": ch.article_range,
                    }
                    for ch in (overview.chapters or [])
                ],
                "has_addenda": overview.has_addenda,
                "other_matches": other_matches,
            },
            state_update={
                "last_regulation": overview.title,
                "last_rule_code": overview.rule_code,
            },
        )

    def get_article_view(
        self,
        regulation: str,
        article_no: int,
        context: Optional[QueryContext] = None,
    ) -> QueryResult:
        """Get specific article full text."""
        matches = self.full_view_usecase.find_matches(regulation)

        if not matches:
            return QueryResult(
                type=QueryType.ERROR,
                success=False,
                content="í•´ë‹¹ ê·œì •ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
            )

        if len(matches) > 1:
            return QueryResult(
                type=QueryType.CLARIFICATION,
                success=True,
                clarification_type="regulation",
                clarification_options=[m.title for m in matches],
                content="ì—¬ëŸ¬ ê·œì •ì´ ë§¤ì¹­ë©ë‹ˆë‹¤. ì„ íƒí•´ì£¼ì„¸ìš”.",
            )

        selected = matches[0]
        article_node = self.full_view_usecase.get_article_view(
            selected.rule_code, article_no
        )

        if not article_node:
            return QueryResult(
                type=QueryType.ERROR,
                success=False,
                content=f"{selected.title}ì—ì„œ ì œ{article_no}ì¡°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
            )

        content_text = render_full_view_nodes([article_node])
        content_text = format_regulation_content(content_text)
        full_response = f"## ğŸ“Œ {selected.title} ì œ{article_no}ì¡°\n\n{content_text}"

        return QueryResult(
            type=QueryType.ARTICLE,
            success=True,
            content=full_response,
            data={
                "regulation_title": selected.title,
                "rule_code": selected.rule_code,
                "article_no": article_no,
                "content": content_text,
            },
            state_update={
                "last_regulation": selected.title,
                "last_rule_code": selected.rule_code,
            },
        )

    def get_chapter_view(
        self,
        regulation: str,
        chapter_no: int,
        context: Optional[QueryContext] = None,
    ) -> QueryResult:
        """Get specific chapter full text."""
        matches = self.full_view_usecase.find_matches(regulation)

        if not matches:
            return QueryResult(
                type=QueryType.ERROR,
                success=False,
                content="í•´ë‹¹ ê·œì •ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
            )

        if len(matches) > 1:
            return QueryResult(
                type=QueryType.CLARIFICATION,
                success=True,
                clarification_type="regulation",
                clarification_options=[m.title for m in matches],
                content="ì—¬ëŸ¬ ê·œì •ì´ ë§¤ì¹­ë©ë‹ˆë‹¤. ì„ íƒí•´ì£¼ì„¸ìš”.",
            )

        selected = matches[0]
        json_path = self.full_view_usecase._resolve_json_path()

        if not json_path:
            return QueryResult(
                type=QueryType.ERROR,
                success=False,
                content="ê·œì • JSON íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
            )

        doc = self.loader.get_regulation_doc(json_path, selected.rule_code)
        chapter_node = self.full_view_usecase.get_chapter_node(doc, chapter_no)

        if not chapter_node:
            return QueryResult(
                type=QueryType.ERROR,
                success=False,
                content=f"{selected.title}ì—ì„œ ì œ{chapter_no}ì¥ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
            )

        chapter_title = chapter_node.get("title", "").strip()
        chapter_disp = chapter_node.get("display_no", f"ì œ{chapter_no}ì¥").strip()
        full_title = f"{selected.title} {chapter_disp} {chapter_title}".strip()

        content_text = render_full_view_nodes(chapter_node.get("children", []))
        content_text = format_regulation_content(content_text)
        full_response = f"## ğŸ“‘ {full_title}\n\n{content_text}"

        return QueryResult(
            type=QueryType.CHAPTER,
            success=True,
            content=full_response,
            data={
                "regulation_title": selected.title,
                "rule_code": selected.rule_code,
                "chapter_no": chapter_no,
                "chapter_title": chapter_title,
                "content": content_text,
            },
            state_update={
                "last_regulation": selected.title,
                "last_rule_code": selected.rule_code,
            },
        )

    def get_attachment_view(
        self,
        regulation: str,
        label: Optional[str] = None,
        table_no: Optional[int] = None,
        context: Optional[QueryContext] = None,
    ) -> QueryResult:
        """Get attachment (ë³„í‘œ/ë³„ì²¨/ë³„ì§€) content."""
        matches = self.full_view_usecase.find_matches(regulation)

        if not matches:
            return QueryResult(
                type=QueryType.ERROR,
                success=False,
                content="í•´ë‹¹ ê·œì •ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
            )

        if len(matches) > 1:
            return QueryResult(
                type=QueryType.CLARIFICATION,
                success=True,
                clarification_type="regulation",
                clarification_options=[m.title for m in matches],
                content="ì—¬ëŸ¬ ê·œì •ì´ ë§¤ì¹­ë©ë‹ˆë‹¤. ì„ íƒí•´ì£¼ì„¸ìš”.",
            )

        selected = matches[0]
        label_variants = attachment_label_variants(label)
        tables = self.full_view_usecase.find_tables(
            selected.rule_code, table_no, label_variants
        )

        if not tables:
            label_text = label or "ë³„í‘œ"
            return QueryResult(
                type=QueryType.ERROR,
                success=False,
                content=f"{label_text}ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
            )

        display_title = infer_regulation_title_from_tables(tables, selected.title)
        label_text = label or "ë³„í‘œ"

        # Build content
        lines = []
        for idx, table in enumerate(tables, 1):
            path = clean_path_segments(table.path) if table.path else []
            heading = " > ".join(path) if path else table.title or label_text
            if table_no:
                table_label = f"{label_text} {table_no}"
            else:
                table_label = infer_attachment_label(table, label_text)
            lines.append(f"### [{idx}] {heading} ({table_label})")
            if table.text:
                lines.append(table.text)
            lines.append(normalize_markdown_table(table.markdown).strip())

        title_label = f"{display_title} {label_text}"
        if table_no:
            title_label = f"{display_title} {label_text} {table_no}"

        full_response = f"## ğŸ“‹ {title_label}\n\n" + "\n\n".join(lines)

        return QueryResult(
            type=QueryType.ATTACHMENT,
            success=True,
            content=full_response,
            data={
                "regulation_title": display_title,
                "rule_code": selected.rule_code,
                "label": label_text,
                "table_no": table_no,
                "tables": [
                    {
                        "path": clean_path_segments(t.path) if t.path else [],
                        "text": t.text,
                        "markdown": t.markdown,
                    }
                    for t in tables
                ],
            },
            state_update={
                "last_regulation": display_title,
                "last_rule_code": selected.rule_code,
            },
        )

    def get_full_view(
        self,
        query: str,
        context: Optional[QueryContext] = None,
    ) -> QueryResult:
        """Get full regulation text."""
        matches = self.full_view_usecase.find_matches(query)

        if not matches:
            return QueryResult(
                type=QueryType.ERROR,
                success=False,
                content="í•´ë‹¹ ê·œì •ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
            )

        if len(matches) > 1:
            return QueryResult(
                type=QueryType.CLARIFICATION,
                success=True,
                clarification_type="regulation",
                clarification_options=[m.title for m in matches],
                content="ì—¬ëŸ¬ ê·œì •ì´ ë§¤ì¹­ë©ë‹ˆë‹¤. ì„ íƒí•´ì£¼ì„¸ìš”.",
            )

        selected = matches[0]
        view = self.full_view_usecase.get_full_view(
            selected.rule_code
        ) or self.full_view_usecase.get_full_view(selected.title)

        if not view:
            return QueryResult(
                type=QueryType.ERROR,
                success=False,
                content="ê·œì • ì „ë¬¸ì„ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.",
            )

        # Build TOC
        toc_text = (
            "### ëª©ì°¨\n" + "\n".join([f"- {t}" for t in view.toc])
            if view.toc
            else "ëª©ì°¨ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤."
        )

        content_text = render_full_view_nodes(view.content)
        content_text = format_regulation_content(content_text)

        # Abbreviate addenda if there are many items (e.g., historical changes)
        addenda_text = render_full_view_nodes(view.addenda, max_items=10)
        addenda_text = format_regulation_content(addenda_text)

        full_content = f"## ğŸ“– {view.title}\n\n{toc_text}\n\n---\n\n### ë³¸ë¬¸\n\n{content_text or 'ë³¸ë¬¸ì´ ì—†ìŠµë‹ˆë‹¤.'}"
        if addenda_text:
            # Avoid redundant "ë¶€ì¹™" title if rendered text already starts with one
            if re.match(r"^#+\s*ë¶€\s*ì¹™", addenda_text.strip()):
                full_content += f"\n\n---\n\n{addenda_text}"
            else:
                full_content += f"\n\n---\n\n### ë¶€ì¹™\n\n{addenda_text}"

        return QueryResult(
            type=QueryType.FULL_VIEW,
            success=True,
            content=full_content,
            data={
                "title": view.title,
                "rule_code": view.rule_code,
                "toc": view.toc,
                "content": view.content,
                "addenda": view.addenda,
            },
            state_update={
                "last_regulation": view.title,
                "last_rule_code": view.rule_code,
            },
        )

    def search(
        self,
        query: str,
        options: Optional[QueryOptions] = None,
    ) -> QueryResult:
        """Perform hybrid search."""
        options = options or QueryOptions()

        if self.store is None:
            return QueryResult(
                type=QueryType.ERROR,
                success=False,
                content="ë°ì´í„°ë² ì´ìŠ¤ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.",
            )

        if self.store.count() == 0:
            return QueryResult(
                type=QueryType.ERROR,
                success=False,
                content="ë°ì´í„°ë² ì´ìŠ¤ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. CLIì—ì„œ 'regulation sync'ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.",
            )

        search_usecase = SearchUseCase(
            self.store,
            use_reranker=options.use_rerank,
        )

        results = search_usecase.search_unique(
            query,
            top_k=options.top_k,
            include_abolished=options.include_abolished,
            audience_override=options.audience_override,
        )

        self._last_query_rewrite = search_usecase.get_last_query_rewrite()

        if not results:
            return QueryResult(
                type=QueryType.SEARCH,
                success=True,
                content="ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.",
                data={"results": []},
            )

        # Build table format for CLI/Web
        table_rows = [
            "| # | ê·œì •ëª… | ì½”ë“œ | ì¡°í•­ | ë§¤ì¹­ ì´ìœ  | ì ìˆ˜ |",
            "|---|------|------|------|----------|------|",
        ]
        for i, r in enumerate(results, 1):
            reg_title = r.chunk.parent_path[0] if r.chunk.parent_path else r.chunk.title
            path_segments = (
                clean_path_segments(r.chunk.parent_path) if r.chunk.parent_path else []
            )
            path = " > ".join(path_segments[-2:]) if path_segments else r.chunk.title

            # ìƒˆë¡œ ì¶”ê°€: ë§¤ì¹­ ì„¤ëª… ìƒì„±
            _, matched_kw = format_search_result_with_explanation(
                r, query, show_score=False
            )
            explanation_short = matched_kw if matched_kw else "ê´€ë ¨ ë‚´ìš©"

            table_rows.append(
                f"| {i} | {reg_title} | {r.chunk.rule_code} | {path[:30]} | {explanation_short[:30]} | {r.score:.2f} |"
            )

        # Add top result detail
        top = results[0]
        top_text = strip_path_prefix(top.chunk.text, top.chunk.parent_path or [])
        full_path = (
            " > ".join(clean_path_segments(top.chunk.parent_path))
            if top.chunk.parent_path
            else top.chunk.title
        )

        # ë§¤ì¹­ ì„¤ëª… ìƒì„±
        explanation, _ = format_search_result_with_explanation(
            top, query, show_score=options.show_debug
        )

        content = "\n".join(table_rows)
        content += f"\n\n---\n\n### ğŸ† 1ìœ„ ê²°ê³¼: {top.chunk.rule_code}\n\n"
        content += f"**ê·œì •ëª…:** {top.chunk.parent_path[0] if top.chunk.parent_path else top.chunk.title}\n\n"
        content += f"**ê²½ë¡œ:** {full_path}\n\n"
        content += f"**ë§¤ì¹­ ì •ë³´:** {explanation}\n\n"

        # Step 6: ì‚­ì œ ì¡°í•­ ê²½ê³  ì¶”ê°€
        deletion_warning = detect_deletion_warning(top_text)
        if deletion_warning:
            content += f"\n{deletion_warning}\n\n"

        content += f"{top_text}"

        # Build data for MCP
        formatted_results = []
        for i, r in enumerate(results, 1):
            reg_name = r.chunk.parent_path[0] if r.chunk.parent_path else r.chunk.title
            path = (
                " > ".join(clean_path_segments(r.chunk.parent_path))
                if r.chunk.parent_path
                else r.chunk.title
            )
            # ê° ê²°ê³¼ì—ë„ ì‚­ì œ ê²½ê³  í¬í•¨
            result_deletion_warning = detect_deletion_warning(r.chunk.text)
            formatted_results.append(
                {
                    "rank": i,
                    "regulation_name": reg_name,
                    "rule_code": r.chunk.rule_code,
                    "path": path,
                    "text": r.chunk.text,
                    "score": round(r.score, 4),
                    "deletion_warning": result_deletion_warning,
                }
            )

        top_regulation = (
            top.chunk.parent_path[0] if top.chunk.parent_path else top.chunk.title
        )

        return QueryResult(
            type=QueryType.SEARCH,
            success=True,
            content=content,
            data={
                "query": query,
                "results": formatted_results,
            },
            state_update={
                "last_regulation": top_regulation,
                "last_rule_code": top.chunk.rule_code,
            },
        )

    def ask(
        self,
        question: str,
        options: Optional[QueryOptions] = None,
        context: Optional[QueryContext] = None,
    ) -> QueryResult:
        """Get LLM-generated answer."""
        options = options or QueryOptions()
        context = context or QueryContext()

        if self.store is None:
            return QueryResult(
                type=QueryType.ERROR,
                success=False,
                content="ë°ì´í„°ë² ì´ìŠ¤ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.",
            )

        if self.store.count() == 0:
            return QueryResult(
                type=QueryType.ERROR,
                success=False,
                content="ë°ì´í„°ë² ì´ìŠ¤ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. CLIì—ì„œ 'regulation sync'ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.",
            )

        if self.llm_client is None:
            return QueryResult(
                type=QueryType.ERROR,
                success=False,
                content="LLM í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.",
            )

        search_usecase = SearchUseCase(
            self.store,
            llm_client=self.llm_client,
            use_reranker=options.use_rerank,
        )

        # Build history context if available
        history_text = None
        if context.history:
            history_lines = []
            for msg in context.history[-10:]:  # Last 10 messages
                role = "ì‚¬ìš©ì" if msg.get("role") == "user" else "AI"
                content = msg.get("content", "")
                if content:
                    history_lines.append(f"{role}: {content[:200]}")
            if history_lines:
                history_text = "\n".join(history_lines)

        # Handle multi-turn context expansion
        search_query = question
        if context.last_regulation:
            expanded = expand_followup_query(question, context.last_regulation)
            if expanded != question:
                search_query = expanded
                # Log expansion for debug
                if options.show_debug:
                    logger.debug(f"Context expansion: '{question}' -> '{search_query}'")

        try:
            answer = search_usecase.ask(
                question=question,
                top_k=options.top_k,
                include_abolished=options.include_abolished,
                audience_override=options.audience_override,
                history_text=history_text,
                search_query=search_query,
            )
        except Exception as e:
            return QueryResult(
                type=QueryType.ERROR,
                success=False,
                content=f"ë‹µë³€ ìƒì„± ì‹¤íŒ¨: {str(e)}",
            )

        self._last_query_rewrite = search_usecase.get_last_query_rewrite()

        answer_text = normalize_markdown_emphasis(answer.text)

        # Build sources section
        sources_md = []
        if answer.sources:
            norm_scores = normalize_relevance_scores(answer.sources)
            display_sources = filter_by_relevance(answer.sources, norm_scores)

            for i, r in enumerate(display_sources, 1):
                citation_block = format_regulation_citation(r.chunk)
                norm_score = norm_scores.get(r.chunk.id, 0.0)
                rel_pct = int(norm_score * 100)

                # Add matching explanation with keywords
                explanation, _ = format_search_result_with_explanation(
                    r, question, show_score=False
                )

                sources_md.append(f"""{citation_block}
*ê´€ë ¨ë„: {rel_pct}%*

**ë§¤ì¹­ ì •ë³´:** {explanation}

---
""")

        content = answer_text
        if sources_md:
            content += "\n\n---\n\n" + "\n".join(sources_md)

        # Build data for MCP
        sources_data = []
        if answer.sources:
            norm_scores = normalize_relevance_scores(answer.sources)
            display_sources = filter_by_relevance(answer.sources, norm_scores)
            for r in display_sources:
                reg_name = (
                    r.chunk.parent_path[0] if r.chunk.parent_path else r.chunk.title
                )
                path = (
                    " > ".join(clean_path_segments(r.chunk.parent_path))
                    if r.chunk.parent_path
                    else r.chunk.title
                )
                sources_data.append(
                    {
                        "regulation_name": reg_name,
                        "rule_code": r.chunk.rule_code,
                        "path": path,
                        "text": r.chunk.text,
                        "relevance_pct": int(norm_scores.get(r.chunk.id, 0.0) * 100),
                    }
                )

        top_regulation = ""
        top_rule_code = ""
        if answer.sources:
            top = answer.sources[0]
            top_regulation = (
                top.chunk.parent_path[0] if top.chunk.parent_path else top.chunk.title
            )
            top_rule_code = top.chunk.rule_code

        return QueryResult(
            type=QueryType.ASK,
            success=True,
            content=content,
            data={
                "question": question,
                "answer": answer.text,
                "confidence": round(answer.confidence, 3),
                "sources": sources_data,
            },
            state_update={
                "last_regulation": top_regulation,
                "last_rule_code": top_rule_code,
            },
        )

    def get_last_query_rewrite(self):
        """Get the last query rewrite info for debug output."""
        return self._last_query_rewrite
