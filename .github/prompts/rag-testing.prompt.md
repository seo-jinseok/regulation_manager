# RAG 시스템 품질 테스트 및 개선

AI 에이전트가 다양한 사용자 페르소나를 시뮬레이션하여 RAG 시스템의 품질을 **엄격하게** 테스트하고, 답변 품질을 **비판적으로** 검토하는 워크플로우입니다.

## ⚠️ 평가자 마인드셋 (중요!)

> **당신은 까다로운 품질 검수자입니다. 사용자 입장에서 "이게 정말 도움이 되는가?"를 냉정하게 판단하세요.**
>
> - ❌ "대체로 맞는 것 같다" → 팩트체크 없이 통과시키지 마세요
> - ❌ "규정 조항이 언급되었다" → 그 조항이 실제로 존재하는지 확인했나요?
> - ❌ "답변이 길고 상세하다" → 핵심 정보가 정확한지가 중요합니다
> - ❌ "일반적으로 맞는 내용이다" → **이 학교**의 규정과 일치하는지 확인하세요
> - ❌ "절차를 설명했다" → 구체적인 기한, 서류, 담당부서가 명시되었나요?

## 성공 기준

| 메트릭 | 목표 | 엄격 모드 적용 |
|--------|------|---------------|
| 정적 테스트 통과율 | ≥ 85% | - |
| 동적 쿼리 성공률 | ≥ 80% | **"부분 성공" = 실패**로 카운트 |
| 멀티턴 대화 성공률 | ≥ 75% | - |
| 답변 품질 점수 | ≥ 4.0/5.0 | 팩트체크 실패 시 **최대 2.0점** |
| 회귀 발생 | 0건 | - |
| **팩트체크 수행률** | **100%** | 모든 답변 필수 검증 |

---

## Phase 0: 사전 검증

### 0.1 시스템 상태 확인
```bash
uv run regulation status
```

### 0.2 데이터가 없으면 동기화
```bash
uv run regulation sync data/output/규정집.json
```

### 0.3 LLM 연결 확인
```bash
# .env 파일에서 LLM_PROVIDER 확인 후 해당 서버 체크
# lmstudio인 경우:
curl -s $LLM_BASE_URL/v1/models | head -5
# ollama인 경우:
curl http://localhost:11434/api/tags 2>/dev/null || echo "Ollama 미실행"
```

---

## Phase 1: 정적 평가 실행

### 1.1 자동 평가 실행
```bash
uv run python scripts/auto_evaluate.py --run
```

### 1.2 결과 확인
- 통과율 ≥ 85% → Phase 2로 이동
- 통과율 < 85% → Phase 5 (개선 적용)로 이동

---

## Phase 2: 동적 쿼리 테스트 (핵심)

매 실행마다 **다양한 페르소나**와 **새로운 쿼리**를 생성하여 시스템을 테스트합니다.

### 2.1 페르소나 정의

테스트할 때마다 아래 페르소나 중 **3~5개를 무작위 선택**합니다:

| 페르소나 | 특성 | 예상 관심사 |
|----------|------|-------------|
| 🎓 신입생 | 학교 시스템에 익숙하지 않음, 비공식적 표현 | 수강신청, 장학금, 기숙사, 휴학 |
| 📚 재학생 (3학년) | 구체적 정보 필요, 졸업 준비 | 졸업요건, 전과, 복수전공, 교환학생 |
| 🎓 대학원생 | 연구/논문 중심, 전문적 질문 | 논문심사, 연구비, 학위취득, 지도교수 |
| 👨‍🏫 신임 교수 | 제도 파악 필요, 공식적 표현 | 연구년, 승진, 강의부담, 업적평가 |
| 👩‍🏫 정교수 | 세부 규정 확인, 권리 주장 | 안식년, 정년, 명예퇴직, 보직 |
| 👔 신입 직원 | 복무규정 파악, 혜택 문의 | 휴가, 복리후생, 승진, 겸직 |
| 👨‍💼 과장급 직원 | 부서 운영, 예산 관련 | 예산집행, 시설사용, 인사규정 |
| 👪 학부모 | 자녀 관련 정보, 외부 시선 | 등록금, 장학금, 휴학, 학사일정 |
| 🤕 어려운 상황의 학생 | 감정적, 급한 상황 | 제적위기, 학사경고, 성적이의, 고충처리 |
| 😡 불만있는 구성원 | 권리 주장, 신고 의향 | 성희롱, 갑질, 부당대우, 인권침해 |

### 2.2 쿼리 난이도 매트릭스 (필수)

**각 페르소나에 대해 아래 난이도 분포로 쿼리를 생성합니다:**

| 난이도 | 비율 | 특성 | 예시 |
|--------|------|------|------|
| **쉬움** | 30% | 단일 규정, 명확한 키워드 | "휴학 신청 기간" |
| **중간** | 40% | 여러 규정 연계, 조건부 답변 필요 | "장학금 받다가 휴학하면?" |
| **어려움** | 30% | 모호한 표현, 감정적, 복합 질문 | "학교 너무 힘들어서 쉬고 싶은데 돈이 없어요" |

### 2.3 쿼리 유형 매트릭스

| 유형 | 설명 | 예시 | 검증 포인트 |
|------|------|------|------------|
| **사실 확인** | 구체적 수치/정보 요청 | "졸업학점이 몇 학점이야?" | 정확한 숫자 |
| **절차 질문** | 방법/단계 문의 | "휴학 신청은 어떻게 해?" | 단계별 절차 + 기한 |
| **자격 확인** | 조건/요건 질문 | "장학금 받으려면 학점이 몇 점?" | 구체적 기준 |
| **비교 질문** | 옵션 간 차이 | "일반휴학 vs 군휴학 차이?" | 차이점 명확히 |
| **모호한 질문** | 비구체적 표현 | "학교 그만두고 싶어" | 의도 파악 + 옵션 제시 |
| **감정 표현** | 상황+감정 | "교수님이 불공평해" | 공감 + 실질적 해결책 |
| **복합 질문** | 여러 정보 동시 | "휴학하면 장학금은? 복학은?" | 모든 질문에 답변 |
| **은어/축약어** | 비공식 표현 | "수강철", "복전", "조졸" | 정확한 용어 인식 |

### 2.4 쿼리 생성 및 실행

**각 선택된 페르소나에 대해:**

1. **쿼리 생성**: 난이도 분포를 반영하여 3개 쿼리 생성
2. **쿼리 실행**:
```bash
uv run regulation search "<생성된_쿼리>" -a -n 5
```

3. **결과 기록**: 쿼리, 검색 결과, LLM 답변을 **전체** 캡처

### 2.5 예시 시나리오 (난이도별)

**페르소나**: 🎓 신입생

```
[쿼리 1 - 쉬움]
"휴학 신청 기간이 언제야?"
→ 기대: 구체적 기간 (예: "학기 시작 전 방학 중" 또는 "수업일수 2/3 이전")

[쿼리 2 - 중간]
"장학금 받고 있는데 휴학하면 어떻게 돼?"
→ 기대: 장학금 중단/유지 조건, 복학 후 재신청 여부

[쿼리 3 - 어려움]
"돈이 없어서 학교 다니기 힘든데 어떡해야 할지 모르겠어요"
→ 기대: 장학금 + 등록금 분납 + 근로장학 + 긴급 지원 등 복합 안내
```

---

## Phase 3: 답변 품질 심층 검토 (강화됨)

### 3.1 필수 팩트체크 절차

> ⚠️ **모든 답변에 대해 아래 절차를 반드시 수행하세요. 생략 금지!**

각 답변에서 **핵심 주장 3개**를 추출하고 검증합니다:

```bash
# 1. 답변에서 언급된 규정/조항 확인
uv run regulation search "<규정명> 제X조" -n 3

# 2. 답변의 핵심 수치/기한 확인
uv run regulation search "<키워드> 기간|학점|요건" -n 5

# 3. 실제 검색 결과와 답변 내용 대조
```

**팩트체크 기록 형식:**
```
[팩트체크 #1]
- 답변 주장: "휴학은 수업일수 2/3까지 가능"
- 검증 쿼리: uv run regulation search "휴학 수업일수" -n 3
- 검증 결과: ✅ 학칙 제XX조에서 확인됨 / ❌ 해당 내용 없음 / ⚠️ 다른 내용임
```

### 3.2 답변 품질 평가 매트릭스 (엄격화)

| 항목 | 배점 | 평가 기준 | 자동 감점 조건 |
|------|------|----------|---------------|
| **정확성** | 1.0 | 규정 내용과 일치 | 팩트체크 실패 시 **0점** |
| **완전성** | 1.0 | 질문의 모든 측면에 답변 | 복합질문 중 1개 누락 시 **-0.5** |
| **관련성** | 1.0 | 질문 의도에 맞는 답변 | 50% 이상 무관한 내용 시 **0점** |
| **출처 명시** | 1.0 | 규정명/조항 인용 | 출처 없는 단정 시 **0점** |
| **실용성** | 1.0 | 기한/서류/담당부서 포함 | 절차질문에 기한 없으면 **-0.5** |
| **합계** | 5.0 | | |

### 3.3 성공/실패 판정 (엄격 기준)

| 판정 | 조건 | 성공률 계산 |
|------|------|------------|
| ✅ **성공** | 점수 ≥ 4.0 AND 팩트체크 모두 통과 | 성공으로 카운트 |
| ⚠️ **부분성공** | 점수 3.0~3.9 OR 팩트체크 1개 실패 | **실패로 카운트** |
| ❌ **실패** | 점수 < 3.0 OR 팩트체크 2개 이상 실패 | 실패로 카운트 |

### 3.4 실패 유형 및 심각도

| 실패 유형 | 설명 | 심각도 | 자동 판정 |
|----------|------|--------|----------|
| `WRONG_FACT` | 규정과 다른 정보 제공 | Critical | 즉시 실패 |
| `HALLUCINATION` | 존재하지 않는 규정/조항 언급 | Critical | 즉시 실패 |
| `GENERIC_ANSWER` | 일반론만 제시, 이 학교 규정 미인용 | High | 즉시 실패 |
| `IRRELEVANT` | 질문과 무관한 답변 | High | 즉시 실패 |
| `INCOMPLETE` | 핵심 정보 누락 (기한, 조건 등) | Medium | 부분성공 |
| `NO_SOURCE` | 출처 없이 단정적 답변 | Medium | 부분성공 |
| `CONFUSING` | 이해하기 어려운 답변 | Low | 감점 |

### 3.5 검토 체크리스트 (필수)

각 답변에 대해 **모두 확인**:

- [ ] **팩트체크 완료**: 핵심 주장 3개 검증 (검증 쿼리 실행 필수)
- [ ] **일반론 체크**: "대학마다 다를 수 있습니다" 같은 회피성 답변 아닌가?
- [ ] **구체성 체크**: 숫자(학점, 기간), 담당부서, 필요서류가 명시되었는가?
- [ ] **출처 체크**: 인용된 규정/조항이 실제로 존재하고 내용이 일치하는가?
- [ ] **누락 체크**: 중요한 예외사항, 주의사항이 빠지지 않았는가?
- [ ] **할루시네이션 체크**: 규정에 없는 내용을 지어내지 않았는가?

---

## Phase 4: 멀티턴 대화 테스트

단일 쿼리를 넘어 **후속 질문 시나리오**를 테스트합니다.

### 4.1 후속 질문 유형

| 유형 | 설명 | 예시 |
|------|------|------|
| **구체화** | 더 자세한 정보 요청 | "그러면 정확히 몇 학점이야?" |
| **관련 확장** | 연관 주제로 확장 | "휴학하면 장학금은 어떻게 돼?" |
| **예외 확인** | 특수 상황 문의 | "군대 가는 경우도 똑같아?" |
| **절차 심화** | 구체적 절차 문의 | "신청서는 어디서 받아?" |
| **조건 변경** | 다른 조건에서의 적용 | "대학원생도 마찬가지야?" |
| **확인 질문** | 이해 확인 | "그러니까 3월 전에 신청해야 한다는 거지?" |

### 4.2 멀티턴 시나리오 템플릿

각 페르소나에 대해 **1개 이상의 3턴 대화**를 실행:

```
[Turn 1 - 초기 질문]
User: "휴학하고 싶어요"
→ 시스템 응답 확인

[Turn 2 - 후속 질문 (구체화)]
User: "신청 기간은 언제야? 서류는 뭐가 필요해?"
→ 이전 맥락을 유지하며 답변하는지 확인

[Turn 3 - 후속 질문 (예외 확인)]
User: "군대 때문에 휴학하는 것도 같은 방법이야?"
→ 맥락 유지 + 새로운 정보 제공 확인
```

### 4.3 멀티턴 평가 기준

| 항목 | 평가 내용 |
|------|----------|
| **맥락 유지** | 이전 대화 내용을 기억하고 반영하는가? |
| **정보 일관성** | Turn 간에 모순되는 정보가 없는가? |
| **점진적 심화** | 후속 질문에 더 구체적인 정보를 제공하는가? |
| **중복 회피** | 이미 언급한 내용을 불필요하게 반복하지 않는가? |

### 4.4 CLI에서 멀티턴 테스트

```bash
# 인터랙티브 모드로 멀티턴 테스트
uv run regulation

# 첫 질문 입력 후 후속 질문 연속 입력
```

---

## Phase 5: 개선 적용 (실패 발생 시)

### 5.1 실패 분석

```bash
cat data/output/improvement_plan.json | python -m json.tool
```

### 5.2 제안 유형별 처리

| 유형 | 처리 방법 |
|------|----------|
| `intent` | `data/config/intents.json` 패치 |
| `synonym` | `data/config/synonyms.json` 패치 |
| `code_pattern` | `src/rag/infrastructure/query_analyzer.py` 수정 |
| `code_weight` | 가중치 조정 |
| `code_audience` | 대상 감지 로직 개선 |
| `architecture` | Phase 7에서 수동 검토 보고 |

### 5.3 데이터 패치 (intent/synonym)

**인텐트 추가** - `data/config/intents.json`:
```json
{
  "intent_id": "overseas_conference",
  "triggers": ["해외학회", "해외 학회", "국제학회"]
}
```

**동의어 추가** - `data/config/synonyms.json`에 새 항목 추가

### 5.4 코드 개선 (code_*)

| 제안 유형 | 수정 파일 | 수정 대상 |
|-----------|----------|----------|
| `code_pattern` | `src/rag/infrastructure/query_analyzer.py` | `INTENT_PATTERNS` |
| `code_weight` | `src/rag/infrastructure/query_analyzer.py` | `WEIGHT_PRESETS` |
| `code_audience` | `src/rag/infrastructure/query_analyzer.py` | `*_KEYWORDS` 상수 |

**수정 원칙**: 기존 항목 삭제 금지, 새 항목만 추가

### 5.5 패치 검증
```bash
uv run pytest tests/rag/unit/infrastructure/test_query_analyzer.py -v --tb=short
```

---

## Phase 6: 재평가 및 반복 판단

### 6.1 단위 테스트 확인
```bash
uv run pytest tests/rag/ -v --tb=short
```

### 6.2 정적 평가 재실행
```bash
uv run python scripts/auto_evaluate.py --run
```

### 6.3 실패한 동적 쿼리 재테스트

Phase 3에서 실패한 쿼리들을 다시 테스트

### 6.4 반복 판단

**종료 조건** (하나라도 해당 시 Phase 7으로):
1. 모든 목표 달성
2. 개선 한계: 2회 연속 동일 결과
3. 최대 반복: 3회 사이클 완료
4. 구조적 문제: `architecture` 유형만 남음

종료 조건 미해당 시 **Phase 5로 반복**

---

## Phase 7: 완료 보고

### 7.1 세션 요약 생성

1. **시작 상태**
   - 정적 테스트 통과율
   - 시스템 상태 (규정 수, 조항 수)

2. **동적 테스트 결과**
   - 테스트한 페르소나 목록
   - 쿼리 난이도 분포
   - **팩트체크 수행 내역** (검증 쿼리 포함)
   - 성공/부분성공/실패 비율

3. **멀티턴 테스트 결과**
   - 테스트한 시나리오 수
   - 맥락 유지 성공률

4. **답변 품질 점수**
   - 항목별 평균 점수
   - **주요 실패 유형 분포**

5. **적용된 개선**
   - 인텐트/동의어 추가 내역
   - 코드 수정 내역

6. **최종 상태**
   - 최종 통과율
   - **남은 문제 및 원인 분석**

7. **다음 단계 권장사항**

### 7.2 결과 저장 위치
- 세션 요약: `data/output/test_session_<날짜>.md`
- 실패 쿼리 목록: `data/output/failed_queries_<날짜>.json`

---

## 트러블슈팅

```bash
# LLM 연결 확인 (lmstudio)
curl -s http://game-mac-studio:1234/v1/models | python3 -c "import sys,json; print(json.load(sys.stdin))"

# 특정 테스트 디버깅
uv run pytest tests/rag/unit/infrastructure/test_query_analyzer.py::test_specific -v -s

# 변경사항 확인/되돌리기
git diff data/config/
git checkout -- data/config/intents.json

# 규정 내용 직접 확인 (팩트체크용)
uv run regulation search "<규정명>" -n 10

# 특정 조항 확인
uv run regulation search "<규정명> 제N조"
```

---

## 체크리스트

### 기본 검증
- [ ] Phase 0: 시스템 상태 확인
- [ ] Phase 1: 정적 평가 완료

### 동적 테스트
- [ ] Phase 2: 페르소나 선택 (3~5개)
- [ ] Phase 2: **난이도 분포 반영** (쉬움 30%, 중간 40%, 어려움 30%)
- [ ] Phase 2: 쿼리 생성 및 실행
- [ ] Phase 3: **모든 답변 팩트체크 완료**
- [ ] Phase 3: 답변 품질 검토 완료 (평균 ≥ 4.0)

### 멀티턴 테스트
- [ ] Phase 4: 멀티턴 시나리오 실행 (페르소나당 1개 이상)
- [ ] Phase 4: 맥락 유지 확인

### 개선 및 완료
- [ ] Phase 5: 개선 적용 (필요시)
- [ ] Phase 6: 재평가 완료
- [ ] Phase 7: 보고서 생성

---

## 부록: 엄격한 테스트 세션 예시

```
=== RAG 품질 테스트 세션 시작 ===
날짜: 2026-01-12
테스터: AI Agent (엄격 모드)

[Phase 0] 시스템 상태: OK (318개 규정, 17254개 조항)
[Phase 1] 정적 테스트: 50/50 통과 (100%)

[Phase 2] 동적 테스트
선택된 페르소나: 신입생, 대학원생, 불만있는 구성원

--- 페르소나: 신입생 ---

[쿼리 1 - 쉬움] "휴학 신청 기간이 언제야?"
답변 요약: "학기 시작 전 방학 기간 또는 수업일수 2/3 이전..."

[팩트체크]
#1: "수업일수 2/3 이전" 
   검증: uv run regulation search "휴학 수업일수" -n 3
   결과: ✅ 학칙 제XX조 "수업일수의 3분의 2선까지" 확인

#2: "방학 기간" 
   검증: uv run regulation search "휴학 방학" -n 3  
   결과: ✅ 휴학규정 제X조 확인

점수: 정확성 1.0 + 완전성 0.8 + 관련성 1.0 + 출처 1.0 + 실용성 0.8 = 4.6
판정: ✅ 성공

---

[쿼리 2 - 중간] "장학금 받고 있는데 휴학하면 어떻게 돼?"
답변 요약: "휴학 시 장학금은 중단되며..."

[팩트체크]
#1: "장학금 중단"
   검증: uv run regulation search "휴학 장학금" -n 5
   결과: ⚠️ 명확한 규정 없음, 장학금 유형별로 다를 수 있음

#2: "복학 후 재신청"
   검증: uv run regulation search "장학금 재신청" -n 3
   결과: ❌ 해당 내용 찾을 수 없음

점수: 정확성 0.5 + 완전성 0.7 + 관련성 1.0 + 출처 0.5 + 실용성 0.5 = 3.2
판정: ⚠️ 부분성공 → **실패로 카운트**

---

[쿼리 3 - 어려움] "돈이 없어서 학교 다니기 힘든데 어떡해야 할지 모르겠어요"
답변 요약: "장학금 종류로는... 등록금 분납 제도가..."

[팩트체크]
#1: "국가장학금"
   검증: uv run regulation search "국가장학금" -n 3
   결과: ✅ 장학금규정 제X조 확인

#2: "등록금 분납"
   검증: uv run regulation search "등록금 분납" -n 3
   결과: ✅ 등록금납부규정 제X조 확인

#3: "근로장학금"
   검증: uv run regulation search "근로장학" -n 3
   결과: ✅ 근로장학생규정 확인

점수: 정확성 1.0 + 완전성 0.9 + 관련성 1.0 + 출처 0.8 + 실용성 0.9 = 4.6
판정: ✅ 성공

---

[Phase 3] 품질 점수 (엄격 모드)
- 정확성: 4.2/5.0
- 완전성: 3.8/5.0
- 관련성: 4.6/5.0
- 출처 명시: 3.7/5.0
- 실용성: 3.7/5.0
- 평균: 4.0/5.0 ✅

동적 쿼리 결과:
- 성공: 6개
- 부분성공(=실패): 3개
- 실패: 1개
- **성공률: 60%** ❌ (목표 80% 미달)

[Phase 5] 개선 필요
- 장학금-휴학 연계 정보 보강 필요
- 등록금 관련 인텐트 추가 필요

[Phase 7] 최종 결과
- 정적 테스트: 100% ✅
- 동적 쿼리 성공률: 60% ❌
- 멀티턴 성공률: 80% ✅
- 답변 품질: 4.0/5.0 ✅
- 회귀: 없음

결론: 동적 쿼리 목표 미달 - 개선 필요 ⚠️
```
