# RAG 시스템 품질 테스트 및 개선 (v2.1)

AI 에이전트가 다양한 사용자 페르소나를 시뮬레이션하여 RAG 시스템의 품질을 **엄격하게** 테스트하고, 답변 품질을 **비판적으로** 검토하는 워크플로우입니다.

**v2.1 주요 변경사항:**
- 🆕 Fact Check 시스템 검증 추가
- 🆕 synonym CLI 명령어 문서화
- 🆕 입력 검증 및 보안 테스트 섹션
- 🆕 Query Decomposition 컴포넌트 추가
- CLI 옵션 정확성 업데이트 (`--tool-calling` 제거)

**v2.0 주요 변경사항:**
- 고급 RAG 기능 검증 추가 (Self-RAG, HyDE, Corrective RAG, Hybrid Search, BGE Reranker)
- 컴포넌트별 기여도 분석 추가
- 의도 추론 정확성 검증 강화
- 최소 3턴 이상 후속 질문 필수화

## ⚠️ 평가자 마인드셋 (중요!)

> **당신은 까다로운 품질 검수자입니다. 사용자 입장에서 "이게 정말 도움이 되는가?"를 냉정하게 판단하세요.**
>
> - ❌ "대체로 맞는 것 같다" → 팩트체크 없이 통과시키지 마세요
> - ❌ "규정 조항이 언급되었다" → 그 조항이 실제로 존재하는지 확인했나요?
> - ❌ "답변이 길고 상세하다" → 핵심 정보가 정확한지가 중요합니다
> - ❌ "일반적으로 맞는 내용이다" → **이 학교**의 규정과 일치하는지 확인하세요
> - ❌ "절차를 설명했다" → 구체적인 기한, 서류, 담당부서가 명시되었나요?
> - ❌ "검색 결과가 나왔다" → **어떤 RAG 컴포넌트**가 결과에 기여했는지 분석했나요?

---

## 고급 RAG 컴포넌트 개요

테스트 전 반드시 이해해야 할 시스템 컴포넌트:

| 컴포넌트 | 역할 | 활성화 조건 | 검증 포인트 |
|----------|------|-------------|-------------|
| **Self-RAG** | 검색 필요성 판단 + 결과 관련성 평가 | `ENABLE_SELF_RAG=true` (기본) | 단순 인사말에서 검색 스킵 여부 |
| **HyDE** | 모호한 쿼리 → 가상 문서 생성 | `ENABLE_HYDE=true` (기본) | "학교 가기 싫어" 같은 모호 쿼리 처리 |
| **Corrective RAG** | 검색 결과 품질 평가 → 재검색 트리거 | 동적 임계값 (0.3~0.5) | 낮은 점수 결과에서 재검색 발동 여부 |
| **Hybrid Search** | BM25 + Dense 검색 융합 (RRF) | `use_hybrid=True` | 키워드 검색과 의미 검색 균형 |
| **BGE Reranker** | 검색 결과 재정렬 | `use_reranker=True` | 최종 순위 품질 |
| **Tool Calling** | Agentic RAG (도구 기반 검색) | `serve --mcp` 또는 내부 로직 | 복잡 쿼리의 도구 선택 정확성 |
| **Query Analyzer** | 인텐트 분석 + 쿼리 확장 | 항상 활성 | 의도 파악 + 동의어 확장 |
| **Fact Check** 🆕 | 답변 생성 후 팩트체크 및 재생성 | `ENABLE_FACT_CHECK=true` (기본 OFF) | 오류 발견 시 재생성 여부 |
| **Query Decomposition** 🆕 | 복합 질문 → 하위 질문 분해 | 내부 로직 | 복합 쿼리 처리 정확도 |
| **Dynamic RRF** 🆕 | RRF k 값 동적 조정 | 코드 내 설정 | BM25/Dense 균형 |

## 성공 기준

| 메트릭 | 목표 | 엄격 모드 적용 |
|--------|------|---------------|
| 정적 테스트 통과율 | ≥ 85% | - |
| 동적 쿼리 성공률 | ≥ 80% | **"부분 성공" = 실패**로 카운트 |
| 멀티턴 대화 성공률 | ≥ 80% | **필수** (최소 3턴 후속 질문) |
| **후속 질문 성공률** | **≥ 85%** | 각 Turn별 성공률 |
| 답변 품질 점수 | ≥ 4.0/5.0 | 팩트체크 실패 시 **최대 2.0점** |
| 회귀 발생 | 0건 | - |
| **팩트체크 수행률** | **100%** | 모든 답변 필수 검증 |
| **의도 충족률** | **≥ 90%** | 사용자가 바로 행동 가능해야 함 |
| **의도 추론 정확도** | **≥ 85%** | AI가 파악한 의도가 실제 의도와 일치 |
| **RAG 컴포넌트 기여도** | **분석 필수** | 각 기능이 품질에 미친 영향 |

---

## Phase 0: 사전 검증

### 0.1 시스템 상태 확인
```bash
uv run regulation status
```

### 0.2 데이터가 없으면 동기화
```bash
uv run regulation sync data/output/규정집.json
```

### 0.3 LLM 연결 확인
```bash
# .env 파일에서 LLM_PROVIDER 확인 후 해당 서버 체크
# lmstudio인 경우:
curl -s $LLM_BASE_URL/v1/models | head -5
# ollama인 경우:
curl http://localhost:11434/api/tags 2>/dev/null || echo "Ollama 미실행"
```

### 0.4 고급 RAG 설정 확인 (신규)
```bash
# 현재 RAG 설정 확인 (확장)
cat .env | grep -E "(ENABLE_SELF_RAG|ENABLE_HYDE|BM25_TOKENIZE_MODE|HYDE_CACHE|ENABLE_FACT_CHECK|FACT_CHECK_MAX_RETRIES)"

# 기본 설정값 (미설정 시):
# ENABLE_SELF_RAG=true
# ENABLE_HYDE=true  
# BM25_TOKENIZE_MODE=konlpy
# HYDE_CACHE_ENABLED=true
# ENABLE_FACT_CHECK=false       # 🆕 기본 비활성화
# FACT_CHECK_MAX_RETRIES=2      # 🆕 최대 재생성 횟수
```

---

## Phase 1: 정적 평가 실행

### 1.1 자동 평가 실행
```bash
uv run python scripts/auto_evaluate.py --run
```

### 1.2 결과 확인
- 통과율 ≥ 85% → Phase 1.5로 이동
- 통과율 < 85% → Phase 5 (개선 적용)로 이동

---

## Phase 1.5: 고급 RAG 컴포넌트 단위 테스트 (신규)

> ⚠️ **각 RAG 컴포넌트가 제대로 작동하는지 개별 검증합니다.**

### 1.5.1 Self-RAG 검증

Self-RAG는 (1) 검색 필요성 판단, (2) 결과 관련성 평가를 수행합니다.

**테스트 케이스:**

| 쿼리 유형 | 예시 쿼리 | 기대 동작 |
|----------|----------|----------|
| 인사말 | "안녕하세요" | `[RETRIEVE_NO]` → 검색 스킵 |
| 단순 정보 | "휴학 신청 기간" | `[RETRIEVE_YES]` → 검색 수행 |
| 후속 질문 (맥락 있음) | "그러면 복학은요?" | 상황에 따라 판단 |

```bash
# Self-RAG 동작 확인 (디버그 모드)
uv run regulation --debug search "안녕하세요" -n 1
# 로그에서 "Self-RAG: needs_retrieval=False" 확인

uv run regulation --debug search "휴학 신청 기간" -n 3
# 로그에서 "Self-RAG: needs_retrieval=True" 확인
```

**검증 기록:**
```
[Self-RAG 검증]
- 인사말 쿼리: ✅ 검색 스킵됨 / ❌ 불필요한 검색 수행
- 정보 쿼리: ✅ 검색 수행됨 / ❌ 검색이 스킵됨
- 관련성 필터링: ✅ 무관한 결과 제거됨 / ❌ 필터링 미작동
```

### 1.5.2 HyDE 검증

HyDE는 모호한 쿼리에 대해 가상 문서를 생성하여 검색 품질을 높입니다.

**테스트 케이스:**

| 쿼리 유형 | 예시 쿼리 | HyDE 발동 | 기대 효과 |
|----------|----------|----------|----------|
| 명확한 쿼리 | "휴학 신청 기간" | ❌ | 직접 검색 |
| 모호한 쿼리 | "학교 가기 싫어" | ✅ | 휴학/휴직 관련 결과 |
| 감정 표현 | "교수님이 너무 힘들어요" | ✅ | 고충처리/상담 관련 결과 |
| 은어/축약 | "복전 하고 싶어요" | ❌/✅ | 복수전공 관련 결과 |

```bash
# HyDE 동작 확인
uv run regulation --debug search "학교 가기 싫어" -a -n 5
# 로그에서 "HyDE: generated hypothetical document" 확인

# HyDE 캐시 확인
cat data/cache/hyde/hyde_cache.json | python -m json.tool | head -20
```

**비교 테스트 (HyDE ON vs OFF):**
```bash
# HyDE 활성화 (기본)
uv run regulation search "학교 가기 싫어" -n 5

# HyDE 비활성화
ENABLE_HYDE=false uv run regulation search "학교 가기 싫어" -n 5

# 결과 비교: HyDE 활성화 시 더 관련성 높은 결과가 나오는지 확인
```

**검증 기록:**
```
[HyDE 검증]
- 모호 쿼리 "학교 가기 싫어":
  - HyDE OFF: 검색 결과 [결과 요약]
  - HyDE ON: 검색 결과 [결과 요약]
  - 품질 개선: ✅ 휴학/휴직 관련 결과 증가 / ❌ 차이 없음 / ⚠️ 오히려 악화
```

### 1.5.3 Corrective RAG 검증

검색 결과 품질이 낮으면 쿼리를 확장하여 재검색합니다.

**동적 임계값:**
- 단순 쿼리 (simple): 0.3
- 일반 쿼리 (medium): 0.4
- 복잡 쿼리 (complex): 0.5

```bash
# Corrective RAG 트리거 확인 (디버그 모드)
uv run regulation --debug search "희귀한키워드조합" -n 5
# 로그에서 "Corrective RAG: triggered, expanding query" 확인
```

**검증 기록:**
```
[Corrective RAG 검증]
- 낮은 품질 결과 쿼리: ✅ 재검색 트리거됨 / ❌ 미트리거
- 재검색 후 품질: ✅ 개선됨 / ❌ 변화 없음
```

### 1.5.4 Hybrid Search (BM25 + Dense) 검증

키워드 기반(BM25)과 의미 기반(Dense) 검색을 융합합니다.

**테스트 케이스:**

| 쿼리 특성 | 예시 | BM25 우세 | Dense 우세 |
|----------|------|----------|----------|
| 정확한 키워드 | "교원인사규정 제8조" | ✅ | - |
| 의미적 유사 | "교수 승진 조건" | - | ✅ |
| 혼합 | "휴학 신청 방법" | 균형 | 균형 |

```bash
# BM25 토크나이저 모드 확인
echo $BM25_TOKENIZE_MODE  # konlpy, morpheme, simple

# 하이브리드 검색 결과 확인 (디버그 모드)
uv run regulation --debug search "교원인사규정 제8조" -n 5
```

### 1.5.5 BGE Reranker 검증

검색 결과를 재정렬하여 가장 관련성 높은 결과를 상위에 배치합니다.

```bash
# Reranker ON (기본)
uv run regulation search "휴학 신청" -n 5

# Reranker OFF
uv run regulation search "휴학 신청" -n 5 --no-rerank

# 결과 순서 비교
```

**검증 기록:**
```
[Reranker 검증]
- Reranker OFF 순위: [1위 제목], [2위 제목], [3위 제목]
- Reranker ON 순위: [1위 제목], [2위 제목], [3위 제목]
- 순위 변동: ✅ 더 관련성 높은 결과가 상위로 / ❌ 변동 없음/악화
```

### 1.5.6 Query Analyzer (인텐트 분석) 검증

사용자의 숨겨진 의도를 파악하고 쿼리를 확장합니다.

**인텐트 매칭 테스트:**
```bash
# 인텐트 매칭 확인
uv run regulation --debug search "학교 안 가고 싶어" -a -n 5
# 로그에서 "[의도 분석]" 힌트 확인

# intents.json 확인
cat data/config/intents.json | python -m json.tool | head -30
```

**검증 기록:**
```
[Query Analyzer 검증]
- 쿼리: "학교 안 가고 싶어"
- 감지된 인텐트: [휴직, 휴가, 연구년]
- 확장된 키워드: [휴직, 휴가, 연구년, 안식년]
- 감지된 청중: [교수/교원]
- 정확도: ✅ 의도 정확히 파악 / ❌ 잘못된 인텐트 / ⚠️ 부분 매칭
```

### 1.5.7 컴포넌트 통합 테스트

모든 컴포넌트가 함께 작동할 때의 시너지 효과를 검증합니다.

```bash
# 모든 기능 활성화 (기본)
uv run regulation search "돈 없어서 학교 다니기 힘들어요" -a -n 5

# 기능별 비활성화 비교
ENABLE_HYDE=false uv run regulation search "돈 없어서 학교 다니기 힘들어요" -a -n 5
ENABLE_SELF_RAG=false uv run regulation search "돈 없어서 학교 다니기 힘들어요" -a -n 5
```

**컴포넌트 기여도 분석 템플릿:**
```
[통합 테스트] 쿼리: "돈 없어서 학교 다니기 힘들어요"

| 컴포넌트 | 활성화 | 동작 여부 | 기여도 |
|----------|--------|----------|--------|
| Self-RAG | ✅ | 검색 필요 판단 | 정상 |
| HyDE | ✅ | 가상 문서 생성 | 장학금/분납 키워드 추가 |
| Query Analyzer | ✅ | 인텐트: 경제적 어려움 | 키워드 확장 |
| Hybrid Search | ✅ | BM25+Dense 융합 | 정상 |
| Corrective RAG | ❌ | 미트리거 (품질 충분) | - |
| Reranker | ✅ | 재정렬 수행 | 장학금 규정 상위 배치 |

최종 결과 품질: ✅ 우수 / ⚠️ 보통 / ❌ 미흡
```

### 1.5.8 Fact Check 검증 (선택적) 🆕

Fact Check는 LLM 답변 생성 후 팩트체크를 수행하고 오류 발견 시 재생성합니다.

> ⚠️ 기본 비활성화(`ENABLE_FACT_CHECK=false`)이므로 활성화 후 테스트합니다.

**테스트 케이스:**

| 시나리오 | 기대 동작 |
|----------|----------|
| 정확한 답변 | 팩트체크 통과, 재생성 없음 |
| 부정확한 답변 | 팩트체크 실패, 최대 N회 재생성 |

```bash
# Fact Check 활성화 테스트
ENABLE_FACT_CHECK=true uv run regulation search "휴학 신청 기간" -a -n 5
# 로그에서 "Fact check passed" 또는 "Fact check failed, regenerating" 확인

# Fact Check 비활성화 (기본)
uv run regulation search "휴학 신청 기간" -a -n 5
```

**비교 테스트:**
```bash
# Fact Check ON - 정확도 검증
ENABLE_FACT_CHECK=true uv run regulation --debug search "교원 승진 조건" -a -n 5
# 로그에서 팩트체크 프로세스 확인

# 최대 재시도 횟수 조정
ENABLE_FACT_CHECK=true FACT_CHECK_MAX_RETRIES=3 uv run regulation search "장학금 신청 자격" -a -n 5
```

**검증 기록:**
```
[Fact Check 검증]
- 활성화 상태: ENABLE_FACT_CHECK=true
- 정확한 답변: ✅ 팩트체크 통과 / ❌ 불필요한 재생성
- 부정확한 답변 시뮬레이션: ✅ 재생성 트리거 / ❌ 미트리거
- 최대 재시도 횟수: N회 확인
```

### 1.5.9 입력 검증 및 보안 테스트 🆕

QueryHandler의 입력 검증이 올바르게 작동하는지 확인합니다.

**검증 항목:**
- 최대 쿼리 길이: 500자
- 금지 패턴 차단: XSS, SQL Injection, Template Injection

**테스트 케이스:**
```bash
# 길이 제한 테스트 (500자 초과)
uv run regulation search "$(python -c 'print("a"*501)')" -n 1
# 기대: 오류 메시지 또는 잘린 쿼리

# XSS 패턴 차단 테스트
uv run regulation search "<script>alert(1)</script>" -n 1
# 기대: 차단 또는 무시

# SQL Injection 패턴 차단 테스트
uv run regulation search "'; DROP TABLE regulations; --" -n 1
# 기대: 차단 또는 무시

# Template Injection 패턴 차단 테스트
uv run regulation search "{{config}}" -n 1
# 기대: 차단 또는 무시
```

**검증 기록:**
```
[입력 검증 테스트]
- 500자 초과 쿼리: ✅ 차단/잘림 / ❌ 그대로 처리
- XSS 패턴 (<script>): ✅ 차단 / ❌ 처리됨
- SQL Injection 패턴 (DROP TABLE): ✅ 차단 / ❌ 처리됨
- Template Injection ({{}}): ✅ 차단 / ❌ 처리됨
```

---

## Phase 2: 동적 쿼리 테스트 - 의도 추론 중심 (핵심)

매 실행마다 **다양한 페르소나**와 **새로운 쿼리**를 생성하여 시스템을 테스트합니다.

> ⚠️ **핵심 변경**: 각 쿼리에서 **AI가 추론한 의도**와 **실제 의도**의 일치 여부를 검증합니다.

### 2.1 페르소나 정의

테스트할 때마다 아래 페르소나 중 **3~5개를 무작위 선택**합니다:

| 페르소나 | 특성 | 예상 관심사 |
|----------|------|-------------|
| 🎓 신입생 | 학교 시스템에 익숙하지 않음, 비공식적 표현 | 수강신청, 장학금, 기숙사, 휴학 |
| 📚 재학생 (3학년) | 구체적 정보 필요, 졸업 준비 | 졸업요건, 전과, 복수전공, 교환학생 |
| 🎓 대학원생 | 연구/논문 중심, 전문적 질문 | 논문심사, 연구비, 학위취득, 지도교수 |
| 👨‍🏫 신임 교수 | 제도 파악 필요, 공식적 표현 | 연구년, 승진, 강의부담, 업적평가 |
| 👩‍🏫 정교수 | 세부 규정 확인, 권리 주장 | 안식년, 정년, 명예퇴직, 보직 |
| 👔 신입 직원 | 복무규정 파악, 혜택 문의 | 휴가, 복리후생, 승진, 겸직 |
| 👨‍💼 과장급 직원 | 부서 운영, 예산 관련 | 예산집행, 시설사용, 인사규정 |
| 👪 학부모 | 자녀 관련 정보, 외부 시선 | 등록금, 장학금, 휴학, 학사일정 |
| 🤕 어려운 상황의 학생 | 감정적, 급한 상황 | 제적위기, 학사경고, 성적이의, 고충처리 |
| 😡 불만있는 구성원 | 권리 주장, 신고 의향 | 성희롱, 갑질, 부당대우, 인권침해 |

### 2.2 쿼리 난이도 매트릭스 (필수)

**각 페르소나에 대해 아래 난이도 분포로 쿼리를 생성합니다:**

| 난이도 | 비율 | 특성 | 예시 |
|--------|------|------|------|
| **쉬움** | 30% | 단일 규정, 명확한 키워드 | "휴학 신청 기간" |
| **중간** | 40% | 여러 규정 연계, 조건부 답변 필요 | "장학금 받다가 휴학하면?" |
| **어려움** | 30% | 모호한 표현, 감정적, 복합 질문 | "학교 너무 힘들어서 쉬고 싶은데 돈이 없어요" |

### 2.3 쿼리 유형 매트릭스

| 유형 | 설명 | 예시 | 검증 포인트 |
|------|------|------|------------|
| **사실 확인** | 구체적 수치/정보 요청 | "졸업학점이 몇 학점이야?" | 정확한 숫자 |
| **절차 질문** | 방법/단계 문의 | "휴학 신청은 어떻게 해?" | 단계별 절차 + 기한 |
| **자격 확인** | 조건/요건 질문 | "장학금 받으려면 학점이 몇 점?" | 구체적 기준 |
| **비교 질문** | 옵션 간 차이 | "일반휴학 vs 군휴학 차이?" | 차이점 명확히 |
| **모호한 질문** | 비구체적 표현 | "학교 그만두고 싶어" | 의도 파악 + 옵션 제시 |
| **감정 표현** | 상황+감정 | "교수님이 불공평해" | 공감 + 실질적 해결책 |
| **복합 질문** | 여러 정보 동시 | "휴학하면 장학금은? 복학은?" | 모든 질문에 답변 |
| **은어/축약어** | 비공식 표현 | "수강철", "복전", "조졸" | 정확한 용어 인식 |

### 2.4 의도 추론 검증 프레임워크 (신규 - 핵심)

> ⚠️ **모든 쿼리에 대해 AI가 사용자 의도를 정확히 파악했는지 검증해야 합니다.**

#### 2.4.1 의도 추론 3단계

각 쿼리에 대해 다음 3단계로 의도를 분석합니다:

1. **표면적 의도 (Surface Intent)**: 쿼리에서 직접 표현된 것
2. **숨겨진 의도 (Hidden Intent)**: 쿼리 뒤에 있는 실제 니즈
3. **행동 의도 (Action Intent)**: 사용자가 궁극적으로 하고 싶은 행동

**예시:**
```
쿼리: "학교 너무 힘들어요"

1. 표면적 의도: 학교 생활의 어려움 표현
2. 숨겨진 의도: 
   - 휴학을 고려 중 (학업 부담)
   - 상담이 필요함 (심리적 어려움)
   - 학사 경고 위기 (성적 문제)
   - 경제적 지원 필요 (재정 문제)
3. 행동 의도: 현재 상황을 해결할 수 있는 옵션을 알고 싶음
```

#### 2.4.2 의도 추론 정확도 평가

| 평가 등급 | 조건 | 점수 |
|----------|------|------|
| **정확** | 3단계 의도 모두 정확히 파악 | 100% |
| **부분 정확** | 숨겨진 의도 일부 누락 | 70% |
| **표면적 파악** | 표면적 의도만 파악 | 40% |
| **오해** | 의도를 잘못 파악 | 0% |

#### 2.4.3 의도 추론 검증 기록 형식

```
[쿼리] "학교 너무 힘들어서 쉬고 싶은데 돈이 없어요"

[의도 분석 - 정답 (평가자 판단)]
1. 표면적 의도: 학교 휴식 희망 + 경제적 어려움 호소
2. 숨겨진 의도: 
   - 휴학을 고려하지만 경제적 부담 우려
   - 장학금이나 지원제도를 알고 싶음
3. 행동 의도: 휴학하면서도 경제적 지원을 받을 수 있는 방법 탐색

[AI의 의도 파악 (시스템 응답 분석)]
- 감지된 인텐트: 경제적_어려움, 휴학_희망
- 확장된 키워드: 휴학, 장학금, 등록금, 분납
- 청중 감지: 학생

[의도 추론 평가]
- 표면적 의도: ✅ 정확히 파악
- 숨겨진 의도 파악률: 
  - ✅ 휴학 고려 파악
  - ✅ 경제적 지원 필요 파악
  - ⚠️ 심리적 지원 필요성 미파악 (부분 누락)
- 행동 의도: ✅ 지원 옵션 제시

의도 추론 점수: 85% (부분 정확)
```

### 2.5 쿼리 생성 및 실행

**각 선택된 페르소나에 대해:**

1. **쿼리 생성**: 난이도 분포를 반영하여 3개 쿼리 생성
2. **쿼리 실행**:
```bash
uv run regulation search "<생성된_쿼리>" -a -n 5
```

3. **결과 기록**: 쿼리, 검색 결과, LLM 답변, **RAG 컴포넌트 동작 로그**를 **전체** 캡처

### 2.6 의도 충족 검증 (필수)

> ⚠️ **모든 답변에 대해 "사용자가 이 답변으로 다음 행동을 할 수 있는가?"를 검증하세요.**

#### 의도 충족 체크리스트

각 답변에 대해 **모두 확인**:

- [ ] 사용자가 원하는 **구체적 행동**이 명확히 안내되었는가?
- [ ] **다음 단계**가 무엇인지 알 수 있는가?
- [ ] **예상 결과**가 설명되었는가?
- [ ] 필요한 **준비물/조건**이 명시되었는가?
- [ ] **기한**이 명시되었는가? (해당되는 경우)
- [ ] **담당부서/연락처**가 안내되었는가?

#### 의도 충족 판정

| 판정 | 조건 | 성공 카운트 |
|------|------|------------|
| ✅ **충족** | 체크리스트 5개 이상 통과 | 성공 |
| ⚠️ **부분 충족** | 체크리스트 3~4개 통과 | **실패로 카운트** |
| ❌ **미충족** | 체크리스트 2개 이하 통과 | 실패 |

#### 의도 충족 검증 기록 형식

```
[쿼리] "휴학하고 싶어요"

[의도 추론 검증]
- AI가 파악한 의도: 휴학 절차 안내 요청
- 실제 의도: 휴학 절차를 알고 싶음
- 의도 추론 정확도: ✅ 100%

[의도 충족 검증]
- 기대 행동: 휴학 신청서 제출
- ✅ 구체적 행동: 휴학 신청서 작성 및 제출
- ✅ 다음 단계: 학과 → 교무처 순서
- ✅ 예상 결과: 휴학 승인 후 학적 변경
- ✅ 준비물/조건: 휴학 신청서, 보호자 동의서 (해당 시)
- ✅ 기한: 수업일수 2/3 이전
- ⚠️ 담당부서: 교무처 (연락처 누락)

[RAG 컴포넌트 기여 분석]
- Self-RAG: ✅ 검색 수행 결정 정확
- HyDE: ❌ 미발동 (명확한 쿼리)
- Query Analyzer: ✅ 휴학 인텐트 감지
- Corrective RAG: ❌ 미필요 (첫 검색 품질 충분)
- Reranker: ✅ 휴학 관련 규정 상위 배치

판정: ✅ 의도 충족 (6/6 통과)
행동 가능성: ✅ 사용자가 바로 행동 가능
```

---

### 2.7 예시 시나리오 (난이도별 + 컴포넌트 분석)

**페르소나**: 🎓 신입생

```
[쿼리 1 - 쉬움]
"휴학 신청 기간이 언제야?"

의도 분석:
- 표면적: 휴학 신청 기간 문의
- 숨겨진: 휴학을 고려 중
- 행동: 기간 내에 신청하고 싶음

기대 답변: 구체적 기간 (예: "학기 시작 전 방학 중" 또는 "수업일수 2/3 이전")

RAG 컴포넌트 기대 동작:
- Self-RAG: RETRIEVE_YES
- HyDE: 미발동 (명확한 쿼리)
- Query Analyzer: 휴학 인텐트 감지
- Corrective RAG: 미필요 (예상)

[쿼리 2 - 중간]
"장학금 받고 있는데 휴학하면 어떻게 돼?"

의도 분석:
- 표면적: 휴학 시 장학금 처리 문의
- 숨겨진: 장학금 유지하면서 휴학하고 싶음
- 행동: 휴학 결정 전 영향 파악

기대 답변: 장학금 중단/유지 조건, 복학 후 재신청 여부

RAG 컴포넌트 기대 동작:
- Query Analyzer: 복합 인텐트 (장학금 + 휴학)
- Hybrid Search: 두 주제 교차 검색
- Corrective RAG: 트리거 가능 (복합 쿼리)

[쿼리 3 - 어려움]
"돈이 없어서 학교 다니기 힘든데 어떡해야 할지 모르겠어요"

의도 분석:
- 표면적: 경제적 어려움 호소
- 숨겨진: 
  * 등록금 납부 어려움
  * 장학금/지원금 정보 필요
  * 휴학도 고려 중
  * 심리적 지지 필요
- 행동: 경제적 지원 받을 수 있는 모든 옵션 탐색

기대 답변: 장학금 + 등록금 분납 + 근로장학 + 긴급 지원 등 복합 안내

RAG 컴포넌트 기대 동작:
- Self-RAG: RETRIEVE_YES (정보 검색 필요)
- HyDE: ✅ 발동 (모호한 쿼리 → 가상 문서 생성)
- Query Analyzer: 경제적_어려움 인텐트 감지, 키워드 확장
- Hybrid Search: 장학금, 분납, 지원 관련 청크 검색
- Corrective RAG: 트리거 가능
- Reranker: 가장 관련성 높은 지원 규정 상위 배치
```

---

## Phase 3: 답변 품질 심층 검토 (강화됨)

### 3.1 필수 팩트체크 절차

> ⚠️ **모든 답변에 대해 아래 절차를 반드시 수행하세요. 생략 금지!**

각 답변에서 **핵심 주장 3개**를 추출하고 검증합니다:

```bash
# 1. 답변에서 언급된 규정/조항 확인
uv run regulation search "<규정명> 제X조" -n 3

# 2. 답변의 핵심 수치/기한 확인
uv run regulation search "<키워드> 기간|학점|요건" -n 5

# 3. 실제 검색 결과와 답변 내용 대조
```

**팩트체크 기록 형식:**
```
[팩트체크 #1]
- 답변 주장: "휴학은 수업일수 2/3까지 가능"
- 검증 쿼리: uv run regulation search "휴학 수업일수" -n 3
- 검증 결과: ✅ 학칙 제XX조에서 확인됨 / ❌ 해당 내용 없음 / ⚠️ 다른 내용임
```

### 3.2 답변 품질 평가 매트릭스 (엄격화)

| 항목 | 배점 | 평가 기준 | 자동 감점 조건 |
|------|------|----------|---------------|
| **정확성** | 1.0 | 규정 내용과 일치 | 팩트체크 실패 시 **0점** |
| **완전성** | 1.0 | 질문의 모든 측면에 답변 | 복합질문 중 1개 누락 시 **-0.5** |
| **관련성** | 1.0 | 질문 의도에 맞는 답변 | 50% 이상 무관한 내용 시 **0점** |
| **출처 명시** | 1.0 | 규정명/조항 인용 | 출처 없는 단정 시 **0점** |
| **실용성** | 0.5 | 기한/서류/담당부서 포함 | 절차질문에 기한 없으면 **-0.25** |
| **행동 가능성** | 0.5 | 사용자가 바로 행동 가능 | 기한/서류/담당부서 중 2개↑ 누락 시 **0점** |
| **합계** | 5.0 | | |

> ⚠️ **행동 가능성(Actionability)**: 답변을 읽은 사용자가 **추가 질문 없이 바로 행동**에 옮길 수 있어야 합니다.

### 3.3 성공/실패 판정 (엄격 기준)

| 판정 | 조건 | 성공률 계산 |
|------|------|------------|
| ✅ **성공** | 점수 ≥ 4.0 AND 팩트체크 모두 통과 | 성공으로 카운트 |
| ⚠️ **부분성공** | 점수 3.0~3.9 OR 팩트체크 1개 실패 | **실패로 카운트** |
| ❌ **실패** | 점수 < 3.0 OR 팩트체크 2개 이상 실패 | 실패로 카운트 |

### 3.4 실패 유형 및 심각도

| 실패 유형 | 설명 | 심각도 | 자동 판정 |
|----------|------|--------|----------|
| `WRONG_FACT` | 규정과 다른 정보 제공 | Critical | 즉시 실패 |
| `HALLUCINATION` | 존재하지 않는 규정/조항 언급 | Critical | 즉시 실패 |
| `GENERIC_ANSWER` | 일반론만 제시, 이 학교 규정 미인용 | High | 즉시 실패 |
| `IRRELEVANT` | 질문과 무관한 답변 | High | 즉시 실패 |
| `INCOMPLETE` | 핵심 정보 누락 (기한, 조건 등) | Medium | 부분성공 |
| `NO_SOURCE` | 출처 없이 단정적 답변 | Medium | 부분성공 |
| `CONFUSING` | 이해하기 어려운 답변 | Low | 감점 |

### 3.5 검토 체크리스트 (필수)

각 답변에 대해 **모두 확인**:

- [ ] **팩트체크 완료**: 핵심 주장 3개 검증 (검증 쿼리 실행 필수)
- [ ] **일반론 체크**: "대학마다 다를 수 있습니다" 같은 회피성 답변 아닌가?
- [ ] **구체성 체크**: 숫자(학점, 기간), 담당부서, 필요서류가 명시되었는가?
- [ ] **출처 체크**: 인용된 규정/조항이 실제로 존재하고 내용이 일치하는가?
- [ ] **누락 체크**: 중요한 예외사항, 주의사항이 빠지지 않았는가?
- [ ] **할루시네이션 체크**: 규정에 없는 내용을 지어내지 않았는가?
- [ ] **행동 가능성 체크**: 사용자가 바로 행동할 수 있는가?

---

### 3.6 일반론 답변 감지 패턴 (자동 실패)

> ⚠️ 다음 패턴이 답변에 포함되면 **GENERIC_ANSWER**로 즉시 실패 처리:

| 패턴 | 예시 | 이유 |
|------|------|------|
| `대학마다 다를 수 있습니다` | "일반적으로... 대학마다 다를 수 있습니다" | 회피성 답변 |
| `확인이 필요합니다` | "정확한 내용은 학교에 확인이 필요합니다" | 책임 회피 |
| `일반적으로` (규정 인용 없이) | "일반적으로 휴학은..." | 이 학교 규정 미인용 |
| `담당 부서에 문의` (구체 부서명 없이) | "자세한 내용은 담당 부서에 문의하세요" | 비구체적 안내 |
| `상황에 따라 다릅니다` (조건 미명시) | "상황에 따라 다릅니다" | 조건 미제시 |
| `정확한 정보는 확인 바랍니다` | "위 내용은 참고용이며..." | 책임 회피 |
| `학교마다 차이가 있을 수 있습니다` | "...학교마다 차이가 있을 수 있습니다" | 회피성 답변 |

**예외**: 규정에 실제로 "경우에 따라 다르다"고 명시된 경우는 출처와 함께 제시하면 허용

---

### 3.7 RAG 컴포넌트 기여도 분석 (신규 - 필수)

> ⚠️ **모든 테스트 쿼리에 대해 각 RAG 컴포넌트가 결과에 어떻게 기여했는지 분석합니다.**

#### 3.7.1 컴포넌트별 기여도 평가 기준

| 컴포넌트 | 긍정적 기여 | 부정적 영향 | 무영향 |
|----------|------------|------------|--------|
| **Self-RAG** | 불필요한 검색 스킵 / 무관한 결과 필터링 | 필요한 검색 스킵 / 관련 결과 제거 | 판단 정확하나 품질 변화 없음 |
| **HyDE** | 모호 쿼리에서 관련 결과 증가 | 오히려 무관한 결과 증가 | 발동 안됨 / 효과 없음 |
| **Corrective RAG** | 재검색으로 품질 개선 | 불필요한 재검색으로 지연 | 미트리거 |
| **Hybrid Search** | BM25+Dense 융합으로 균형 잡힌 결과 | 한쪽에 치우친 결과 | - |
| **Reranker** | 관련 결과 상위 배치 | 관련 결과 하위로 밀림 | 순위 변동 없음 |
| **Query Analyzer** | 의도 정확 파악 + 유용한 확장 | 잘못된 의도 파악 / 무관한 확장 | 확장 없음 |

#### 3.7.2 컴포넌트 기여도 기록 템플릿

```
[쿼리] "학교 가기 싫어요"

[RAG 컴포넌트 분석]

1. Self-RAG:
   - 동작: RETRIEVE_YES (검색 수행)
   - 기여도: ✅ 긍정적 (검색 필요성 정확 판단)

2. HyDE:
   - 동작: 가상 문서 생성 ("교직원의 휴직은 다음 각 호의...")
   - 기여도: ✅ 긍정적 (휴학/휴직 관련 결과 검색에 도움)
   - 생성된 키워드: [휴직, 휴학, 연구년]

3. Query Analyzer:
   - 감지 인텐트: 학교_가기_싫어
   - 확장 키워드: [휴직, 휴가, 연구년, 안식년]
   - 감지 청중: all (→ 개선 필요: 학생/교원 구분 필요)
   - 기여도: ⚠️ 부분적 (키워드 확장 유용, 청중 감지 부정확)

4. Hybrid Search:
   - BM25 결과: [휴학규정, 복무규정]
   - Dense 결과: [휴직규정, 연구년규정]
   - RRF 융합 결과: [휴학규정, 휴직규정, 복무규정, 연구년규정]
   - 기여도: ✅ 긍정적 (다양한 관련 결과)

5. Corrective RAG:
   - 동작: 미트리거 (첫 검색 품질 충분)
   - 기여도: - (해당 없음)

6. Reranker:
   - 재정렬 전: [휴학규정, 휴직규정, 복무규정]
   - 재정렬 후: [휴학규정, 휴직규정, 연구년규정]
   - 기여도: ✅ 긍정적 (학생 입장에서 더 관련 높은 결과 상위)

[종합 기여도 점수]
| 컴포넌트 | 점수 |
|----------|------|
| Self-RAG | +1 |
| HyDE | +2 |
| Query Analyzer | +1 |
| Hybrid Search | +1 |
| Corrective RAG | 0 |
| Reranker | +1 |
| **합계** | **+6** |

[개선 제안]
- Query Analyzer: 청중 감지 로직 개선 필요 ("가기 싫어" → 학생일 확률 높음)
```

---

### 3.8 후속 질문 제안 품질 검증

시스템이 제안하는 후속 질문(`suggestions`)이 사용자 의도 흐름과 일치하는지 검증합니다.

#### 검증 체크리스트
- [ ] **관련성**: 제안된 질문이 현재 주제와 관련있는가?
- [ ] **자연스러움**: 실제 사용자가 물어볼 법한 질문인가?
- [ ] **심화 방향**: 더 구체적인 정보로 안내하는가?
- [ ] **다양성**: 서로 다른 측면을 다루는가? (중복 없음)
- [ ] **실용성**: 사용자에게 실질적 도움이 되는 질문인가?

#### 후속 질문 품질 점수

| 점수 | 기준 |
|------|------|
| 5/5 | 모든 제안이 관련성 높고 자연스러움 |
| 4/5 | 1개 제안이 약간 관련성 부족 |
| 3/5 | 2개 제안이 관련성 부족 또는 중복 |
| 2/5 | 대부분 제안이 부적절 |
| 1/5 | 제안이 없거나 모두 무관함 |

#### 좋은/나쁜 후속 질문 예시

```
원래 질문: "휴학하고 싶어요"

❌ 나쁜 제안:
- "학교 역사가 궁금하신가요?" (무관함)
- "휴학이 무엇인가요?" (이미 알고 있음)
- "다른 규정을 검색하시겠습니까?" (너무 일반적)

✅ 좋은 제안:
- "휴학 기간은 얼마나 할 수 있나요?"
- "휴학 중 등록금은 어떻게 되나요?"
- "복학 절차도 알려드릴까요?"
```

---

## Phase 4: 멀티턴 대화 테스트 - 3턴 이상 필수 (핵심)

> ⚠️ **멀티턴 테스트는 선택이 아닌 필수입니다.** 모든 시나리오는 **최소 3턴 이상**의 후속 질문을 포함해야 합니다.

단일 쿼리를 넘어 **후속 질문 시나리오**를 테스트합니다.

### 4.1 후속 질문 유형

| 유형 | 설명 | 예시 | 빈도 |
|------|------|------|------|
| **구체화** | 더 자세한 정보 요청 | "그러면 정확히 몇 학점이야?" | 매우 높음 |
| **관련 확장** | 연관 주제로 확장 | "휴학하면 장학금은 어떻게 돼?" | 높음 |
| **예외 확인** | 특수 상황 문의 | "군대 가는 경우도 똑같아?" | 높음 |
| **절차 심화** | 구체적 절차 문의 | "신청서는 어디서 받아?" | 매우 높음 |
| **조건 변경** | 다른 조건에서의 적용 | "대학원생도 마찬가지야?" | 중간 |
| **확인 질문** | 이해 확인 | "그러니까 3월 전에 신청해야 한다는 거지?" | 높음 |
| **되돌아가기** | 이전 주제로 복귀 | "아까 장학금 얘기로 돌아가서..." | 중간 |
| **비교 요청** | 옵션 비교 | "그럼 일반휴학이랑 군휴학 중에 뭐가 나아요?" | 중간 |

### 4.2 멀티턴 시나리오 최소 요건 (강화)

> 각 페르소나에 대해 **2개 이상의 5턴 대화**를 실행 (필수)
> **모든 시나리오는 최소 3턴의 의미있는 후속 질문을 포함해야 함**

```
[Turn 1 - 초기 질문]
User: "휴학하고 싶어요"
→ 의도 추론: 표면(휴학 희망) + 숨겨진(절차/조건 알고 싶음)
→ 시스템 응답 확인
→ 중단점: 휴학 종류가 언급되지 않으면 실패

[Turn 2 - 후속 질문 1 (구체화)]
User: "일반휴학이요. 신청 기간은 언제예요?"
→ 의도 추론: 신청 기간 확인 → 기간 내 신청 계획
→ 맥락 검증: "일반휴학"이 맥락에 유지되는지 확인
→ RAG 컴포넌트: Query Analyzer가 휴학 유형 구체화 반영하는지

[Turn 3 - 후속 질문 2 (관련 확장)]
User: "장학금 받고 있는데 어떻게 돼요?"
→ 의도 추론: 휴학 시 장학금 영향 → 장학금 유지 가능성 탐색
→ 맥락 검증: 휴학 맥락 유지 + 장학금 정보 추가
→ RAG 컴포넌트: 복합 쿼리 처리 (휴학+장학금)

[Turn 4 - 후속 질문 3 (절차 심화)]
User: "그럼 복학할 때는요?"
→ 의도 추론: 복학 절차 → 휴학~복학 전체 사이클 이해
→ 맥락 검증: 휴학 → 장학금 → 복학 흐름 유지
→ RAG 컴포넌트: 컨텍스트 축적 및 연결

[Turn 5 - 후속 질문 4 (확인)]
User: "휴학 기간은 얼마까지 가능해요?"
→ 의도 추론: 최대 기간 확인 → 계획 수립
→ 최종 맥락 일관성 확인
```

### 4.3 각 Turn별 의도 추론 검증 (신규)

> ⚠️ **각 Turn마다 AI가 의도를 정확히 추론했는지 검증합니다.**

#### Turn별 의도 추론 체크리스트

각 후속 질문(Turn 2 이상)에 대해:

1. **맥락 연결**: 이전 Turn의 맥락을 올바르게 연결했는가?
2. **의도 진화**: 사용자 의도가 어떻게 발전했는지 추적했는가?
3. **암묵적 정보**: 명시하지 않은 정보(예: 휴학 유형)를 기억하는가?
4. **핵심 니즈**: 이번 Turn의 핵심 니즈를 파악했는가?

#### Turn별 의도 추론 기록 템플릿

```
[멀티턴 시나리오] 신입생 - 휴학 문의

=== Turn 1 ===
User: "휴학하고 싶어요"
[의도 추론]
- 표면: 휴학 희망
- 숨겨진: 절차/조건 알고 싶음
- AI 파악: ✅ 휴학 안내 제공
- RAG 동작: Self-RAG(O), HyDE(X), Corrective(X)

=== Turn 2 ===
User: "일반휴학이요. 신청 기간은 언제예요?"
[의도 추론]
- 맥락 연결: ✅ Turn 1의 휴학 맥락 유지
- 의도 진화: 휴학 유형 특정 → 기간 구체화
- 암묵적 정보: "일반휴학" (새로 제공됨)
- AI 파악: ✅ 일반휴학 신청 기간 안내
- RAG 동작: Query Analyzer(일반휴학 키워드 반영)

=== Turn 3 ===
User: "장학금 받고 있는데 어떻게 돼요?"
[의도 추론]
- 맥락 연결: ✅ 일반휴학 맥락 유지
- 의도 진화: 휴학 결정 전 영향 파악
- 암묵적 정보: "장학금 수혜 중" (새로 제공됨)
- AI 파악: ⚠️ 장학금 일반론만 제공 (휴학 연계 부족)
- RAG 동작: Corrective RAG 트리거됨 (복합 쿼리)

=== Turn 4 ===
User: "그럼 복학할 때는요?"
[의도 추론]
- 맥락 연결: ✅ 휴학 → 장학금 → 복학 흐름
- 의도 진화: 전체 사이클 이해
- 암묵적 정보: 일반휴학, 장학금 수혜 (누적)
- AI 파악: ✅ 복학 절차 + 장학금 재신청 안내
- RAG 동작: 컨텍스트 윈도우 내 누적 정보 활용

=== Turn 5 ===
User: "휴학 기간은 얼마까지 가능해요?"
[의도 추론]
- 맥락 연결: ✅ 일관성 유지
- 의도 진화: 구체적 계획 수립 단계
- AI 파악: ✅ 최대 휴학 기간 + 연장 조건 안내

[멀티턴 종합 평가]
- 맥락 유지율: 5/5 (100%)
- 의도 추론 정확도: 4/5 (80%) - Turn 3에서 복합 의도 파악 부족
- RAG 컴포넌트 기여도: +5 (Self-RAG +1, Query Analyzer +2, Corrective RAG +1, Reranker +1)
```

### 4.4 멀티턴 평가 기준 (확장)

| 항목 | 평가 내용 | 배점 |
|------|----------|------|
| **맥락 유지** | 이전 대화 내용을 기억하고 반영하는가? | 1.0 |
| **정보 일관성** | Turn 간에 모순되는 정보가 없는가? | 1.0 |
| **점진적 심화** | 후속 질문에 더 구체적인 정보를 제공하는가? | 1.0 |
| **중복 회피** | 이미 언급한 내용을 불필요하게 반복하지 않는가? | 0.5 |
| **자연스러운 전환** | 대화 흐름이 자연스러움 | 0.5 |
| **후속 질문 예측** | 적절한 후속 질문을 제안하는가? | 0.5 |
| **의도 추론 정확도** | 각 Turn에서 의도를 정확히 파악했는가? | 0.5 |
| **합계** | | 5.0 |

### 4.5 멀티턴 성공/실패 판정

| 판정 | 조건 | 성공률 계산 |
|------|------|------------|
| ✅ **성공** | 점수 ≥ 4.0 AND 모든 Turn에서 맥락 유지 AND 의도 추론 ≥ 80% | 성공 |
| ⚠️ **부분성공** | 점수 3.0~3.9 OR 1개 Turn에서 맥락 단절 OR 의도 추론 60~79% | **실패로 카운트** |
| ❌ **실패** | 점수 < 3.0 OR 2개↑ Turn에서 맥락 단절 OR 의도 추론 < 60% | 실패 |

### 4.6 CLI에서 멀티턴 테스트

**search 명령 실제 옵션:** 🆕
```bash
uv run regulation search "query" [OPTIONS]
  -n, --top-k INT      결과 개수 (기본: 10)
  -a, --answer         LLM 답변 생성
  -q, --quick          빠른 검색 (리랭킹 생략)
  --no-rerank          리랭킹 비활성화
  --debug              디버그 모드
  --interactive        대화형 모드
  --feedback           피드백 수집 모드
```

```bash
# 인터랙티브 모드로 멀티턴 테스트
uv run regulation

# 첫 질문 입력 후 후속 질문 연속 입력
# 각 Turn의 응답을 기록하고 맥락 유지 여부 확인
# --debug 옵션으로 RAG 컴포넌트 동작 확인

uv run regulation --debug
```

### 4.7 멀티턴 평가 기록 양식 (확장)

```
[시나리오] 신입생 - 휴학 문의
[실행 일시] 2026-01-15 14:30

=== Turn별 상세 평가 ===

Turn 1: ✅ 성공
- 의도 추론: ✅ 정확 (휴학 절차 안내 요청)
- 맥락 설정: ✅ 완료
- RAG: Self-RAG(검색 수행), Reranker(휴학 규정 상위)

Turn 2: ✅ 성공
- 의도 추론: ✅ 정확 (기간 구체화)
- 맥락 유지: ✅ "일반휴학" 반영
- RAG: Query Analyzer(키워드 반영)

Turn 3: ⚠️ 부분성공
- 의도 추론: ⚠️ 부분 (장학금 유형 미파악)
- 맥락 유지: ✅ 휴학 맥락 유지
- RAG: Corrective RAG 트리거, 재검색 수행

Turn 4: ✅ 성공
- 의도 추론: ✅ 정확 (복학 절차)
- 맥락 유지: ✅ 휴학→장학금→복학 흐름
- RAG: 컨텍스트 누적 활용

Turn 5: ✅ 성공
- 의도 추론: ✅ 정확 (기간 제한 확인)
- 맥락 유지: ✅ 일관성 유지

=== 종합 점수 ===
[멀티턴 점수]
- 맥락 유지: 5/5 (1.0)
- 정보 일관성: 5/5 (1.0)
- 점진적 심화: 4/5 (0.8)
- 중복 회피: 5/5 (0.5)
- 자연스러운 전환: 4/5 (0.4)
- 후속 질문 예측: 4/5 (0.4)
- 의도 추론 정확도: 4/5 (0.4)
- 총점: 4.5/5.0

[RAG 컴포넌트 종합 기여도]
| 컴포넌트 | 발동 횟수 | 기여도 |
|----------|----------|--------|
| Self-RAG | 5회 | +3 |
| HyDE | 0회 | 0 |
| Query Analyzer | 5회 | +4 |
| Corrective RAG | 1회 | +1 |
| Hybrid Search | 5회 | +3 |
| Reranker | 5회 | +2 |
| **합계** | | **+13** |

[판정] ✅ 성공
[근본 원인] Turn 3에서 복합 의도(휴학+장학금) 파악 개선 필요
[개선 제안] intents.json에 장학금_휴학 복합 인텐트 추가
```

---

## Phase 4.5: 실패 케이스 심층 분석 (5-Why + RAG 컴포넌트 분석)

실패한 모든 쿼리에 대해 **근본 원인 분석**을 수행합니다.

### 4.5.1 5-Why 분석 템플릿 (RAG 컴포넌트 포함)

```
[실패 쿼리] "장학금 받고 있는데 휴학하면 어떻게 돼?"
[실패 유형] INCOMPLETE

Why 1: 왜 실패했는가?
→ 장학금 유형별 처리 방법이 누락됨

Why 2: 왜 누락되었는가?
→ 검색 결과에 장학금-휴학 연계 정보가 없었음

Why 3: 왜 검색되지 않았는가?
→ "장학금 휴학" 키워드 조합이 인텐트에 없음

Why 4: 왜 인텐트에 없는가?
→ 복합 상황(A+B) 시나리오가 인텐트 설계에 미반영

Why 5: 근본 원인은?
→ 인텐트 설계가 단일 주제 중심이며, 주제 간 연계 시나리오 부재

[RAG 컴포넌트별 분석]
| 컴포넌트 | 동작 | 문제점 |
|----------|------|--------|
| Query Analyzer | 단일 인텐트만 매칭 | 복합 인텐트 미지원 |
| HyDE | 미발동 | 명확 쿼리로 판단 (오류) |
| Corrective RAG | 미트리거 | 임계값 조정 필요 |
| Hybrid Search | BM25가 장학금만 검색 | 복합 키워드 처리 미흡 |

[조치 방안]
1. data/config/intents.json에 복합 인텐트 추가
   - 예: "scholarship_leave" 인텐트 신설
2. Query Analyzer 복합 인텐트 지원 로직 추가
3. HyDE 발동 조건 완화 (복합 쿼리 포함)
```

### 4.5.2 실패 유형별 RAG 컴포넌트 원인 매핑

| 실패 유형 | 1차 원인 | 관련 RAG 컴포넌트 | 개선 방향 |
|----------|---------|-------------------|----------|
| `WRONG_FACT` | LLM이 잘못된 정보 생성 | **생성 단계** - 프롬프트 | prompts.json 수정 |
| `HALLUCINATION` | 존재하지 않는 규정 언급 | **생성 단계** - Grounding | Self-RAG 강화 |
| `GENERIC_ANSWER` | 규정 미인용 | **검색 단계** - 전체 | Query Analyzer + Corrective RAG |
| `IRRELEVANT` | 의도 파악 실패 | **분석 단계** - Query Analyzer | 인텐트 추가 |
| `INCOMPLETE` | 정보 누락 | **검색/생성** - Hybrid Search | 동의어 추가, top_k 증가 |
| `NO_SOURCE` | 출처 미명시 | **생성 단계** - 프롬프트 | prompts.json 수정 |

### 4.5.3 근본 원인별 개선 방향 (컴포넌트별)

| 근본 원인 | 관련 컴포넌트 | 개선 방향 | 담당 Phase |
|----------|-------------|----------|------------|
| **인텐트 미매칭** | Query Analyzer | intents.json 추가 | Phase 5.3 |
| **동의어 부족** | Hybrid Search (BM25) | synonyms.json 추가 | Phase 5.3 |
| **HyDE 미발동** | HyDE | 발동 조건 완화 | Phase 5.4 |
| **Corrective RAG 임계값** | Corrective RAG | 임계값 조정 | Phase 5.4 |
| **Reranker 순위 오류** | BGE Reranker | - (모델 제한) | 별도 검토 |
| **Self-RAG 오판** | Self-RAG | 프롬프트 개선 | Phase 5.4 |
| **프롬프트 문제** | LLM 생성 | prompts.json 수정 | Phase 5.4 |

### 4.5.4 분석 필수 실행 조건

다음 조건 중 하나라도 해당되면 **5-Why + RAG 컴포넌트 분석 필수**:

- ❌ 동일 실패 유형이 2회 이상 발생
- ❌ Critical 심각도 실패 발생 (`WRONG_FACT`, `HALLUCINATION`)
- ❌ 동적 쿼리 성공률 80% 미달
- ❌ 멀티턴 테스트에서 맥락 단절 발생
- ❌ 특정 RAG 컴포넌트 관련 실패 3회 이상

---

## Phase 5: 개선 적용 (실패 발생 시)

### 5.1 실패 분석

```bash
cat data/output/improvement_plan.json | python -m json.tool
```

### 5.2 제안 유형별 처리

| 유형 | 처리 방법 | 관련 RAG 컴포넌트 |
|------|----------|------------------|
| `intent` | `data/config/intents.json` 패치 | Query Analyzer |
| `synonym` | `data/config/synonyms.json` 패치 | Hybrid Search (BM25) |
| `code_pattern` | `src/rag/infrastructure/query_analyzer.py` 수정 | Query Analyzer |
| `code_weight` | 가중치 조정 | Corrective RAG / Reranker |
| `code_audience` | 대상 감지 로직 개선 | Query Analyzer |
| `hyde_condition` | HyDE 발동 조건 수정 | HyDE |
| `self_rag_prompt` | Self-RAG 프롬프트 수정 | Self-RAG |
| `prompt` | `data/config/prompts.json` 수정 | LLM 생성 |
| `architecture` | Phase 7에서 수동 검토 보고 | - |

### 5.3 데이터 패치 (intent/synonym)

**인텐트 추가** - `data/config/intents.json`:
```json
{
  "intent_id": "overseas_conference",
  "triggers": ["해외학회", "해외 학회", "국제학회"]
}
```

**복합 인텐트 추가** (신규):
```json
{
  "intent_id": "scholarship_leave",
  "triggers": ["장학금 휴학", "장학금 받고 휴학", "휴학하면 장학금"],
  "keywords": ["장학금", "휴학", "중단", "복학", "재신청"],
  "compound": true
}
```

**동의어 추가** - CLI 사용 권장 🆕:
```bash
# 방법 1: CLI (권장)
uv run regulation synonym add 휴학 학업중단
uv run regulation synonym add 휴학 학교출석건

# LLM 기반 동의어 제안 후 추가
uv run regulation synonym suggest "장학금"  # 제안 확인
uv run regulation synonym add 장학금 장학금지원  # 선택적 추가

# 방법 2: 수동 편집 (필요시)
# data/config/synonyms.json에 직접 추가
```

> 💡 **팁**: CLI를 사용하면 오타 방지 및 포맷 검증이 자동화됩니다.

### 5.4 코드 개선 (code_* / RAG 컴포넌트)

| 제안 유형 | 수정 파일 | 수정 대상 |
|-----------|----------|----------|
| `code_pattern` | `src/rag/infrastructure/query_analyzer.py` | `INTENT_PATTERNS` |
| `code_weight` | `src/rag/infrastructure/query_analyzer.py` | `WEIGHT_PRESETS` |
| `code_audience` | `src/rag/infrastructure/query_analyzer.py` | `*_KEYWORDS` 상수 |
| `hyde_condition` | `src/rag/infrastructure/hyde.py` | `_should_use_hyde()` 조건 |
| `self_rag_prompt` | `src/rag/infrastructure/self_rag.py` | 프롬프트 상수 |
| `corrective_threshold` | `src/rag/config.py` | `corrective_rag_thresholds` |
| `prompt` | `data/config/prompts.json` | 해당 프롬프트 키 |

**수정 원칙**: 기존 항목 삭제 금지, 새 항목만 추가

### 5.5 RAG 컴포넌트별 개선 예시

#### Self-RAG 개선
```python
# 검색 필요성 판단 개선 (self_rag.py)
# 복합 쿼리에서 검색 스킵 방지
if any(keyword in query for keyword in ["하면", "경우", "받고"]):
    return True  # 조건부 질문은 항상 검색
```

#### HyDE 개선
```python
# HyDE 발동 조건 완화 (hyde.py)
VAGUE_PATTERNS = [
    r"싶어|싫어",      # 의도 표현
    r"뭐가|어떤|어떻게",  # 불명확 질문
    r"알려|설명",      # 정보 요청
    r".+하면.+",      # 조건부 질문 (신규)
    r".+받고.+",      # 복합 상황 (신규)
]
```

#### Corrective RAG 임계값 조정
```python
# config.py
corrective_rag_thresholds = {
    "simple": 0.3,
    "medium": 0.4,
    "complex": 0.5,
    "compound": 0.35,  # 복합 쿼리용 (신규)
}
```

### 5.6 패치 검증
```bash
# Query Analyzer 테스트
uv run pytest tests/rag/unit/infrastructure/test_query_analyzer.py -v --tb=short

# Self-RAG 테스트
uv run pytest tests/rag/unit/infrastructure/test_self_rag.py -v --tb=short

# HyDE 테스트
uv run pytest tests/rag/unit/infrastructure/test_hyde.py -v --tb=short

# 전체 RAG 테스트
uv run pytest tests/rag/ -v --tb=short
```

---

## Phase 6: 재평가 및 반복 판단

### 6.1 단위 테스트 확인
```bash
uv run pytest tests/rag/ -v --tb=short
```

### 6.2 정적 평가 재실행
```bash
uv run python scripts/auto_evaluate.py --run
```

### 6.3 실패한 동적 쿼리 재테스트

Phase 3에서 실패한 쿼리들을 다시 테스트

### 6.4 반복 판단

**종료 조건** (하나라도 해당 시 Phase 7으로):
1. 모든 목표 달성
2. 개선 한계: 2회 연속 동일 결과
3. 최대 반복: 3회 사이클 완료
4. 구조적 문제: `architecture` 유형만 남음

종료 조건 미해당 시 **Phase 5로 반복**

---

## Phase 7: 완료 보고

### 7.1 세션 요약 생성

1. **시작 상태**
   - 정적 테스트 통과율
   - 시스템 상태 (규정 수, 조항 수)
   - 고급 RAG 설정 상태 (Self-RAG, HyDE, BM25 모드 등)

2. **RAG 컴포넌트 단위 테스트 결과** (신규)
   - 각 컴포넌트별 검증 결과
   - 발견된 이슈

3. **동적 테스트 결과**
   - 테스트한 페르소나 목록
   - 쿼리 난이도 분포
   - **팩트체크 수행 내역** (검증 쿼리 포함)
   - 성공/부분성공/실패 비율
   - **의도 추론 정확도**

4. **멀티턴 테스트 결과**
   - 테스트한 시나리오 수
   - 맥락 유지 성공률
   - **Turn별 의도 추론 정확도**

5. **답변 품질 점수**
   - 항목별 평균 점수
   - **주요 실패 유형 분포**

6. **RAG 컴포넌트 기여도 종합** (신규)
   - 컴포넌트별 발동 횟수
   - 컴포넌트별 기여도 점수
   - 가장 효과적인 컴포넌트
   - 개선이 필요한 컴포넌트

7. **적용된 개선**
   - 인텐트/동의어 추가 내역
   - 코드 수정 내역
   - RAG 컴포넌트 설정 변경 내역

8. **최종 상태**
   - 최종 통과율
   - **남은 문제 및 원인 분석**

9. **다음 단계 권장사항**
   - 우선순위별 개선 항목
   - RAG 컴포넌트별 개선 제안

### 7.2 결과 저장 위치
- 세션 요약: `data/output/test_session_<날짜>.md`
- 실패 쿼리 목록: `data/output/failed_queries_<날짜>.json`

---

## 트러블슈팅

```bash
# LLM 연결 확인 (lmstudio)
curl -s http://game-mac-studio:1234/v1/models | python3 -c "import sys,json; print(json.load(sys.stdin))"

# 특정 테스트 디버깅
uv run pytest tests/rag/unit/infrastructure/test_query_analyzer.py::test_specific -v -s

# RAG 컴포넌트별 테스트
uv run pytest tests/rag/unit/infrastructure/test_self_rag.py -v -s
uv run pytest tests/rag/unit/infrastructure/test_hyde.py -v -s
uv run pytest tests/rag/unit/infrastructure/test_retrieval_evaluator.py -v -s

# 변경사항 확인/되돌리기
git diff data/config/
git checkout -- data/config/intents.json

# 규정 내용 직접 확인 (팩트체크용)
uv run regulation search "<규정명>" -n 10

# 특정 조항 확인
uv run regulation search "<규정명> 제N조"

# 디버그 모드로 RAG 파이프라인 확인
uv run regulation --debug search "<쿼리>" -a -n 5

# HyDE 캐시 확인/초기화
cat data/cache/hyde/hyde_cache.json | python -m json.tool
rm data/cache/hyde/hyde_cache.json  # 캐시 초기화

# RAG 설정 임시 변경 테스트
ENABLE_HYDE=false uv run regulation search "<쿼리>" -n 5
ENABLE_SELF_RAG=false uv run regulation search "<쿼리>" -n 5
BM25_TOKENIZE_MODE=simple uv run regulation search "<쿼리>" -n 5

# 동의어 관리 (synonym CLI) 🆕
uv run regulation synonym suggest "휴학"       # LLM 기반 동의어 제안
uv run regulation synonym add 휴학 학업중단    # 동의어 추가
uv run regulation synonym remove 휴학         # 동의어 삭제
uv run regulation synonym list                # 전체 동의어 목록
```

---

## 체크리스트

### 기본 검증
- [ ] Phase 0: 시스템 상태 확인
- [ ] Phase 0: 고급 RAG 설정 확인
- [ ] Phase 1: 정적 평가 완료

### RAG 컴포넌트 검증 (신규)
- [ ] Phase 1.5: Self-RAG 검증 완료
- [ ] Phase 1.5: HyDE 검증 완료 (ON/OFF 비교)
- [ ] Phase 1.5: Corrective RAG 검증 완료
- [ ] Phase 1.5: Hybrid Search 검증 완료
- [ ] Phase 1.5: Reranker 검증 완료 (ON/OFF 비교)
- [ ] Phase 1.5: Query Analyzer 검증 완료
- [ ] Phase 1.5: 컴포넌트 통합 테스트 완료
- [ ] Phase 1.5: **Fact Check 검증 완료 (선택적)** 🆕
- [ ] Phase 1.5: **입력 검증/보안 테스트 완료** 🆕

### 동적 테스트
- [ ] Phase 2: 페르소나 선택 (3~5개)
- [ ] Phase 2: **난이도 분포 반영** (쉬움 30%, 중간 40%, 어려움 30%)
- [ ] Phase 2: 쿼리 생성 및 실행
- [ ] Phase 2: **의도 추론 검증 완료** (3단계 의도 분석)
- [ ] Phase 2: **의도 충족 검증 완료** (모든 쿼리)
- [ ] Phase 3: **모든 답변 팩트체크 완료**
- [ ] Phase 3: **일반론 답변 패턴 체크 완료**
- [ ] Phase 3: **RAG 컴포넌트 기여도 분석 완료**
- [ ] Phase 3: **후속 질문 제안 품질 검증 완료**
- [ ] Phase 3: 답변 품질 검토 완료 (평균 ≥ 4.0)

### 멀티턴 테스트 (필수)
- [ ] Phase 4: 멀티턴 시나리오 실행 **(페르소나당 2개 × 5턴 이상)**
- [ ] Phase 4: **각 Turn별 의도 추론 검증 완료**
- [ ] Phase 4: 맥락 유지 확인 (각 Turn별)
- [ ] Phase 4: 멀티턴 점수 산정 완료 (평균 ≥ 4.0)
- [ ] Phase 4: 후속 질문 성공률 확인 (≥ 85%)
- [ ] Phase 4: 의도 추론 정확도 확인 (≥ 80%)

### 실패 분석
- [ ] Phase 4.5: 실패 케이스 5-Why 분석 완료 (해당 시)
- [ ] Phase 4.5: **RAG 컴포넌트별 원인 분석 완료**
- [ ] Phase 4.5: 근본 원인 카테고리화 완료

### 개선 및 완료
- [ ] Phase 5: 개선 적용 (필요시)
- [ ] Phase 5: **RAG 컴포넌트별 개선 적용** (해당 시)
- [ ] Phase 6: 재평가 완료
- [ ] Phase 7: 보고서 생성 (RAG 기여도 포함)

---

## 부록 A: 엄격한 테스트 세션 예시 (RAG 컴포넌트 분석 포함)

```
=== RAG 품질 테스트 세션 시작 ===
날짜: 2026-01-15
테스터: AI Agent (엄격 모드)
RAG 설정: Self-RAG=ON, HyDE=ON, BM25=konlpy, Reranker=ON

[Phase 0] 시스템 상태: OK (318개 규정, 17254개 조항)
[Phase 0] RAG 설정: ENABLE_SELF_RAG=true, ENABLE_HYDE=true, BM25_TOKENIZE_MODE=konlpy

[Phase 1] 정적 테스트: 50/50 통과 (100%)

[Phase 1.5] RAG 컴포넌트 단위 테스트
- Self-RAG: ✅ 인사말 스킵, 정보 쿼리 검색 정상
- HyDE: ✅ "학교 가기 싫어" 테스트 통과 (휴학 결과 증가)
- Corrective RAG: ✅ 낮은 품질 결과에서 재검색 트리거
- Hybrid Search: ✅ BM25+Dense 융합 정상
- Fact Check: ⚠️ 선택적 (ENABLE_FACT_CHECK=false)
- 보안 검증: ✅ XSS/SQL Injection 패턴 차단 확인
- Reranker: ✅ 관련 결과 상위 배치
- Query Analyzer: ⚠️ 복합 인텐트 매칭 부족 (개선 필요)

[Phase 2] 동적 테스트
선택된 페르소나: 신입생, 대학원생, 불만있는 구성원

--- 페르소나: 신입생 ---

[쿼리 1 - 쉬움] "휴학 신청 기간이 언제야?"

[의도 추론]
- 표면적: 휴학 신청 기간 문의
- 숨겨진: 휴학 고려 중, 기간 내 신청 계획
- 행동: 기간 확인 후 신청 준비
- AI 파악: ✅ 정확 (휴학 기간 안내)
- 의도 추론 정확도: 100%

[RAG 컴포넌트 동작]
- Self-RAG: RETRIEVE_YES ✅
- HyDE: 미발동 (명확한 쿼리) ✅
- Query Analyzer: 휴학 인텐트 감지 ✅
- Corrective RAG: 미트리거 (품질 충분) ✅
- Reranker: 휴학규정 상위 배치 ✅

답변 요약: "학기 시작 전 방학 기간 또는 수업일수 2/3 이전..."

[팩트체크]
#1: "수업일수 2/3 이전" 
   검증: uv run regulation search "휴학 수업일수" -n 3
   결과: ✅ 학칙 제XX조 "수업일수의 3분의 2선까지" 확인

#2: "방학 기간" 
   검증: uv run regulation search "휴학 방학" -n 3  
   결과: ✅ 휴학규정 제X조 확인

점수: 정확성 1.0 + 완전성 0.8 + 관련성 1.0 + 출처 1.0 + 실용성 0.8 + 행동가능성 0.5 = 4.6
판정: ✅ 성공

---

[쿼리 2 - 중간] "장학금 받고 있는데 휴학하면 어떻게 돼?"

[의도 추론]
- 표면적: 휴학 시 장학금 처리 문의
- 숨겨진: 장학금 유지하면서 휴학하고 싶음, 복학 후 상황 알고 싶음
- 행동: 휴학 결정 전 영향 파악
- AI 파악: ⚠️ 부분적 (장학금 중단만 언급, 복학 후 재신청 미언급)
- 의도 추론 정확도: 70%

[RAG 컴포넌트 동작]
- Self-RAG: RETRIEVE_YES ✅
- HyDE: 미발동 ⚠️ (복합 쿼리인데 미발동)
- Query Analyzer: 단일 인텐트만 매칭 ⚠️
- Corrective RAG: 트리거됨 ✅ (복합 쿼리로 첫 검색 부족)
- Reranker: 장학금 규정 상위 ✅

답변 요약: "휴학 시 장학금은 중단되며..."

[팩트체크]
#1: "장학금 중단"
   검증: uv run regulation search "휴학 장학금" -n 5
   결과: ⚠️ 명확한 규정 없음, 장학금 유형별로 다를 수 있음

#2: "복학 후 재신청"
   검증: uv run regulation search "장학금 재신청" -n 3
   결과: ❌ 해당 내용 찾을 수 없음 (답변에서도 누락)

점수: 정확성 0.5 + 완전성 0.7 + 관련성 1.0 + 출처 0.5 + 실용성 0.5 + 행동가능성 0.3 = 3.0
판정: ⚠️ 부분성공 → **실패로 카운트**
실패 유형: INCOMPLETE
RAG 원인: Query Analyzer 복합 인텐트 미지원, HyDE 미발동

---

[쿼리 3 - 어려움] "돈이 없어서 학교 다니기 힘든데 어떡해야 할지 모르겠어요"

[의도 추론]
- 표면적: 경제적 어려움 호소
- 숨겨진: 등록금 납부 어려움, 장학금/지원금 필요, 휴학도 고려, 심리적 지지
- 행동: 경제적 지원 옵션 탐색
- AI 파악: ✅ 대부분 파악 (장학금, 분납, 근로장학 안내)
- 의도 추론 정확도: 90%

[RAG 컴포넌트 동작]
- Self-RAG: RETRIEVE_YES ✅
- HyDE: 발동 ✅ (가상 문서: "교직원의 경제적 지원은...")
- Query Analyzer: 경제적_어려움 인텐트 ✅, 키워드 확장 ✅
- Corrective RAG: 미트리거 (HyDE로 품질 확보) ✅
- Reranker: 장학금, 분납 규정 상위 ✅

[HyDE 효과 분석]
- HyDE OFF 결과: [일반 학사 규정]
- HyDE ON 결과: [장학금규정, 등록금분납규정, 근로장학생규정]
- 효과: ✅ 매우 긍정적 (+3)

답변 요약: "장학금 종류로는... 등록금 분납 제도가..."

[팩트체크]
#1: "국가장학금" - ✅ 장학금규정 확인
#2: "등록금 분납" - ✅ 등록금납부규정 확인
#3: "근로장학금" - ✅ 근로장학생규정 확인

점수: 정확성 1.0 + 완전성 0.9 + 관련성 1.0 + 출처 0.8 + 실용성 0.9 + 행동가능성 0.5 = 4.6
판정: ✅ 성공

---

[Phase 3] 품질 점수 (엄격 모드)
- 정확성: 4.2/5.0
- 완전성: 3.8/5.0
- 관련성: 4.6/5.0
- 출처 명시: 3.7/5.0
- 실용성: 3.7/5.0
- 행동 가능성: 3.5/5.0
- 평균: 3.9/5.0 ⚠️

[RAG 컴포넌트 기여도 종합]
| 컴포넌트 | 발동 | 기여도 | 주요 이슈 |
|----------|------|--------|----------|
| Self-RAG | 9/9 | +6 | 정상 |
| HyDE | 3/9 | +5 | 복합 쿼리 발동 필요 |
| Query Analyzer | 9/9 | +4 | 복합 인텐트 개선 필요 |
| Corrective RAG | 2/9 | +2 | 정상 |
| Hybrid Search | 9/9 | +5 | 정상 |
| Reranker | 9/9 | +4 | 정상 |

동적 쿼리 결과:
- 성공: 6개
- 부분성공(=실패): 3개
- 실패: 1개
- **성공률: 60%** ❌ (목표 80% 미달)

[Phase 4] 멀티턴 테스트 (신입생 - 휴학 문의)

Turn 1: "휴학하고 싶어요" - ✅ 의도 추론 정확
Turn 2: "일반휴학이요. 신청 기간은?" - ✅ 맥락 유지
Turn 3: "장학금 받고 있는데요?" - ⚠️ 복합 의도 부분 파악
Turn 4: "복학할 때는요?" - ✅ 맥락 누적
Turn 5: "휴학 기간은 얼마까지?" - ✅ 일관성 유지

멀티턴 점수: 4.2/5.0 ✅
의도 추론 정확도: 80% ✅
맥락 유지율: 100% ✅

[Phase 4.5] 실패 분석 (5-Why + RAG)

실패 쿼리: "장학금 받고 있는데 휴학하면?"
Why 5 근본 원인: 복합 인텐트 설계 부재
RAG 원인: Query Analyzer 단일 인텐트만 매칭, HyDE 발동 조건 미충족

[Phase 5] 개선 필요
1. intents.json: 복합 인텐트 추가 (scholarship_leave)
2. hyde.py: 복합 쿼리 발동 조건 추가
3. query_analyzer.py: 복합 인텐트 매칭 로직

[Phase 7] 최종 결과
- 정적 테스트: 100% ✅
- RAG 컴포넌트 테스트: 6/7 통과 (Query Analyzer 개선 필요)
- 동적 쿼리 성공률: 60% ❌
- 멀티턴 성공률: 80% ✅
- 의도 추론 정확도: 82% ⚠️
- 답변 품질: 3.9/5.0 ⚠️
- 회귀: 없음

결론: 복합 쿼리 처리 개선 필요 - Query Analyzer + HyDE 개선 권장 ⚠️
```

---

## 부록 B: 멀티턴 시나리오 템플릿 라이브러리 (의도 추론 + RAG 분석 포함)

페르소나별 대표 멀티턴 시나리오입니다. 각 시나리오는 **5턴 이상**으로 구성되며, **각 Turn별 의도 추론 및 RAG 컴포넌트 동작**을 검증합니다.

### B.1 🎓 신입생 시나리오

#### 시나리오 1: 휴학 문의 → 장학금 연계 → 복학
```
[Turn 1] "휴학하고 싶어요"
의도 추론:
- 표면: 휴학 희망
- 숨겨진: 절차/조건 알고 싶음, 휴학 유형 파악 필요
- 행동: 휴학 가능 여부 및 방법 파악
기대: 휴학 종류, 기본 절차 안내
중단점: 휴학 종류가 언급되지 않으면 실패
RAG 기대: Self-RAG(검색), Query Analyzer(휴학 인텐트)

[Turn 2] "일반휴학이요. 신청 기간이 언제예요?"
의도 추론:
- 맥락 연결: Turn 1 휴학 → 일반휴학 구체화
- 의도 진화: 유형 결정 → 기간 확인
- 암묵적 정보: "일반휴학" 선택 (새로 제공)
기대: 구체적 신청 기간 + 필요 서류
맥락 검증: "일반휴학"이 맥락에 유지되는지 확인
RAG 기대: Query Analyzer(키워드 "일반휴학" 반영)

[Turn 3] "장학금 받고 있는데 어떻게 돼요?"
의도 추론:
- 맥락 연결: 일반휴학 맥락 유지
- 의도 진화: 휴학 결정 전 영향 파악
- 암묵적 정보: "장학금 수혜 중" (새로 제공)
- 숨겨진: 장학금 유지 가능성 탐색, 복학 후 재수혜 가능?
기대: 장학금 유형별 처리 방법
맥락 검증: 휴학 맥락 유지 + 장학금 정보 추가
RAG 기대: 복합 인텐트 처리, Corrective RAG 가능

[Turn 4] "그럼 복학할 때는요?"
의도 추론:
- 맥락 연결: 휴학 → 장학금 → 복학 전체 흐름
- 의도 진화: 전체 사이클 이해
- 암묵적 정보: 일반휴학, 장학금 수혜 (누적)
기대: 복학 절차 + 장학금 재신청 여부
맥락 검증: 휴학 → 장학금 → 복학 흐름 유지

[Turn 5] "휴학 기간은 얼마까지 가능해요?"
의도 추론:
- 맥락 연결: 전체 흐름 유지
- 의도 진화: 구체적 계획 수립
기대: 최대 휴학 기간 + 연장 가능 여부
```

#### 시나리오 2: 경제적 어려움 → 종합 지원
```
[Turn 1] "돈이 없어서 학교 다니기 힘들어요"
의도 추론:
- 표면: 경제적 어려움 호소
- 숨겨진: 등록금 문제, 장학금 필요, 휴학도 고려, 심리적 지지
- 행동: 지원 옵션 탐색
기대: 공감 + 지원 옵션 개요 (장학금, 분납, 근로)
중단점: 단순 위로만 하면 실패
RAG 기대: HyDE 발동 (모호 쿼리), Query Analyzer(경제적_어려움)

[Turn 2] "장학금 종류가 뭐가 있어요?"
의도 추론:
- 맥락 연결: 경제적 어려움 → 장학금 탐색
- 의도 진화: 옵션 중 장학금 심화
기대: 교내/교외 장학금 목록 + 신청 조건

[Turn 3] "성적이 안 좋은데도 받을 수 있어요?"
의도 추론:
- 맥락 연결: 장학금 맥락 유지
- 의도 진화: 자격 조건 확인 (본인 상황에 맞는지)
- 암묵적 정보: 성적 부진 (새로 제공)
기대: 성적 기준 + 성적 무관 장학금 안내

[Turn 4] "등록금 분납은 어떻게 해요?"
의도 추론:
- 맥락 연결: 경제적 어려움 맥락 유지
- 의도 진화: 다른 옵션(분납) 탐색
기대: 분납 신청 절차 + 기한 + 조건

[Turn 5] "근로장학생은요?"
의도 추론:
- 맥락 연결: 경제적 지원 흐름
- 의도 진화: 또 다른 옵션(근로) 탐색
기대: 근로장학 신청 방법 + 근무 조건 + 급여
```

### B.2 📚 재학생 (3학년) 시나리오

#### 시나리오 1: 졸업요건 확인 → 부족학점 해결
```
[Turn 1] "졸업하려면 뭐가 필요해요?"
의도 추론:
- 표면: 졸업요건 문의
- 숨겨진: 졸업 가능 여부 확인, 부족한 부분 파악
기대: 졸업요건 개요 (학점, 필수과목, 외국어 등)
중단점: 구체적 학점 수치 없으면 실패

[Turn 2] "전공학점이 몇 학점이에요?"
기대: 전공 필수/선택 학점 구분 + 합계

[Turn 3] "교양은요?"
기대: 교양 필수/선택 학점 + 영역별 요건
맥락 검증: 졸업요건 흐름 유지

[Turn 4] "지금 부족한 학점 확인하려면?"
기대: 학점 확인 방법 (포털, 학사시스템 등)

[Turn 5] "계절학기로 채울 수 있어요?"
기대: 계절학기 학점 인정 조건 + 신청 방법
```

#### 시나리오 2: 복수전공 → 졸업연기
```
[Turn 1] "복수전공 하고 싶어요"
기대: 복수전공 개요 + 신청 자격

[Turn 2] "신청 기간이 언제예요?"
기대: 구체적 신청 기간 + 필요 서류

[Turn 3] "학점은 얼마나 더 들어야 해요?"
기대: 복수전공 이수학점 + 기존 학점과의 관계

[Turn 4] "그러면 졸업이 늦어지나요?"
기대: 졸업 연기 가능성 + 초과학기 등록금

[Turn 5] "중간에 포기할 수도 있어요?"
기대: 복수전공 포기 절차 + 이수 학점 처리
```

### B.3 🎓 대학원생 시나리오

#### 시나리오 1: 논문 심사 → 학위 취득
```
[Turn 1] "논문 심사 절차가 어떻게 되나요?"
기대: 심사 단계 개요 (예심, 본심 등)

[Turn 2] "예비심사는 언제 신청해요?"
기대: 예심 신청 기간 + 조건 + 필요 서류

[Turn 3] "심사위원은 어떻게 정해지나요?"
기대: 심사위원 구성 방법 + 자격 요건

[Turn 4] "본심사까지 기간은요?"
기대: 예심-본심 간 최소 기간

[Turn 5] "심사 통과 후 학위 수여까지는요?"
기대: 학위 수여 절차 + 일정
```

### B.4 👨‍🏫 신임 교수 시나리오

#### 시나리오 1: 연구년 문의
```
[Turn 1] "연구년 제도에 대해 알고 싶습니다"
기대: 연구년 개요 + 자격 조건 요약

[Turn 2] "신청 자격이 어떻게 되나요?"
기대: 구체적 자격 요건 (재직 기간, 업적 등)

[Turn 3] "해외 연구년도 가능한가요?"
기대: 해외 연구년 조건 + 지원 내용

[Turn 4] "연구년 중 급여는 어떻게 되나요?"
기대: 급여 지급 비율 + 조건

[Turn 5] "신청 절차와 기한을 알려주세요"
기대: 구체적 절차 + 신청 기한 + 필요 서류
```

### B.5 🤕 어려운 상황의 학생 시나리오

#### 시나리오 1: 학사경고 → 대처방안
```
[Turn 1] "학사경고 받았어요... 어떡하죠?"
기대: 공감 + 학사경고 의미 + 대처 옵션
중단점: 공감 없이 규정만 나열하면 부분성공

[Turn 2] "몇 번 받으면 제적이에요?"
기대: 구체적 제적 기준 (연속/누적)

[Turn 3] "이번 학기 성적 올리면 괜찮아요?"
기대: 학사경고 해제 조건 + 유예 제도 안내

[Turn 4] "성적이 너무 안 좋은 과목 철회할 수 있어요?"
기대: 수강 철회/포기 제도 + 조건 + 기한

[Turn 5] "학습 도움 받을 수 있는 곳 있어요?"
기대: 학습지원센터, 튜터링 등 지원 프로그램
```

#### 시나리오 2: 성적 이의 → 고충 처리
```
[Turn 1] "교수님 성적이 너무 불공정해요"
기대: 공감 + 성적 이의 제도 안내
중단점: 감정 무시하고 절차만 설명하면 부분성공

[Turn 2] "이의신청은 어떻게 해요?"
기대: 이의신청 절차 + 기한 + 필요 서류

[Turn 3] "교수님이 안 받아주면요?"
기대: 상위 기관 절차 (학과 → 단과대 등)

[Turn 4] "그래도 안 되면 어디에 신고해요?"
기대: 고충처리 기관 안내 (학생인권센터 등)

[Turn 5] "신고하면 불이익 없어요?"
기대: 비밀보장 + 보복 금지 규정 안내
```

### B.6 😡 불만있는 구성원 시나리오

#### 시나리오 1: 부당대우 신고
```
[Turn 1] "교수님한테 부당한 대우를 받았어요"
기대: 공감 + 상황 파악 질문 또는 신고 채널 안내

[Turn 2] "연구실에서 부당한 업무 지시를 받아요"
기대: 연구실 관련 고충처리 절차 안내

[Turn 3] "신고하면 어떻게 처리되나요?"
기대: 신고 접수 → 조사 → 결과 통보 절차

[Turn 4] "익명으로 할 수 있어요?"
기대: 익명 신고 가능 여부 + 방법

[Turn 5] "신고 후 보복당하면요?"
기대: 보복 금지 규정 + 추가 신고 채널
```

### B.7 페르소나 선택 가이드

매 테스트 세션마다 아래 기준으로 **3~5개 페르소나**를 선택하세요:

| 선택 기준 | 권장 조합 |
|----------|----------|
| **균형 테스트** | 신입생 + 재학생 + 교수 + 직원 |
| **학생 집중** | 신입생 + 재학생 + 대학원생 + 어려운 상황 학생 |
| **교직원 집중** | 신임 교수 + 정교수 + 신입 직원 + 과장급 직원 |
| **고충/민원 집중** | 어려운 상황 학생 + 불만있는 구성원 + 학부모 |
| **신규 구성원** | 신입생 + 신임 교수 + 신입 직원 |
| **복합 쿼리 테스트** | 경제적 어려움 학생 + 졸업 준비 재학생 |

### B.7 RAG 컴포넌트별 테스트 시나리오 (신규)

RAG 컴포넌트별 동작 검증에 특화된 시나리오입니다.

#### Self-RAG 테스트 시나리오
검색 필요성 판단이 올바르게 작동하는지 검증합니다.
```
[Turn 1] "안녕하세요" → 기대: RETRIEVE_NO (인사말)
[Turn 2] "감사합니다" → 기대: RETRIEVE_NO (감사 표현)
[Turn 3] "휴학 신청 기간이 언제예요?" → 기대: RETRIEVE_YES (정보 요청)
[Turn 4] "아 네 알겠어요" → 기대: RETRIEVE_NO (확인 응답)
[Turn 5] "근데 장학금은 어떻게 돼요?" → 기대: RETRIEVE_YES (추가 정보)
```

#### HyDE 테스트 시나리오
모호한 쿼리에서 HyDE가 적절히 발동하는지 검증합니다.
```
[Turn 1] "학교 너무 힘들어요" → HyDE 발동 기대 (모호한 표현)
[Turn 2] "휴학 말고 다른 방법은요?" → HyDE 발동 기대 (열린 질문)
[Turn 3] "일반휴학 신청 기간" → HyDE 미발동 기대 (명확한 키워드)
[Turn 4] "돈이 없는데 뭔가 방법이 없을까요?" → HyDE 발동 기대 (탐색적 질문)
[Turn 5] "장학금 종류" → HyDE 미발동 기대 (구체적 질문)
```

#### Corrective RAG 테스트 시나리오
검색 품질이 낮을 때 재검색이 트리거되는지 검증합니다.
```
[Turn 1] "희귀한키워드조합검색" → Corrective RAG 트리거 기대 (검색 품질 낮음)
[Turn 2] "휴학이랑 장학금이랑 등록금 분납 다 알려줘" → 트리거 기대 (복합 쿼리)
[Turn 3] "휴학 신청" → 트리거 안됨 기대 (단순 키워드, 품질 충분)
```

#### Query Analyzer 복합 인텐트 테스트
복합 상황의 의도를 정확히 파악하는지 검증합니다.
```
[Turn 1] "장학금 받는데 휴학하면?" → 복합 인텐트 (장학금+휴학)
[Turn 2] "졸업하려면 복수전공 학점도 필요해?" → 복합 인텐트 (졸업+복수전공)
[Turn 3] "연구년 가면서 겸직도 가능해?" → 복합 인텐트 (연구년+겸직)
```

#### Hybrid Search 균형 테스트
BM25(키워드)와 Dense(의미) 검색의 균형을 검증합니다.
```
[Turn 1] "교원인사규정 제8조" → BM25 우세 기대 (정확한 키워드)
[Turn 2] "교수가 승진하려면" → Dense 우세 기대 (의미적 질문)
[Turn 3] "휴학 신청 방법" → 균형 기대 (혼합형)
```
