# RAG 시스템 품질 테스트 및 개선

AI 에이전트가 다양한 사용자 페르소나를 시뮬레이션하여 RAG 시스템의 품질을 **엄격하게** 테스트하고, 답변 품질을 **비판적으로** 검토하는 워크플로우입니다.

## ⚠️ 평가자 마인드셋 (중요!)

> **당신은 까다로운 품질 검수자입니다. 사용자 입장에서 "이게 정말 도움이 되는가?"를 냉정하게 판단하세요.**
>
> - ❌ "대체로 맞는 것 같다" → 팩트체크 없이 통과시키지 마세요
> - ❌ "규정 조항이 언급되었다" → 그 조항이 실제로 존재하는지 확인했나요?
> - ❌ "답변이 길고 상세하다" → 핵심 정보가 정확한지가 중요합니다
> - ❌ "일반적으로 맞는 내용이다" → **이 학교**의 규정과 일치하는지 확인하세요
> - ❌ "절차를 설명했다" → 구체적인 기한, 서류, 담당부서가 명시되었나요?

## 성공 기준

| 메트릭 | 목표 | 엄격 모드 적용 |
|--------|------|---------------|
| 정적 테스트 통과율 | ≥ 85% | - |
| 동적 쿼리 성공률 | ≥ 80% | **"부분 성공" = 실패**로 카운트 |
| 멀티턴 대화 성공률 | ≥ 80% | **필수** (기존 75% → 80%로 상향) |
| **후속 질문 성공률** | **≥ 85%** | **신규 추가** - 각 Turn별 성공률 |
| 답변 품질 점수 | ≥ 4.0/5.0 | 팩트체크 실패 시 **최대 2.0점** |
| 회귀 발생 | 0건 | - |
| **팩트체크 수행률** | **100%** | 모든 답변 필수 검증 |
| **의도 충족률** | **≥ 90%** | 사용자가 바로 행동 가능해야 함 |

---

## Phase 0: 사전 검증

### 0.1 시스템 상태 확인
```bash
uv run regulation status
```

### 0.2 데이터가 없으면 동기화
```bash
uv run regulation sync data/output/규정집.json
```

### 0.3 LLM 연결 확인
```bash
# .env 파일에서 LLM_PROVIDER 확인 후 해당 서버 체크
# lmstudio인 경우:
curl -s $LLM_BASE_URL/v1/models | head -5
# ollama인 경우:
curl http://localhost:11434/api/tags 2>/dev/null || echo "Ollama 미실행"
```

---

## Phase 1: 정적 평가 실행

### 1.1 자동 평가 실행
```bash
uv run python scripts/auto_evaluate.py --run
```

### 1.2 결과 확인
- 통과율 ≥ 85% → Phase 2로 이동
- 통과율 < 85% → Phase 5 (개선 적용)로 이동

---

## Phase 2: 동적 쿼리 테스트 (핵심)

매 실행마다 **다양한 페르소나**와 **새로운 쿼리**를 생성하여 시스템을 테스트합니다.

### 2.1 페르소나 정의

테스트할 때마다 아래 페르소나 중 **3~5개를 무작위 선택**합니다:

| 페르소나 | 특성 | 예상 관심사 |
|----------|------|-------------|
| 🎓 신입생 | 학교 시스템에 익숙하지 않음, 비공식적 표현 | 수강신청, 장학금, 기숙사, 휴학 |
| 📚 재학생 (3학년) | 구체적 정보 필요, 졸업 준비 | 졸업요건, 전과, 복수전공, 교환학생 |
| 🎓 대학원생 | 연구/논문 중심, 전문적 질문 | 논문심사, 연구비, 학위취득, 지도교수 |
| 👨‍🏫 신임 교수 | 제도 파악 필요, 공식적 표현 | 연구년, 승진, 강의부담, 업적평가 |
| 👩‍🏫 정교수 | 세부 규정 확인, 권리 주장 | 안식년, 정년, 명예퇴직, 보직 |
| 👔 신입 직원 | 복무규정 파악, 혜택 문의 | 휴가, 복리후생, 승진, 겸직 |
| 👨‍💼 과장급 직원 | 부서 운영, 예산 관련 | 예산집행, 시설사용, 인사규정 |
| 👪 학부모 | 자녀 관련 정보, 외부 시선 | 등록금, 장학금, 휴학, 학사일정 |
| 🤕 어려운 상황의 학생 | 감정적, 급한 상황 | 제적위기, 학사경고, 성적이의, 고충처리 |
| 😡 불만있는 구성원 | 권리 주장, 신고 의향 | 성희롱, 갑질, 부당대우, 인권침해 |

### 2.2 쿼리 난이도 매트릭스 (필수)

**각 페르소나에 대해 아래 난이도 분포로 쿼리를 생성합니다:**

| 난이도 | 비율 | 특성 | 예시 |
|--------|------|------|------|
| **쉬움** | 30% | 단일 규정, 명확한 키워드 | "휴학 신청 기간" |
| **중간** | 40% | 여러 규정 연계, 조건부 답변 필요 | "장학금 받다가 휴학하면?" |
| **어려움** | 30% | 모호한 표현, 감정적, 복합 질문 | "학교 너무 힘들어서 쉬고 싶은데 돈이 없어요" |

### 2.3 쿼리 유형 매트릭스

| 유형 | 설명 | 예시 | 검증 포인트 |
|------|------|------|------------|
| **사실 확인** | 구체적 수치/정보 요청 | "졸업학점이 몇 학점이야?" | 정확한 숫자 |
| **절차 질문** | 방법/단계 문의 | "휴학 신청은 어떻게 해?" | 단계별 절차 + 기한 |
| **자격 확인** | 조건/요건 질문 | "장학금 받으려면 학점이 몇 점?" | 구체적 기준 |
| **비교 질문** | 옵션 간 차이 | "일반휴학 vs 군휴학 차이?" | 차이점 명확히 |
| **모호한 질문** | 비구체적 표현 | "학교 그만두고 싶어" | 의도 파악 + 옵션 제시 |
| **감정 표현** | 상황+감정 | "교수님이 불공평해" | 공감 + 실질적 해결책 |
| **복합 질문** | 여러 정보 동시 | "휴학하면 장학금은? 복학은?" | 모든 질문에 답변 |
| **은어/축약어** | 비공식 표현 | "수강철", "복전", "조졸" | 정확한 용어 인식 |

### 2.4 쿼리 생성 및 실행

**각 선택된 페르소나에 대해:**

1. **쿼리 생성**: 난이도 분포를 반영하여 3개 쿼리 생성
2. **쿼리 실행**:
```bash
uv run regulation search "<생성된_쿼리>" -a -n 5
```

3. **결과 기록**: 쿼리, 검색 결과, LLM 답변을 **전체** 캡처

### 2.5 의도 충족 검증 (필수)

> ⚠️ **모든 답변에 대해 "사용자가 이 답변으로 다음 행동을 할 수 있는가?"를 검증하세요.**

#### 의도 충족 체크리스트

각 답변에 대해 **모두 확인**:

- [ ] 사용자가 원하는 **구체적 행동**이 명확히 안내되었는가?
- [ ] **다음 단계**가 무엇인지 알 수 있는가?
- [ ] **예상 결과**가 설명되었는가?
- [ ] 필요한 **준비물/조건**이 명시되었는가?
- [ ] **기한**이 명시되었는가? (해당되는 경우)
- [ ] **담당부서/연락처**가 안내되었는가?

#### 의도 충족 판정

| 판정 | 조건 | 성공 카운트 |
|------|------|------------|
| ✅ **충족** | 체크리스트 5개 이상 통과 | 성공 |
| ⚠️ **부분 충족** | 체크리스트 3~4개 통과 | **실패로 카운트** |
| ❌ **미충족** | 체크리스트 2개 이하 통과 | 실패 |

#### 의도 충족 검증 기록 형식

```
[쿼리] "휴학하고 싶어요"

[의도 충족 검증]
- 사용자의 진짜 의도: 휴학 절차를 알고 싶음
- 기대 행동: 휴학 신청서 제출
- ✅ 구체적 행동: 휴학 신청서 작성 및 제출
- ✅ 다음 단계: 학과 → 교무처 순서
- ✅ 예상 결과: 휴학 승인 후 학적 변경
- ✅ 준비물/조건: 휴학 신청서, 보호자 동의서 (해당 시)
- ✅ 기한: 수업일수 2/3 이전
- ⚠️ 담당부서: 교무처 (연락처 누락)

판정: ✅ 의도 충족 (6/6 통과)
행동 가능성: ✅ 사용자가 바로 행동 가능
```

---

### 2.6 예시 시나리오 (난이도별)

**페르소나**: 🎓 신입생

```
[쿼리 1 - 쉬움]
"휴학 신청 기간이 언제야?"
→ 기대: 구체적 기간 (예: "학기 시작 전 방학 중" 또는 "수업일수 2/3 이전")
→ 의도 충족 필수: 기한, 절차 안내

[쿼리 2 - 중간]
"장학금 받고 있는데 휴학하면 어떻게 돼?"
→ 기대: 장학금 중단/유지 조건, 복학 후 재신청 여부
→ 의도 충족 필수: 장학금 처리 결과, 복학 후 조치 방법

[쿼리 3 - 어려움]
"돈이 없어서 학교 다니기 힘든데 어떡해야 할지 모르겠어요"
→ 기대: 장학금 + 등록금 분납 + 근로장학 + 긴급 지원 등 복합 안내
→ 의도 충족 필수: 각 지원 옵션별 신청 방법, 조건, 담당부서
```

---

## Phase 3: 답변 품질 심층 검토 (강화됨)

### 3.1 필수 팩트체크 절차

> ⚠️ **모든 답변에 대해 아래 절차를 반드시 수행하세요. 생략 금지!**

각 답변에서 **핵심 주장 3개**를 추출하고 검증합니다:

```bash
# 1. 답변에서 언급된 규정/조항 확인
uv run regulation search "<규정명> 제X조" -n 3

# 2. 답변의 핵심 수치/기한 확인
uv run regulation search "<키워드> 기간|학점|요건" -n 5

# 3. 실제 검색 결과와 답변 내용 대조
```

**팩트체크 기록 형식:**
```
[팩트체크 #1]
- 답변 주장: "휴학은 수업일수 2/3까지 가능"
- 검증 쿼리: uv run regulation search "휴학 수업일수" -n 3
- 검증 결과: ✅ 학칙 제XX조에서 확인됨 / ❌ 해당 내용 없음 / ⚠️ 다른 내용임
```

### 3.2 답변 품질 평가 매트릭스 (엄격화)

| 항목 | 배점 | 평가 기준 | 자동 감점 조건 |
|------|------|----------|---------------|
| **정확성** | 1.0 | 규정 내용과 일치 | 팩트체크 실패 시 **0점** |
| **완전성** | 1.0 | 질문의 모든 측면에 답변 | 복합질문 중 1개 누락 시 **-0.5** |
| **관련성** | 1.0 | 질문 의도에 맞는 답변 | 50% 이상 무관한 내용 시 **0점** |
| **출처 명시** | 1.0 | 규정명/조항 인용 | 출처 없는 단정 시 **0점** |
| **실용성** | 0.5 | 기한/서류/담당부서 포함 | 절차질문에 기한 없으면 **-0.25** |
| **행동 가능성** | 0.5 | 사용자가 바로 행동 가능 | 기한/서류/담당부서 중 2개↑ 누락 시 **0점** |
| **합계** | 5.0 | | |

> ⚠️ **행동 가능성(Actionability)**: 답변을 읽은 사용자가 **추가 질문 없이 바로 행동**에 옮길 수 있어야 합니다.

### 3.3 성공/실패 판정 (엄격 기준)

| 판정 | 조건 | 성공률 계산 |
|------|------|------------|
| ✅ **성공** | 점수 ≥ 4.0 AND 팩트체크 모두 통과 | 성공으로 카운트 |
| ⚠️ **부분성공** | 점수 3.0~3.9 OR 팩트체크 1개 실패 | **실패로 카운트** |
| ❌ **실패** | 점수 < 3.0 OR 팩트체크 2개 이상 실패 | 실패로 카운트 |

### 3.4 실패 유형 및 심각도

| 실패 유형 | 설명 | 심각도 | 자동 판정 |
|----------|------|--------|----------|
| `WRONG_FACT` | 규정과 다른 정보 제공 | Critical | 즉시 실패 |
| `HALLUCINATION` | 존재하지 않는 규정/조항 언급 | Critical | 즉시 실패 |
| `GENERIC_ANSWER` | 일반론만 제시, 이 학교 규정 미인용 | High | 즉시 실패 |
| `IRRELEVANT` | 질문과 무관한 답변 | High | 즉시 실패 |
| `INCOMPLETE` | 핵심 정보 누락 (기한, 조건 등) | Medium | 부분성공 |
| `NO_SOURCE` | 출처 없이 단정적 답변 | Medium | 부분성공 |
| `CONFUSING` | 이해하기 어려운 답변 | Low | 감점 |

### 3.5 검토 체크리스트 (필수)

각 답변에 대해 **모두 확인**:

- [ ] **팩트체크 완료**: 핵심 주장 3개 검증 (검증 쿼리 실행 필수)
- [ ] **일반론 체크**: "대학마다 다를 수 있습니다" 같은 회피성 답변 아닌가?
- [ ] **구체성 체크**: 숫자(학점, 기간), 담당부서, 필요서류가 명시되었는가?
- [ ] **출처 체크**: 인용된 규정/조항이 실제로 존재하고 내용이 일치하는가?
- [ ] **누락 체크**: 중요한 예외사항, 주의사항이 빠지지 않았는가?
- [ ] **할루시네이션 체크**: 규정에 없는 내용을 지어내지 않았는가?
- [ ] **행동 가능성 체크**: 사용자가 바로 행동할 수 있는가?

---

### 3.6 일반론 답변 감지 패턴 (자동 실패)

> ⚠️ 다음 패턴이 답변에 포함되면 **GENERIC_ANSWER**로 즉시 실패 처리:

| 패턴 | 예시 | 이유 |
|------|------|------|
| `대학마다 다를 수 있습니다` | "일반적으로... 대학마다 다를 수 있습니다" | 회피성 답변 |
| `확인이 필요합니다` | "정확한 내용은 학교에 확인이 필요합니다" | 책임 회피 |
| `일반적으로` (규정 인용 없이) | "일반적으로 휴학은..." | 이 학교 규정 미인용 |
| `담당 부서에 문의` (구체 부서명 없이) | "자세한 내용은 담당 부서에 문의하세요" | 비구체적 안내 |
| `상황에 따라 다릅니다` (조건 미명시) | "상황에 따라 다릅니다" | 조건 미제시 |
| `정확한 정보는 확인 바랍니다` | "위 내용은 참고용이며..." | 책임 회피 |
| `학교마다 차이가 있을 수 있습니다` | "...학교마다 차이가 있을 수 있습니다" | 회피성 답변 |

**예외**: 규정에 실제로 "경우에 따라 다르다"고 명시된 경우는 출처와 함께 제시하면 허용

---

### 3.7 후속 질문 제안 품질 검증

시스템이 제안하는 후속 질문(`suggestions`)이 사용자 의도 흐름과 일치하는지 검증합니다.

#### 검증 체크리스트
- [ ] **관련성**: 제안된 질문이 현재 주제와 관련있는가?
- [ ] **자연스러움**: 실제 사용자가 물어볼 법한 질문인가?
- [ ] **심화 방향**: 더 구체적인 정보로 안내하는가?
- [ ] **다양성**: 서로 다른 측면을 다루는가? (중복 없음)
- [ ] **실용성**: 사용자에게 실질적 도움이 되는 질문인가?

#### 후속 질문 품질 점수

| 점수 | 기준 |
|------|------|
| 5/5 | 모든 제안이 관련성 높고 자연스러움 |
| 4/5 | 1개 제안이 약간 관련성 부족 |
| 3/5 | 2개 제안이 관련성 부족 또는 중복 |
| 2/5 | 대부분 제안이 부적절 |
| 1/5 | 제안이 없거나 모두 무관함 |

#### 좋은/나쁜 후속 질문 예시

```
원래 질문: "휴학하고 싶어요"

❌ 나쁜 제안:
- "학교 역사가 궁금하신가요?" (무관함)
- "휴학이 무엇인가요?" (이미 알고 있음)
- "다른 규정을 검색하시겠습니까?" (너무 일반적)

✅ 좋은 제안:
- "휴학 기간은 얼마나 할 수 있나요?"
- "휴학 중 등록금은 어떻게 되나요?"
- "복학 절차도 알려드릴까요?"
```

---

## Phase 4: 멀티턴 대화 테스트 (필수)

> ⚠️ **멀티턴 테스트는 선택이 아닌 필수입니다.** 대부분의 사용자는 한 번의 쿼리로 끝내지 않고 후속 질문을 계속합니다.

단일 쿼리를 넘어 **후속 질문 시나리오**를 테스트합니다.

### 4.1 후속 질문 유형

| 유형 | 설명 | 예시 | 빈도 |
|------|------|------|------|
| **구체화** | 더 자세한 정보 요청 | "그러면 정확히 몇 학점이야?" | 매우 높음 |
| **관련 확장** | 연관 주제로 확장 | "휴학하면 장학금은 어떻게 돼?" | 높음 |
| **예외 확인** | 특수 상황 문의 | "군대 가는 경우도 똑같아?" | 높음 |
| **절차 심화** | 구체적 절차 문의 | "신청서는 어디서 받아?" | 매우 높음 |
| **조건 변경** | 다른 조건에서의 적용 | "대학원생도 마찬가지야?" | 중간 |
| **확인 질문** | 이해 확인 | "그러니까 3월 전에 신청해야 한다는 거지?" | 높음 |
| **되돌아가기** | 이전 주제로 복귀 | "아까 장학금 얘기로 돌아가서..." | 중간 |
| **비교 요청** | 옵션 비교 | "그럼 일반휴학이랑 군휴학 중에 뭐가 나아요?" | 중간 |

### 4.2 멀티턴 시나리오 최소 요건

> 각 페르소나에 대해 **2개 이상의 5턴 대화**를 실행 (필수)

```
[Turn 1 - 초기 질문]
User: "휴학하고 싶어요"
→ 시스템 응답 확인
→ 중단점: 휴학 종류가 언급되지 않으면 실패

[Turn 2 - 후속 질문 (구체화)]
User: "일반휴학이요. 신청 기간은 언제예요?"
→ 맥락 검증: "일반휴학"이 맥락에 유지되는지 확인

[Turn 3 - 후속 질문 (관련 확장)]
User: "장학금 받고 있는데 어떻게 돼요?"
→ 맥락 검증: 휴학 맥락 유지 + 장학금 정보 추가

[Turn 4 - 후속 질문 (절차 심화)]
User: "그럼 복학할 때는요?"
→ 맥락 검증: 휴학 → 장학금 → 복학 흐름 유지

[Turn 5 - 후속 질문 (확인)]
User: "휴학 기간은 얼마까지 가능해요?"
→ 최종 맥락 일관성 확인
```

### 4.3 멀티턴 평가 기준 (확장)

| 항목 | 평가 내용 | 배점 |
|------|----------|------|
| **맥락 유지** | 이전 대화 내용을 기억하고 반영하는가? | 1.0 |
| **정보 일관성** | Turn 간에 모순되는 정보가 없는가? | 1.0 |
| **점진적 심화** | 후속 질문에 더 구체적인 정보를 제공하는가? | 1.0 |
| **중복 회피** | 이미 언급한 내용을 불필요하게 반복하지 않는가? | 0.5 |
| **자연스러운 전환** | 대화 흐름이 자연스러움 | 0.5 |
| **후속 질문 예측** | 적절한 후속 질문을 제안하는가? | 1.0 |
| **합계** | | 5.0 |

### 4.4 멀티턴 성공/실패 판정

| 판정 | 조건 | 성공률 계산 |
|------|------|------------|
| ✅ **성공** | 점수 ≥ 4.0 AND 모든 Turn에서 맥락 유지 | 성공 |
| ⚠️ **부분성공** | 점수 3.0~3.9 OR 1개 Turn에서 맥락 단절 | **실패로 카운트** |
| ❌ **실패** | 점수 < 3.0 OR 2개↑ Turn에서 맥락 단절 | 실패 |

### 4.5 CLI에서 멀티턴 테스트

```bash
# 인터랙티브 모드로 멀티턴 테스트
uv run regulation

# 첫 질문 입력 후 후속 질문 연속 입력
# 각 Turn의 응답을 기록하고 맥락 유지 여부 확인
```

### 4.6 멀티턴 평가 기록 양식

```
[시나리오] 신입생 - 휴학 문의
[실행 일시] 2026-01-14 14:30

Turn 1: ✅ 성공 (맥락 설정 완료)
Turn 2: ✅ 성공 (맥락 유지 + 구체 정보)
Turn 3: ⚠️ 부분성공 (장학금 유형 일부 누락)
Turn 4: ❌ 실패 (맥락 단절 - 휴학 언급 없이 복학만 설명)
Turn 5: - (Turn 4 실패로 중단)

[멀티턴 점수]
- 맥락 유지: 3/5
- 정보 일관성: 4/5
- 점진적 심화: 3/5
- 중복 회피: 5/5
- 자연스러운 전환: 3/5
- 후속 질문 예측: 4/5
- 총점: 3.7/5.0

[판정] ⚠️ 부분성공 → 실패로 카운트
[근본 원인] Turn 4에서 맥락(휴학) 유실 → 컨텍스트 윈도우 문제 가능성
```

---

## Phase 4.5: 실패 케이스 심층 분석 (5-Why)

실패한 모든 쿼리에 대해 **근본 원인 분석**을 수행합니다.

### 4.5.1 5-Why 분석 템플릿

```
[실패 쿼리] "장학금 받고 있는데 휴학하면 어떻게 돼?"
[실패 유형] INCOMPLETE

Why 1: 왜 실패했는가?
→ 장학금 유형별 처리 방법이 누락됨

Why 2: 왜 누락되었는가?
→ 검색 결과에 장학금-휴학 연계 정보가 없었음

Why 3: 왜 검색되지 않았는가?
→ "장학금 휴학" 키워드 조합이 인텐트에 없음

Why 4: 왜 인텐트에 없는가?
→ 복합 상황(A+B) 시나리오가 인텐트 설계에 미반영

Why 5: 근본 원인은?
→ 인텐트 설계가 단일 주제 중심이며, 주제 간 연계 시나리오 부재

[조치 방안]
- data/config/intents.json에 복합 인텐트 추가
- 예: "scholarship_leave" 인텐트 신설
```

### 4.5.2 실패 유형별 근본 원인 카테고리

| 실패 유형 | 1차 원인 | 근본 원인 카테고리 |
|----------|---------|-------------------|
| `WRONG_FACT` | LLM이 잘못된 정보 생성 | **생성 실패** - 프롬프트/컨텍스트 문제 |
| `HALLUCINATION` | 존재하지 않는 규정 언급 | **생성 실패** - Grounding 부족 |
| `GENERIC_ANSWER` | 규정 미인용 | **검색 실패** - 관련 청크 미검색 |
| `IRRELEVANT` | 의도 파악 실패 | **의도 파악 실패** - 인텐트 매칭 문제 |
| `INCOMPLETE` | 정보 누락 | **검색 실패** 또는 **생성 실패** |
| `NO_SOURCE` | 출처 미명시 | **생성 실패** - 프롬프트 문제 |

### 4.5.3 근본 원인별 개선 방향

| 근본 원인 | 개선 방향 | 담당 Phase |
|----------|----------|------------|
| **검색 실패** | 인텐트/동의어 추가, 쿼리 확장 개선 | Phase 5.3 |
| **생성 실패** | 프롬프트 개선, 컨텍스트 구성 개선 | Phase 5.4 |
| **의도 파악 실패** | 인텐트 패턴 추가, 청중 감지 개선 | Phase 5.3-5.4 |

### 4.5.4 분석 필수 실행 조건

다음 조건 중 하나라도 해당되면 **5-Why 분석 필수**:

- ❌ 동일 실패 유형이 2회 이상 발생
- ❌ Critical 심각도 실패 발생 (`WRONG_FACT`, `HALLUCINATION`)
- ❌ 동적 쿼리 성공률 80% 미달
- ❌ 멀티턴 테스트에서 맥락 단절 발생

---

## Phase 5: 개선 적용 (실패 발생 시)

### 5.1 실패 분석

```bash
cat data/output/improvement_plan.json | python -m json.tool
```

### 5.2 제안 유형별 처리

| 유형 | 처리 방법 |
|------|----------|
| `intent` | `data/config/intents.json` 패치 |
| `synonym` | `data/config/synonyms.json` 패치 |
| `code_pattern` | `src/rag/infrastructure/query_analyzer.py` 수정 |
| `code_weight` | 가중치 조정 |
| `code_audience` | 대상 감지 로직 개선 |
| `architecture` | Phase 7에서 수동 검토 보고 |

### 5.3 데이터 패치 (intent/synonym)

**인텐트 추가** - `data/config/intents.json`:
```json
{
  "intent_id": "overseas_conference",
  "triggers": ["해외학회", "해외 학회", "국제학회"]
}
```

**동의어 추가** - `data/config/synonyms.json`에 새 항목 추가

### 5.4 코드 개선 (code_*)

| 제안 유형 | 수정 파일 | 수정 대상 |
|-----------|----------|----------|
| `code_pattern` | `src/rag/infrastructure/query_analyzer.py` | `INTENT_PATTERNS` |
| `code_weight` | `src/rag/infrastructure/query_analyzer.py` | `WEIGHT_PRESETS` |
| `code_audience` | `src/rag/infrastructure/query_analyzer.py` | `*_KEYWORDS` 상수 |

**수정 원칙**: 기존 항목 삭제 금지, 새 항목만 추가

### 5.5 패치 검증
```bash
uv run pytest tests/rag/unit/infrastructure/test_query_analyzer.py -v --tb=short
```

---

## Phase 6: 재평가 및 반복 판단

### 6.1 단위 테스트 확인
```bash
uv run pytest tests/rag/ -v --tb=short
```

### 6.2 정적 평가 재실행
```bash
uv run python scripts/auto_evaluate.py --run
```

### 6.3 실패한 동적 쿼리 재테스트

Phase 3에서 실패한 쿼리들을 다시 테스트

### 6.4 반복 판단

**종료 조건** (하나라도 해당 시 Phase 7으로):
1. 모든 목표 달성
2. 개선 한계: 2회 연속 동일 결과
3. 최대 반복: 3회 사이클 완료
4. 구조적 문제: `architecture` 유형만 남음

종료 조건 미해당 시 **Phase 5로 반복**

---

## Phase 7: 완료 보고

### 7.1 세션 요약 생성

1. **시작 상태**
   - 정적 테스트 통과율
   - 시스템 상태 (규정 수, 조항 수)

2. **동적 테스트 결과**
   - 테스트한 페르소나 목록
   - 쿼리 난이도 분포
   - **팩트체크 수행 내역** (검증 쿼리 포함)
   - 성공/부분성공/실패 비율

3. **멀티턴 테스트 결과**
   - 테스트한 시나리오 수
   - 맥락 유지 성공률

4. **답변 품질 점수**
   - 항목별 평균 점수
   - **주요 실패 유형 분포**

5. **적용된 개선**
   - 인텐트/동의어 추가 내역
   - 코드 수정 내역

6. **최종 상태**
   - 최종 통과율
   - **남은 문제 및 원인 분석**

7. **다음 단계 권장사항**

### 7.2 결과 저장 위치
- 세션 요약: `data/output/test_session_<날짜>.md`
- 실패 쿼리 목록: `data/output/failed_queries_<날짜>.json`

---

## 트러블슈팅

```bash
# LLM 연결 확인 (lmstudio)
curl -s http://game-mac-studio:1234/v1/models | python3 -c "import sys,json; print(json.load(sys.stdin))"

# 특정 테스트 디버깅
uv run pytest tests/rag/unit/infrastructure/test_query_analyzer.py::test_specific -v -s

# 변경사항 확인/되돌리기
git diff data/config/
git checkout -- data/config/intents.json

# 규정 내용 직접 확인 (팩트체크용)
uv run regulation search "<규정명>" -n 10

# 특정 조항 확인
uv run regulation search "<규정명> 제N조"
```

---

## 체크리스트

### 기본 검증
- [ ] Phase 0: 시스템 상태 확인
- [ ] Phase 1: 정적 평가 완료

### 동적 테스트
- [ ] Phase 2: 페르소나 선택 (3~5개)
- [ ] Phase 2: **난이도 분포 반영** (쉬움 30%, 중간 40%, 어려움 30%)
- [ ] Phase 2: 쿼리 생성 및 실행
- [ ] Phase 2: **의도 충족 검증 완료** (모든 쿼리)
- [ ] Phase 3: **모든 답변 팩트체크 완료**
- [ ] Phase 3: **일반론 답변 패턴 체크 완료**
- [ ] Phase 3: **후속 질문 제안 품질 검증 완료**
- [ ] Phase 3: 답변 품질 검토 완료 (평균 ≥ 4.0)

### 멀티턴 테스트 (필수)
- [ ] Phase 4: 멀티턴 시나리오 실행 **(페르소나당 2개 × 5턴 이상)**
- [ ] Phase 4: 맥락 유지 확인 (각 Turn별)
- [ ] Phase 4: 멀티턴 점수 산정 완료 (평균 ≥ 4.0)
- [ ] Phase 4: 후속 질문 성공률 확인 (≥ 85%)

### 실패 분석
- [ ] Phase 4.5: 실패 케이스 5-Why 분석 완료 (해당 시)
- [ ] Phase 4.5: 근본 원인 카테고리화 완료

### 개선 및 완료
- [ ] Phase 5: 개선 적용 (필요시)
- [ ] Phase 6: 재평가 완료
- [ ] Phase 7: 보고서 생성

---

## 부록 A: 엄격한 테스트 세션 예시

```
=== RAG 품질 테스트 세션 시작 ===
날짜: 2026-01-12
테스터: AI Agent (엄격 모드)

[Phase 0] 시스템 상태: OK (318개 규정, 17254개 조항)
[Phase 1] 정적 테스트: 50/50 통과 (100%)

[Phase 2] 동적 테스트
선택된 페르소나: 신입생, 대학원생, 불만있는 구성원

--- 페르소나: 신입생 ---

[쿼리 1 - 쉬움] "휴학 신청 기간이 언제야?"
답변 요약: "학기 시작 전 방학 기간 또는 수업일수 2/3 이전..."

[팩트체크]
#1: "수업일수 2/3 이전" 
   검증: uv run regulation search "휴학 수업일수" -n 3
   결과: ✅ 학칙 제XX조 "수업일수의 3분의 2선까지" 확인

#2: "방학 기간" 
   검증: uv run regulation search "휴학 방학" -n 3  
   결과: ✅ 휴학규정 제X조 확인

점수: 정확성 1.0 + 완전성 0.8 + 관련성 1.0 + 출처 1.0 + 실용성 0.8 = 4.6
판정: ✅ 성공

---

[쿼리 2 - 중간] "장학금 받고 있는데 휴학하면 어떻게 돼?"
답변 요약: "휴학 시 장학금은 중단되며..."

[팩트체크]
#1: "장학금 중단"
   검증: uv run regulation search "휴학 장학금" -n 5
   결과: ⚠️ 명확한 규정 없음, 장학금 유형별로 다를 수 있음

#2: "복학 후 재신청"
   검증: uv run regulation search "장학금 재신청" -n 3
   결과: ❌ 해당 내용 찾을 수 없음

점수: 정확성 0.5 + 완전성 0.7 + 관련성 1.0 + 출처 0.5 + 실용성 0.5 = 3.2
판정: ⚠️ 부분성공 → **실패로 카운트**

---

[쿼리 3 - 어려움] "돈이 없어서 학교 다니기 힘든데 어떡해야 할지 모르겠어요"
답변 요약: "장학금 종류로는... 등록금 분납 제도가..."

[팩트체크]
#1: "국가장학금"
   검증: uv run regulation search "국가장학금" -n 3
   결과: ✅ 장학금규정 제X조 확인

#2: "등록금 분납"
   검증: uv run regulation search "등록금 분납" -n 3
   결과: ✅ 등록금납부규정 제X조 확인

#3: "근로장학금"
   검증: uv run regulation search "근로장학" -n 3
   결과: ✅ 근로장학생규정 확인

점수: 정확성 1.0 + 완전성 0.9 + 관련성 1.0 + 출처 0.8 + 실용성 0.9 = 4.6
판정: ✅ 성공

---

[Phase 3] 품질 점수 (엄격 모드)
- 정확성: 4.2/5.0
- 완전성: 3.8/5.0
- 관련성: 4.6/5.0
- 출처 명시: 3.7/5.0
- 실용성: 3.7/5.0
- 평균: 4.0/5.0 ✅

동적 쿼리 결과:
- 성공: 6개
- 부분성공(=실패): 3개
- 실패: 1개
- **성공률: 60%** ❌ (목표 80% 미달)

[Phase 5] 개선 필요
- 장학금-휴학 연계 정보 보강 필요
- 등록금 관련 인텐트 추가 필요

[Phase 7] 최종 결과
- 정적 테스트: 100% ✅
- 동적 쿼리 성공률: 60% ❌
- 멀티턴 성공률: 80% ✅
- 답변 품질: 4.0/5.0 ✅
- 회귀: 없음

결론: 동적 쿼리 목표 미달 - 개선 필요 ⚠️
```

---

## 부록 B: 멀티턴 시나리오 템플릿 라이브러리

페르소나별 대표 멀티턴 시나리오입니다. 각 시나리오는 **5턴 이상**으로 구성됩니다.

### B.1 🎓 신입생 시나리오

#### 시나리오 1: 휴학 문의 → 장학금 연계 → 복학
```
[Turn 1] "휴학하고 싶어요"
기대: 휴학 종류, 기본 절차 안내
중단점: 휴학 종류가 언급되지 않으면 실패

[Turn 2] "일반휴학이요. 신청 기간이 언제예요?"
기대: 구체적 신청 기간 + 필요 서류
맥락 검증: "일반휴학"이 맥락에 유지되는지 확인

[Turn 3] "장학금 받고 있는데 어떻게 돼요?"
기대: 장학금 유형별 처리 방법
맥락 검증: 휴학 맥락 유지 + 장학금 정보 추가

[Turn 4] "그럼 복학할 때는요?"
기대: 복학 절차 + 장학금 재신청 여부
맥락 검증: 휴학 → 장학금 → 복학 흐름 유지

[Turn 5] "휴학 기간은 얼마까지 가능해요?"
기대: 최대 휴학 기간 + 연장 가능 여부
```

#### 시나리오 2: 경제적 어려움 → 종합 지원
```
[Turn 1] "돈이 없어서 학교 다니기 힘들어요"
기대: 공감 + 지원 옵션 개요 (장학금, 분납, 근로)
중단점: 단순 위로만 하면 실패

[Turn 2] "장학금 종류가 뭐가 있어요?"
기대: 교내/교외 장학금 목록 + 신청 조건

[Turn 3] "성적이 안 좋은데도 받을 수 있어요?"
기대: 성적 기준 + 성적 무관 장학금 안내

[Turn 4] "등록금 분납은 어떻게 해요?"
기대: 분납 신청 절차 + 기한 + 조건

[Turn 5] "근로장학생은요?"
기대: 근로장학 신청 방법 + 근무 조건 + 급여
```

### B.2 📚 재학생 (3학년) 시나리오

#### 시나리오 1: 졸업요건 확인 → 부족학점 해결
```
[Turn 1] "졸업하려면 뭐가 필요해요?"
기대: 졸업요건 개요 (학점, 필수과목, 외국어 등)
중단점: 구체적 학점 수치 없으면 실패

[Turn 2] "전공학점이 몇 학점이에요?"
기대: 전공 필수/선택 학점 구분 + 합계

[Turn 3] "교양은요?"
기대: 교양 필수/선택 학점 + 영역별 요건
맥락 검증: 졸업요건 흐름 유지

[Turn 4] "지금 부족한 학점 확인하려면?"
기대: 학점 확인 방법 (포털, 학사시스템 등)

[Turn 5] "계절학기로 채울 수 있어요?"
기대: 계절학기 학점 인정 조건 + 신청 방법
```

#### 시나리오 2: 복수전공 → 졸업연기
```
[Turn 1] "복수전공 하고 싶어요"
기대: 복수전공 개요 + 신청 자격

[Turn 2] "신청 기간이 언제예요?"
기대: 구체적 신청 기간 + 필요 서류

[Turn 3] "학점은 얼마나 더 들어야 해요?"
기대: 복수전공 이수학점 + 기존 학점과의 관계

[Turn 4] "그러면 졸업이 늦어지나요?"
기대: 졸업 연기 가능성 + 초과학기 등록금

[Turn 5] "중간에 포기할 수도 있어요?"
기대: 복수전공 포기 절차 + 이수 학점 처리
```

### B.3 🎓 대학원생 시나리오

#### 시나리오 1: 논문 심사 → 학위 취득
```
[Turn 1] "논문 심사 절차가 어떻게 되나요?"
기대: 심사 단계 개요 (예심, 본심 등)

[Turn 2] "예비심사는 언제 신청해요?"
기대: 예심 신청 기간 + 조건 + 필요 서류

[Turn 3] "심사위원은 어떻게 정해지나요?"
기대: 심사위원 구성 방법 + 자격 요건

[Turn 4] "본심사까지 기간은요?"
기대: 예심-본심 간 최소 기간

[Turn 5] "심사 통과 후 학위 수여까지는요?"
기대: 학위 수여 절차 + 일정
```

### B.4 👨‍🏫 신임 교수 시나리오

#### 시나리오 1: 연구년 문의
```
[Turn 1] "연구년 제도에 대해 알고 싶습니다"
기대: 연구년 개요 + 자격 조건 요약

[Turn 2] "신청 자격이 어떻게 되나요?"
기대: 구체적 자격 요건 (재직 기간, 업적 등)

[Turn 3] "해외 연구년도 가능한가요?"
기대: 해외 연구년 조건 + 지원 내용

[Turn 4] "연구년 중 급여는 어떻게 되나요?"
기대: 급여 지급 비율 + 조건

[Turn 5] "신청 절차와 기한을 알려주세요"
기대: 구체적 절차 + 신청 기한 + 필요 서류
```

### B.5 🤕 어려운 상황의 학생 시나리오

#### 시나리오 1: 학사경고 → 대처방안
```
[Turn 1] "학사경고 받았어요... 어떡하죠?"
기대: 공감 + 학사경고 의미 + 대처 옵션
중단점: 공감 없이 규정만 나열하면 부분성공

[Turn 2] "몇 번 받으면 제적이에요?"
기대: 구체적 제적 기준 (연속/누적)

[Turn 3] "이번 학기 성적 올리면 괜찮아요?"
기대: 학사경고 해제 조건 + 유예 제도 안내

[Turn 4] "성적이 너무 안 좋은 과목 철회할 수 있어요?"
기대: 수강 철회/포기 제도 + 조건 + 기한

[Turn 5] "학습 도움 받을 수 있는 곳 있어요?"
기대: 학습지원센터, 튜터링 등 지원 프로그램
```

#### 시나리오 2: 성적 이의 → 고충 처리
```
[Turn 1] "교수님 성적이 너무 불공정해요"
기대: 공감 + 성적 이의 제도 안내
중단점: 감정 무시하고 절차만 설명하면 부분성공

[Turn 2] "이의신청은 어떻게 해요?"
기대: 이의신청 절차 + 기한 + 필요 서류

[Turn 3] "교수님이 안 받아주면요?"
기대: 상위 기관 절차 (학과 → 단과대 등)

[Turn 4] "그래도 안 되면 어디에 신고해요?"
기대: 고충처리 기관 안내 (학생인권센터 등)

[Turn 5] "신고하면 불이익 없어요?"
기대: 비밀보장 + 보복 금지 규정 안내
```

### B.6 😡 불만있는 구성원 시나리오

#### 시나리오 1: 부당대우 신고
```
[Turn 1] "교수님한테 부당한 대우를 받았어요"
기대: 공감 + 상황 파악 질문 또는 신고 채널 안내

[Turn 2] "연구실에서 부당한 업무 지시를 받아요"
기대: 연구실 관련 고충처리 절차 안내

[Turn 3] "신고하면 어떻게 처리되나요?"
기대: 신고 접수 → 조사 → 결과 통보 절차

[Turn 4] "익명으로 할 수 있어요?"
기대: 익명 신고 가능 여부 + 방법

[Turn 5] "신고 후 보복당하면요?"
기대: 보복 금지 규정 + 추가 신고 채널
```

### B.7 페르소나 선택 가이드

매 테스트 세션마다 아래 기준으로 **3~5개 페르소나**를 선택하세요:

| 선택 기준 | 권장 조합 |
|----------|----------|
| **균형 테스트** | 신입생 + 재학생 + 교수 + 직원 |
| **학생 집중** | 신입생 + 재학생 + 대학원생 + 어려운 상황 학생 |
| **교직원 집중** | 신임 교수 + 정교수 + 신입 직원 + 과장급 직원 |
| **고충/민원 집중** | 어려운 상황 학생 + 불만있는 구성원 + 학부모 |
| **신규 구성원** | 신입생 + 신임 교수 + 신입 직원 |
